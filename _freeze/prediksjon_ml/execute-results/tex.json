{
  "hash": "868555f51667de5d1fd1cdb298658120",
  "result": {
    "engine": "knitr",
    "markdown": "# Prediksjon og maskinlæring\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(haven)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\nI tidligere kapitler har vi brukt regresjonsmodeller til å beskrive sammenhenger mellom variable. Vi har tolket regresjonskoeffisienter som uttrykk for forskjeller mellom grupper. Men regresjonsmodeller kan også brukes til noe annet: *prediksjon*. Her gir vi en kort introduksjon til hvordan man tenker på prediksjon og hva som skiller det fra den vanlige tilnærmingen i samfunnsvitenskap.\n\n## Forklaring vs. prediksjon\nI samfunnsvitenskap er vi vanligvis opptatt av *forklaring*: vi vil forstå *hvorfor* ting henger sammen. Da er vi mest interessert i regresjonskoeffisientene. Hva er sammenhengen mellom utdanning og inntekt? Hva er kjønnsforskjellen i timelønn?\n\nMen noen ganger er vi mer opptatt av å *predikere* utfall. Da bryr vi oss ikke nødvendigvis om hvorfor modellen virker, men om den gir gode gjetninger. Eksempler kan være:\n\n- Hvilke pasienter har høy risiko for tilbakefall?\n- Hvilke elever har høy risiko for å falle fra videregående?\n- Hva blir arbeidsledigheten neste kvartal?\n\nI slike tilfeller er det *utfallsvariabelen* vi er mest opptatt av, ikke forklaringsvariablene. Vi vil ha en modell som gir gode prediksjoner for nye observasjoner vi ikke har sett ennå. Dette er kjernen i det som ofte kalles *maskinlæring*.\n\n## Overtilpasning\nEt sentralt problem i prediksjon er *overtilpasning* (engelsk: *overfitting*). En modell som er veldig kompleks kan tilpasse seg alle særegenhetene i dataene vi har, inkludert tilfeldig støy. Da får modellen veldig god \"score\" på treningsdataene, men dårlige prediksjoner for nye data.\n\nTenk deg at du pugger gamle eksamensoppgaver ord for ord. Du kan gjengi alle svarene perfekt -- men bare for akkurat de oppgavene. Får du en ny oppgave som er litt annerledes, hjelper det lite. Det er det samme som skjer med en overtilpasset modell.\n\nEn enkel modell med få variable vil kanskje ikke fange opp alt i treningsdataene, men kan likevel gi bedre prediksjoner for nye data fordi den har lært det generelle mønsteret i stedet for støyen. Balansen mellom for enkel og for kompleks modell er det viktigste spørsmålet i prediksjon.\n\n## Trening og test: dele opp dataene\nHvordan vet vi om modellen vår gir gode prediksjoner for *nye* data? En enkel strategi er å dele opp dataene i to deler:\n\n- **Treningsdata**: Brukes til å estimere modellen\n- **Testdata**: Brukes til å evaluere hvor gode prediksjonene er\n\nVi estimerer modellen kun på treningsdataene, og deretter ser vi hvor godt modellen predikerer utfallsvariabelen i testdataene -- data modellen aldri har \"sett\" under estimeringen.\n\nLa oss prøve dette med abu89-datasettet. Vi deler tilfeldig dataene i 80% trening og 20% test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nn <- nrow(abu89)\ntrenings_indeks <- sample(1:n, size = round(0.8 * n))\n\ntrening <- abu89[trenings_indeks, ]\ntest     <- abu89[-trenings_indeks, ]\n```\n:::\n\n\nFunksjonen `set.seed()` sørger for at den tilfeldige oppdelingen blir den samme hver gang koden kjøres. Det er god praksis for reproduserbarhet.\n\n## En enkel prediksjonsmodell\nVi bruker helt vanlig lineær regresjon som prediksjonsmodell. La oss predikere timelønn (`time89`) basert på alder, kjønn, utdanning og yrkeserfaring.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(time89 ~ age + female + ed + fexp, data = trening)\n```\n:::\n\n\nNå bruker vi `predict()` til å lage prediksjoner for testdataene:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(predikert = predict(mod, newdata = test))\n```\n:::\n\n\nVi kan visualisere hvor godt modellen treffer ved å plotte predikert mot faktisk timelønn:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(test, aes(x = predikert, y = time89)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, col = \"red\", linewidth = 1) +\n  labs(x = \"Predikert timelønn\", y = \"Faktisk timelønn\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](prediksjon_ml_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nDen røde linjen viser hvor punktene ville ligget hvis modellen predikerte perfekt. Vi ser at modellen fanger opp den generelle trenden, men det er mye variasjon den ikke klarer å forklare. Det er helt normalt for denne typen data.\n\n## Mål på prediksjonsevne\nFor å tallfeste hvor gode prediksjonene er bruker vi gjerne to mål:\n\n**RMSE** (*Root Mean Squared Error*) måler gjennomsnittlig avvik mellom predikert og faktisk verdi, i samme enhet som utfallsvariabelen. Lavere er bedre.\n\n**R-kvadrat** ($R^2$) måler hvor stor andel av variasjonen i utfallsvariabelen modellen forklarer. Verdien ligger mellom 0 og 1, der 1 betyr perfekt prediksjon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresidualer <- test$time89 - test$predikert\n\nrmse <- sqrt(mean(residualer^2))\nr2   <- 1 - sum(residualer^2) / sum((test$time89 - mean(test$time89))^2)\n\ndata.frame(RMSE = round(rmse, 1),\n           R2   = round(r2, 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  RMSE    R2\n1 23.6 0.366\n```\n\n\n:::\n:::\n\n\nHer er RMSE uttrykt i kroner, altså det gjennomsnittlige avviket i predikert timelønn. R-kvadrat forteller oss hvor mye av variasjonen i timelønn modellen fanger opp.\n\n## Kryssvalidering\nOppdelingen i trening og test er litt tilfeldig. Kanskje fikk vi et uheldig utvalg? En mer robust tilnærming er *kryssvalidering* (engelsk: *cross-validation*). Prinsippet er at man deler dataene i $k$ deler (f.eks. 10), og så bruker man 9 deler til trening og 1 del til testing. Dette gjentas slik at hver del brukes som testdata nøyaktig en gang. Til slutt regner man ut gjennomsnittet av prediksjonsfeilen over alle rundene.\n\nVi går ikke nærmere inn på implementeringen her, men det er viktig å vite at dette er standardmetoden for å evaluere prediksjonsmodeller. Pakker som `caret` og `tidymodels` i R gjør dette enkelt i praksis.\n\n## Regularisering: LASSO\nNår man har mange mulige forklaringsvariable, kan det være fristende å inkludere alle sammen. Men det kan føre til overtilpasning. En teknikk som hjelper med dette er *regularisering*. Den mest brukte varianten kalles **LASSO** (Least Absolute Shrinkage and Selection Operator).\n\nLASSO fungerer som vanlig regresjon, men legger til en \"straff\" for store koeffisienter. Resultatet er at noen koeffisienter krympes mot null, og noen settes til nøyaktig null. Det betyr at LASSO automatisk velger bort variable som ikke bidrar nok til prediksjon. Dette er veldig nyttig når man har mange potensielle forklaringsvariable.\n\nVi viser ikke koden for LASSO her, men pakken `glmnet` er standardverktøyet i R. Poenget er at dette er et naturlig neste steg etter at man har forstått prediksjon med vanlig regresjon.\n\n## Klassifisering\nSå langt har vi predikert en kontinuerlig variabel (timelønn). Men ofte vil vi predikere en *kategorisk* variabel. For eksempel: vil en person bli arbeidsledig eller ikke? Er en e-post spam eller ikke? Dette kalles *klassifisering*.\n\nFor klassifisering bruker vi gjerne logistisk regresjon (som vi har sett i et annet kapittel) i stedet for lineær regresjon. Evalueringsmålene er da litt annerledes: i stedet for RMSE ser vi på *andelen riktig klassifiserte* (accuracy) og andre mål som presisjon og recall.\n\n## Når er prediksjon nyttig i samfunnsvitenskap?\nSelv om samfunnsvitenskap tradisjonelt er mest opptatt av forklaring, er det flere områder der prediksjon er sentralt:\n\n- **Risikoscoring**: Identifisere individer med høy risiko for f.eks. tilbakefall til kriminalitet, frafall fra skolen, eller helseproblemer\n- **Klassifisering av tekst**: Automatisk kategorisering av store mengder tekst, f.eks. avisartikler eller stortingsdebatter\n- **Prognoser**: Forutsi utvikling i arbeidsledighet, kriminalitet eller demografiske trender\n- **Variabelseleksjon**: Bruke maskinlæring til å identifisere hvilke variable som er viktigst, som utgangspunkt for videre analyse\n\nDet er verdt å merke seg at mange av maskinlæringsmetodene (tilfeldige skoger, nevrale nettverk osv.) bygger på de samme grunnprinsippene vi har gjennomgått her: dele opp data, evaluere prediksjonsevne, og balansere modellkompleksitet mot overtilpasning.\n\n## Videre lesning\nDette kapittelet har gitt en helt grunnleggende smakebit på prediksjon og maskinlæring. Temaet er svært omfattende, og vi har bare skrapt i overflaten. For de som vil lære mer er [SOS2901](https://www.uio.no/studier/emner/sv/iss/SOS2901/index.html) et introduksjonskurs i maskinlæring for samfunnsvitere ved UiO som tar utgangspunkt i nettopp disse konseptene. En god bok for videre lesning er *An Introduction to Statistical Learning* av James, Witten, Hastie og Tibshirani, som også er tilgjengelig gratis på nett.\n",
    "supporting": [
      "prediksjon_ml_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}