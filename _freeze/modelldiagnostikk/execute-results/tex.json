{
  "hash": "a6da352cd17ff3b9a8a47210f78d844c",
  "result": {
    "engine": "knitr",
    "markdown": "# Modelldiagnostikk\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(haven)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\nNår vi estimerer en regresjonsmodell gjør vi en del antakelser om dataene. Disse antakelsene er ikke bare formaliteter -- de har betydning for om vi kan stole på resultatene. Modelldiagnostikk handler om å sjekke om disse antakelsene holder rimelig godt. Heldigvis finnes det enkle grafiske verktøy og tester som gjør dette ganske oversiktlig.\n\nVi bruker en enkel regresjonsmodell som utgangspunkt for diagnostikken. Her predikerer vi timelønn med alder og kjønn:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- lm(time89 ~ age + female, data = abu89)\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = time89 ~ age + female, data = abu89)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-72.37 -17.12  -4.90  10.99 247.94 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  81.10147    1.58497   51.17   <2e-16 ***\nage           0.47380    0.03684   12.86   <2e-16 ***\nfemale      -20.62511    0.91186  -22.62   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.89 on 3756 degrees of freedom\nMultiple R-squared:  0.1539,\tAdjusted R-squared:  0.1535 \nF-statistic: 341.7 on 2 and 3756 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n## Hva er det vi sjekker?\n\nDe viktigste antakelsene i lineær regresjon er:\n\n1. **Linearitet**: Sammenhengen mellom forklaringsvariable og utfallsvariabel er tilnærmet lineær.\n2. **Normalfordelte residualer**: Residualene (avvikene fra regresjonslinjen) er tilnærmet normalfordelt.\n3. **Homoskedastisitet**: Variansen i residualene er omtrent lik for alle verdier av forklaringsvariablene.\n4. **Ingen ekstreme observasjoner** som alene driver resultatene.\n5. **Ingen alvorlig multikollinearitet**: Forklaringsvariablene er ikke for sterkt korrelert med hverandre.\n\nIngen av disse trenger å holde *perfekt*. Regresjon er ganske robust, og poenget er å avdekke grove brudd som kan påvirke konklusjonene.\n\n\n## Residualplot: Residualer mot predikerte verdier\n\nDet mest grunnleggende diagnostiske plottet er å sette residualene opp mot de predikerte (fitted) verdiene. Hvis alt er som det skal, vil punktene ligge tilfeldig spredt rundt null uten noe tydelig mønster.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabu89 <- abu89 %>%\n  mutate(fitted_val = fitted(mod1),\n         resid_val  = residuals(mod1))\n\nggplot(abu89, aes(x = fitted_val, y = resid_val)) +\n  geom_point(alpha = .2) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  labs(x = \"Predikerte verdier\", y = \"Residualer\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modelldiagnostikk_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nHer ser vi etter systematiske mønstre. Hvis punktene danner en trakt (vifteform), tyder det på heteroskedastisitet. Hvis det er en kurve, kan det tyde på at sammenhengen ikke er lineær. I dette tilfellet ser vi at variansen ser ut til å øke noe med predikerte verdier, og det er noen observasjoner med veldig store residualer.\n\n\n## QQ-plot for normalitet\n\nEt QQ-plot (quantile-quantile plot) sammenligner fordelingen av residualene med en teoretisk normalfordeling. Hvis residualene er normalfordelt, vil punktene ligge omtrent langs en rett linje.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(abu89, aes(sample = resid_val)) +\n  stat_qq(alpha = .2) +\n  stat_qq_line(col = \"red\") +\n  labs(x = \"Teoretiske kvantiler\", y = \"Observerte kvantiler\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modelldiagnostikk_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nHer ser vi at punktene følger linjen rimelig bra i midten, men avviker i halene. Det betyr at fordelingen har tyngre haler enn normalfordelingen. Med store utvalg er dette sjelden et stort problem for estimatene, men det er greit å vite om.\n\n\n## De fire standard diagnostikkplottene\n\nR har en innebygd funksjon som gir fire diagnostiske plot samtidig. Man bruker bare `plot()` på et `lm`-objekt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(mod1)\n```\n\n::: {.cell-output-display}\n![](modelldiagnostikk_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n```\n:::\n\n\nDisse fire plottene viser:\n\n1. **Residuals vs Fitted**: Sjekker linearitet og homoskedastisitet (det vi allerede har sett på).\n2. **Normal Q-Q**: Sjekker normalitet i residualene.\n3. **Scale-Location**: Sjekker homoskedastisitet. Linjen bør være tilnærmet flat.\n4. **Residuals vs Leverage**: Identifiserer innflytelsesrike observasjoner.\n\nLegg merke til at R merker noen observasjoner med radnummer. Det er de mest avvikende observasjonene som du kanskje bør se nærmere på.\n\n\n## Heteroskedastisitet\n\nHeteroskedastisitet betyr at variansen i residualene varierer systematisk. Det påvirker ikke selve estimatene, men det gjør at standardfeilene kan bli feil -- og dermed også p-verdier og konfidensintervaller.\n\nVi har allerede sett visuelt etter dette i residualplottet. Man kan også bruke en formell test. Breusch-Pagan-testen sjekker om variansen i residualene korrelerer med de predikerte verdiene:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\nbptest(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  mod1\nBP = 30.972, df = 2, p-value = 1.882e-07\n```\n\n\n:::\n:::\n\n\nEn lav p-verdi (under 0.05) tyder på at heteroskedastisitet er til stede. Men husk at med store utvalg vil selv små avvik bli statistisk signifikante, så det visuelle inntrykket fra residualplottet er vel så viktig.\n\n\n## Innflytelsesrike observasjoner og Cooks avstand\n\nNoen enkeltobservasjoner kan ha uforholdsmessig stor innflytelse på regresjonsresultatene. Cooks avstand (Cook's distance) er et samlemål for hvor mye hvert datapunkt påvirker de estimerte koeffisientene. En tommelfingerregel er at verdier over $4/n$ (der $n$ er antall observasjoner) bør undersøkes nærmere.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabu89 <- abu89 %>%\n  mutate(cooks_d = cooks.distance(mod1))\n\nggplot(abu89, aes(x = seq_along(cooks_d), y = cooks_d)) +\n  geom_point(alpha = .3) +\n  geom_hline(yintercept = 4 / nrow(abu89), col = \"red\", linetype = \"dashed\") +\n  labs(x = \"Observasjon\", y = \"Cooks avstand\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modelldiagnostikk_files/figure-pdf/unnamed-chunk-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nPunktene over den røde linjen er observasjoner som har relativt stor innflytelse. Det betyr ikke nødvendigvis at de er feil eller at de bør fjernes, men det er lurt å sjekke hva slags observasjoner det er. I lønnsdata er det gjerne folk med uvanlig høy inntekt som trekker resultatene.\n\n\n## Multikollinearitet og VIF\n\nMultikollinearitet oppstår når forklaringsvariablene er sterkt korrelert med hverandre. Det gjør at det blir vanskelig å skille effektene fra hverandre, og standardfeilene blåses opp.\n\nVIF (Variance Inflation Factor) måler dette. En VIF på 1 betyr ingen korrelasjon med andre forklaringsvariable. Tommelfingerregler varierer, men VIF over 5 gir grunn til bekymring, og over 10 er et klart problem.\n\nLa oss utvide modellen med noen flere variable og sjekke VIF:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 <- lm(time89 ~ age + female + ed, data = abu89)\n\nlibrary(car)\nvif(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     age   female       ed \n1.004787 1.015293 1.019662 \n```\n\n\n:::\n:::\n\n\nHer ser vi at VIF-verdiene er lave, noe som betyr at multikollinearitet ikke er et problem i denne modellen. Hvis du hadde inkludert variable som i praksis måler det samme, ville VIF blitt høyere.\n\n\n## Rask diagnostikk med `performance`-pakken\n\nPakken {performance} har en veldig nyttig funksjon som gjør mye av diagnostikken i ett steg. Funksjonen `check_model()` lager et sett med diagnostiske plot som dekker de viktigste antakelsene.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_model(mod2)\n```\n\n::: {.cell-output-display}\n![](modelldiagnostikk_files/figure-pdf/unnamed-chunk-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nDette gir deg et samlet bilde av modellens egenskaper, inkludert linearitet, homoskedastisitet, normalitet, innflytelsesrike observasjoner og multikollinearitet. Det er en fin snarvei for en rask sjekk.\n\nDu kan også få en tekstbasert oppsummering:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(mod2, check = \"all\") |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Length Class                Mode   \nVIF            3   check_collinearity   list   \nQQ             2   data.frame           list   \nNORM           3   data.frame           list   \nNCV            2   data.frame           list   \nHOMOGENEITY    2   data.frame           list   \nOUTLIERS    3759   check_outliers       logical\nINFLUENTIAL    7   data.frame           list   \nPP_CHECK      51   performance_pp_check list   \n```\n\n\n:::\n:::\n\n\n\n## Hva gjør man hvis antakelsene brytes?\n\nI praksis er det sjelden at alle antakelser holder perfekt. Her er noen praktiske råd:\n\n**Heteroskedastisitet**: Bruk robuste standardfeil. Det endrer ikke estimatene, men gir korrekte standardfeil og p-verdier. I R kan du bruke pakken {sandwich} sammen med {lmtest}, eller rapportere robuste standardfeil direkte via {modelsummary}.\n\n**Ikke-normalfordelte residualer**: Med store utvalg (over noen hundre observasjoner) er dette sjelden et problem for estimatene eller standardfeilene takket være sentralgrenseteoremet. Men det kan tyde på at modellen mangler noe viktig.\n\n**Innflytelsesrike observasjoner**: Sjekk hva slags observasjoner det er. Kjør modellen med og uten disse observasjonene. Hvis resultatene endrer seg mye, bør du diskutere dette.\n\n**Ikke-linearitet**: Vurder å transformere variablene (f.eks. logaritme) eller inkludere polynomiske ledd.\n\n**Multikollinearitet**: Vurder om du trenger alle variablene i modellen. Kanskje noen av dem måler det samme og du kan droppe en av dem.\n\nDet viktigste er at du *faktisk sjekker* antakelsene. Det er mye bedre å gjøre en enkel sjekk og diskutere eventuelle problemer enn å ignorere diagnostikk fullstendig. Og husk: ingen modell er perfekt. Poenget er at den er nyttig nok til å fortelle oss noe meningsfullt om dataene.\n",
    "supporting": [
      "modelldiagnostikk_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}