[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "",
    "text": "Forord\nDenne boken er ment som en praktisk innføring i bruk av R til dataanalyse for studenter i samfunnsvitenskap. Fokuset er på hvordan man gjør dataanalyse i R – fra innlesning av data, via datahåndtering og deskriptiv analyse, til statistisk modellering og visualisering.\nBoken er ment å komplettere lærebøker i statistikk og metode, ikke erstatte dem. Statistiske begreper forklares når det er nødvendig for å forstå koden, men den grundige teoretiske behandlingen av statistikk overlates til andre lærebøker. Unntaket er kapittelet om design, tolkning og teori (Del IX), som tar opp noen viktige perspektiver på dataanalyse som sjelden presenteres samlet i andre lærebøker.\nTeksten er ment som en ganske grunnleggende innføring for praktikere. Fokuset er å vise løsninger som fungerer uten for mye mikk-makk. Det er alltid flere måter å gjøre ting på, men hovedteksten dekker anbefalte løsninger basert på hensyn som effektivitet, konsistens og funksjonalitet. Boken kan også brukes som oppslagsverk.\nGjennom boken brukes varierte datasett fra ulike R-pakker, med vekt på data som er relevante for samfunnsvitenskap.",
    "crumbs": [
      "Forord"
    ]
  },
  {
    "objectID": "index.html#hvorfor-r",
    "href": "index.html#hvorfor-r",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "Hvorfor R?",
    "text": "Hvorfor R?\nR er et programmeringsspråk laget spesielt for statistikk og dataanalyse. Det er gratis, åpen kildekode, og har et enormt økosystem av pakker for alt fra enkel deskriptiv statistikk til avansert maskinlæring og kartproduksjon.\nEn av de store forskjellene fra SPSS og Stata er at R ikke har muligheten for menybaserte analyser. Du kan altså ikke gjøre analyser med “pek-og-klikk”. R er et programmeringsspråk, og det er viktig å lære å skrive kode for både databehandling og analyse. Dette kan virke krevende i starten, men gir betydelige fordeler: koden dokumenterer nøyaktig hva som er gjort, analyser kan reproduseres, og komplekse operasjoner kan automatiseres.",
    "crumbs": [
      "Forord"
    ]
  },
  {
    "objectID": "index.html#pakker-som-brukes",
    "href": "index.html#pakker-som-brukes",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "Pakker som brukes",
    "text": "Pakker som brukes\nBoken bruker en rekke R-pakker. Tabellen nedenfor genereres automatisk ved å skanne alle kapittelfiler, og oppdateres hvis det gjøres endringer i prosjektet.\n\n\n\nR-pakker brukt i prosjektet (n = 44)\n\n\nPakke\nVersjon\n\n\n\n\narrow\n23.0.1.1\n\n\ncar\n3.1.3\n\n\nchattr\n0.3.1\n\n\ndata.table\n1.17.8\n\n\nDBI\n1.2.3\n\n\ndbplyr\n2.5.2\n\n\ndplyr\n1.2.0\n\n\nequatiomatic\n0.4.4\n\n\nfixest\n0.13.2\n\n\nggdag\n0.2.13\n\n\nggforce\n0.5.0\n\n\nggraph\n2.2.2\n\n\nggridges\n0.5.7\n\n\ngt\n1.3.0\n\n\ngtsummary\n2.5.0\n\n\nhaven\n2.5.5\n\n\nhere\n1.0.2\n\n\nigraph\n2.2.2\n\n\nknitr\n1.51\n\n\nlabelled\n2.16.0\n\n\nleaflet\n2.2.3\n\n\nlmtest\n0.9.40\n\n\nlobstr\n1.1.2\n\n\nmarginaleffects\n0.32.0\n\n\nmemisc\n0.99.31.8.3\n\n\nmodelsummary\n2.6.0\n\n\nnaniar\n1.1.0\n\n\nopenxlsx\n4.2.8.1\n\n\nperformance\n0.16.0\n\n\nPxWebApiData\n1.9.0\n\n\nreadxl\n1.4.5\n\n\nremotes\n2.5.0\n\n\nrenv\n1.1.7\n\n\nRSQLite\n2.4.6\n\n\nRStata\n1.1.2\n\n\nrvest\n1.0.5\n\n\nsandwich\n3.1.1\n\n\nscales\n1.4.0\n\n\nsf\n1.0.22\n\n\nstargazer\n5.2.3\n\n\ntidyr\n1.3.1\n\n\ntidyverse\n2.0.0\n\n\nwooldridge\n1.4.4\n\n\nwritexl\n1.5.4",
    "crumbs": [
      "Forord"
    ]
  },
  {
    "objectID": "index.html#bokens-oppbygning",
    "href": "index.html#bokens-oppbygning",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "Bokens oppbygning",
    "text": "Bokens oppbygning\nBoken er organisert i ni deler:\n\nDel I hjelper deg med å komme igang med R og RStudio.\nDel II dekker innlesning av data fra ulike formater og kilder, inkludert Stata, SPSS, Excel og SSBs statistikkbank.\nDel III handler om datahåndtering: tidyverse-verb, omkoding, manglende verdier, kobling av datasett og håndtering av store data.\nDel IV dekker deskriptiv analyse med grafikk og tabeller.\nDel V er den mest omfattende delen og dekker statistisk modellering: lineær regresjon med utvidelser (interaksjoner, splines, DiD, RD), diagnostikk, logistisk regresjon, marginaleffekter, og en introduksjon til prediksjon og maskinlæring.\nDel VI handler om statistisk tolkning: standardfeil, konfidensintervaller og p-verdier.\nDel VII viser hvordan man plasserer data på kart.\nDel VIII gir en enkel introduksjon til nettverksanalyse.\nDel IX tar opp viktige perspektiver på design, tolkning, teori og reproduserbarhet.",
    "crumbs": [
      "Forord"
    ]
  },
  {
    "objectID": "installering.html",
    "href": "installering.html",
    "title": "1  Installere R og Rstudio",
    "section": "",
    "text": "1.1 Installasjon\nVi forutsetter grunnleggende kunnskap til bruk av datamaskiner, og hvis du oppdager at det er tekniske ting du ikke får til forutsetter vi at du lærer deg det. Det går også an å spørres seminarleder om hjelp, men gjør det unna tidlig i semesteret. Her er noe av det vi forutsetter:\nLaste ned og installere programmer på datamaskinen Lage mapper og mappestruktur på lokal maskin, og holde oversikt over filer på din datamaskin Laste ned en fil direkte til en mappe uten å åpne, herunder lokalisere download-mappen\nOBS! Det er mange csv-filer tilknyttet oppgaver i læreboken. Sørg for å laste ned filene uten at de først åpnes i Excel med en gang. Grunnen er at selv om det stort sett går greit, er Excel tilbøyelig til å tenke litt mye selv og kan finne på å forandre datasettet. (Hvis dette skjer på eksamen er du i trøbbel, så unngå det!).\nInstaller nyeste versjon av R herfra: https://cran.uib.no/ Du trenger det som heter «base» når man installerer for første gang. Hvis du har R installert på maskinen din fra før, sørg for at du har siste versjon installert. Siste versjon er 4.1.2. Versjon etter 4.0 bør gå bra, men tidligere versjoner vil kunne gi problemer. Installer nyeste versjon av RStudio (gratisversjon) herfra: https://rstudio.com/products/rstudio/download/ Viktig: du må installere R før du installerer Rstudio for Rstudio finner R på din datamaskin og vil gi feilmelding hvis den ikke finner R. Hvis du har en eldre datamaskin og du får feilmelding ved installasjon av RStudio kan du vurdere å installere forrige versjon av Rstudio herfra: https://www.rstudio.com/products/rstudio/older-versions/\nR og Rstudio er to programmer er integrert i hverandre og du åpner heretter R ved å åpne RStudio. Merk: R er navnet på programmeringsspråket og programmet som gjør selve utregningene. Det kjører fra en kommandolinje og er ikke veldig brukervennlig alene. RStudio er et “integrated development environment” (IDE) til R. Det integrerer R med en konsoll, grafikk-vindu og en del andre nyttige ting. Det gjør det lettere å bruke R.\nDet finnes også andre IDE for R, men vi skal bruke RStudio gjennomgående på dette kurset. (RStudio inneholder også masse annen funksjonalitet vi ikke trenger til dette kurset).\nDu skal også installere noen R-pakker. Det er omtalt i et annet kapittel med oversikt over hva det er og hvilke du trenger.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "installering.html#installasjon",
    "href": "installering.html#installasjon",
    "title": "1  Installere R og Rstudio",
    "section": "",
    "text": "1.1.1 Ikke alle feilmeldinger er like nøye\nMange av dere vil få en feilmelding av denne typen når dere starter R:\n\nError in file.exists(pythonPath) : \n  file name conversion problem -- name too long?\n\nIkke bry dere om akkurat den. Det spiller ingen rolle.\n\n\n1.1.2 Spesielt om Windows-maskiner: installer Rtools\nHvis du jobber på en Windows-maskin må du også installere Rtools herfra: https://cran.r-project.org/bin/windows/Rtools/\n\n\n1.1.3 Spesielt om Mac-maskiner\nR skal normalt installere på Mac uten problemer. Noen har fått beskjed om at de også trenger å installere XQuartz eller Xcode. I så fall installerer du de også. Se mer informasjon her: https://cran.r-project.org/bin/macosx/tools/\n\n\n1.1.4 Spesielt om Linux-maskiner\nHar du Linux vet du antakelig hva du driver med. Siste versjon av R og Rstudio kan antakeligvis installeres fra distroens repository.\n\n\n1.1.5 Spesielt om Chromebook\nChromebook kjører et annet operativsystem og R vil ikke uten videre fungere. Derimot kan man på de fleste slike maskiner åpne opp for å kjøre Linux og da kan man installere linux-versjon av R og Rstudio. https://blog.sellorm.com/2018/12/20/installing-r-and-rstudio-on-a-chromebook/ Eller se nedenfor hvordan du kan kjøre R i skyen.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "installering.html#hvis-du-har-problemer-med-installasjon-som-vi-ikke-får-løst",
    "href": "installering.html#hvis-du-har-problemer-med-installasjon-som-vi-ikke-får-løst",
    "title": "1  Installere R og Rstudio",
    "section": "1.2 Hvis du har problemer med installasjon som vi ikke får løst",
    "text": "1.2 Hvis du har problemer med installasjon som vi ikke får løst\n\n1.2.1 Rstudio workbench i UiO-skyen\nHvis du opplever uløselige problemer med å kjøre R og Rstudio på din datamaskin, så finnes det en krise-løsning. Rstudio har også en versjon som kjører i skyen via nettleser. UiO har en slik versjon installert på sine servere som vi kan bruke. Du logger da inn på Rstudio Workbench med ditt Feide brukernavn og passord. (Det er sendt inn beskjed om at alle på SOS4020 skal ha tilgang, og håper det er i orden nå eller veldig snart).\nRstudio workbench fungerer på samme måte som Rstudio ellers, men du kan ikke installere pakker selv. Det viktigste er tilgjengelig allerede, så det burde gå fint. I fanen “Files” kan du lage en mappestruktur og laste opp/ned filer etter behov.\nOBS! Workbench-løsningen har et helt trivilet sikkerhetsnivå for data. Den er kun godkjent for å bruke grønne data. Det betyr at du ikke kan jobbe med data som ikke er åpne med denne løsningen.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "installering.html#oppsett-og-forberedelser",
    "href": "installering.html#oppsett-og-forberedelser",
    "title": "1  Installere R og Rstudio",
    "section": "1.3 Oppsett og forberedelser",
    "text": "1.3 Oppsett og forberedelser\nDette oppsettet gjelder både hvis du har en lokal installasjon og for skyløsninger. Utseendet spiller ingen rolle, og R kan også fungere uten å opprette «projects» som beskrevet her. Men det er lettere å bruke og du har bedre orden hvis du gjør dette.\n\n1.3.1 Utseende i Rstudio\nEndre gjerne på oppsettet i RStudio ved å gå til Tools og deretter Global options, så Pane Layout.\n\nDet spiller ingen rolle for funksjonaliteten hvor du har hvilken fane, men her er et forslag.\n\nDette kan også endres senere og har altså bare med hvordan Rstudio ser ut.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "installering.html#rstudio-projects",
    "href": "installering.html#rstudio-projects",
    "title": "1  Installere R og Rstudio",
    "section": "1.4 Rstudio projects",
    "text": "1.4 Rstudio projects\nNår du åpner Rstudio skal du alltid åpne som «project» (se video med instruksjon og i R4DS (Wickham and Grolemund (2017))). Arbeidsområdet er da definert og du kan åpne data ved å bruke relative filbaner, dvs. at du oppgir hvor dataene ligger med utgangspunkt i prosjektmappen. Se kursvideo og instruksjoner i R4DS og gjør følgende:\nOpprettet mappestruktur med prosjektmappen som øverste nivå og egne undermapper for data, script, og output.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "href": "installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "title": "1  Installere R og Rstudio",
    "section": "1.5 Åpne RStudio og opprett et .Rproject",
    "text": "1.5 Åpne RStudio og opprett et .Rproject\n\nBruk funksjonen getwd() og se at du har riktig filbane til arbeidsområdet. Hvis du ikke er sikker på hva det betyr, må du spørre noen eller finne det ut på annen måte!\nDet første dere må gjøre er å sørge for å ha orden i datasett, script og annet på din egen datamaskin. Å f.eks. lagre alle filer på skrivebordet bør du aldri gjøre, og særlig ikke i dette kurset eller når man jobber med større prosjekter og datasett.\nFor dette kurset skal du ha en mappestruktur med en hovedmappe for dette kurset og tilhørende undermapper. Det spiller ingen rolle hvor på datamaskinen du legger disse mappene, men du må vite hvor det er. Lag første en mappe med et hensiktsmessig navn for kurset, og innunder denne mappen lager du tre andre mapper med navnene data, output og script. Du kan ha andre mapper i tillegg ved behov. Det kan se slik ut:\n\nDu skal opprette et Rstudio-prosjekt for hele kurset. Dette er beskrevet nærmere i R4DS i kapittel 6. Når du har åpnet RStudio skal du aller først klikke New Project.\n\nDeretter klikker du du «Existing Directory»\n\nKlikk «Browse» og bla deg så frem til mappen du har laget for dette kurset.\nRStudio-prosjektet ligger så i den mappen du har valgt. I filutforsker på datamaskinen vil nå disse to filene dukke opp:\n\nFor å starte R videre i dette kurset skal du dobbeltklikke det første ikonet, så vil R åpne seg med riktig arbeidsområde. Mappen .Rproj.user skal du ikke røre. I RStudio vil du se at prosjektet er åpnet ved at det i øvre høyre hjørne er dette ikonet:\n\nEn stor fordel med å bruke projects er at du kan flytte hele mappen til et annet sted, eller til en annen datamaskin og alt vil fungere akkurat som før. Hvis du bruker en skytjeneste (OneDrive, Dropbox etc) vil du kunne åpne Rstudio projects på samme måte fra flere maskiner.\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installere R og Rstudio</span>"
    ]
  },
  {
    "objectID": "intro_R.html",
    "href": "intro_R.html",
    "title": "2  En veldig kjapp intro til R",
    "section": "",
    "text": "2.0.1 Et par hurtigtaster\nFør vi setter igang trengs det en kort introduksjon til noe grunnleggende om hvordan R fungerer. Så lærer man mer underveis, og et senere kapittel går grundigere inn i datahåndtering og omkoding av variable. En grundigere gjennomgang av R finner du i Wickham and Grolemund (2017).\nDu skriver altså kode i script-vinduet i RStudio. For å kjøre koden kan du klikke på “Run” opp i høyre hjørne av script-vinduet. Det kan være lurt å markere det du vil kjøre før du klikker “Run” slik at du bare kjører akkurat det du har tenkt til. Man blir fort lei av å klikke på den måten. En hurtigtast er Ctlr + Enter som altså gjør det samme.\nDu vil komme til å skrive %&gt;% ganske mange ganger etterhvert. Det er litt styrete å skrive pga hvordan tastene ligger på tastaturet ditt. En hurtigtast for dette tegnet er Ctrl + Shift + M.\nDet er mange andre hurtigtaster tilgjengelig, men det er disse to du vil ha mest bruk for.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "intro_R.html#objektorientert",
    "href": "intro_R.html#objektorientert",
    "title": "2  En veldig kjapp intro til R",
    "section": "2.1 Objektorientert",
    "text": "2.1 Objektorientert\nR er bygd opp rundt å bruke “objekter” i den forstand at alt man jobber med (typisk: datasett) ligger i objekter.\nDu kan tenke på objekter som en boks som det står et navn på. Ofte er det bare et datasett oppi boksen, men det kan også være flere ting. Det finnes derfor flere typer objekter. Vi skal primært jobbe med datasett, og slike objekter er av typen “data.frame”. De kan også være av typen “tibble”, men det er for alle praktiske formål på dette nivået akkurat det samme som “data.frame”. Men objekter kan også inneholde resultater fra analyser, som f.eks. grafikk, tabeller eller regresjonsresultater. Man kan også legge enkelttall, vektorer og tekststrenger i objekter.\nNoen ganger vil et objekt inneholde flere forskjellige ting. Et eksempel er resultat fra regresjonsmodeller som både vil inneholde koeffisienter, standardfeil, residualer, en del statistikker, men også selve datasettet. Men for å se på output er det funksjoner som trekker ut akkurat det vi trenger, så du trenger sjelden forholde deg til hvordan et slikt objekt er bygd opp.\nPoenget er: Alt du jobber med i R er objekter. Alle objekter har et navn som du velger selv. Du kan legge hva som helst i et objekt. Du kan ikke ha to objekter med samme navn, og hvis du lager et objekt med et navn som eksisterer fra før overskriver du det gamle objektet.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "intro_R.html#funksjoner",
    "href": "intro_R.html#funksjoner",
    "title": "2  En veldig kjapp intro til R",
    "section": "2.2 Funksjoner",
    "text": "2.2 Funksjoner\nAlt man gjør i R gjøres med “funksjoner”, og man bruker funksjonene på objekter eller deler av objekter. Funksjonen har et navn etterfulgt av en parentes slik som f.eks. dinfunksjon(...). Du kan tenke på funksjoner som en liten maskin der du putter noe inn, og så kommer noe annet ut. Det du putter inn skal stå inni parentesen. Det som kommer ut kan du enten legge i et eget objekt eller la det skrives til output-vinduet.\nDet du legger inn i funksjonen – altså inni parentesen – kalles “argumenter”. Hvert argument har et navn og du skal normalt oppgi i hvert fall hvilket datasett funksjonen skal brukes på. Argumentet for data er nettopp data = og så oppgis navnet på det objektet dataene ligger i.\nI tillegg kan det være en rekke andre argumenter. Et poeng er viktig å presisere: argumentene har også en forventet rekkefølge. Man kan også oppgi argumentene uten å angi navnet hvis de kommer i riktig rekkefølge. Man kan godt oppgi argumentene i annen rekkefølge, men da er man nødt til å bruke argumentnavnet slik at R forstår hva som er hva.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "intro_R.html#r-pakker",
    "href": "intro_R.html#r-pakker",
    "title": "2  En veldig kjapp intro til R",
    "section": "2.3 R-pakker",
    "text": "2.3 R-pakker\nNår man installerer R har man svært mye funksjonalitet tilgjengelig uten videre. Dette kalles “base R”. Men R er i praksis basert på å bruke såkalte “pakker”. Dette er funksjoner som utvider R sin funksjonalitet.\nR-pakker er et helt økosystem av funksjonalitet, og det finnes mange tusen R-pakker tilgjengelig på en server som heter CRAN. For nye brukere av R vil dette fremstå som ganske kaotisk, men du får beskjed om hvilke pakker du trenger fortløpende.\nFor å installere en pakke må du vite hva pakken heter og datamaskinen din må være koblet til internett:\n\ninstall.packages(\"pakkenavn\")\n\nVanlige grunner til feilmeldinger ved installering:\n\nDu har stavet navnet på pakken feil. Pass på små og store bokstaver.\nPakken krever at du har noen andre pakker installert fra før. Installer disse først og prøv igjen.\nNoen andre pakker trenger oppdatering. Oppdater alle pakker og prøv på nytt.\nDin R-installasjon må oppdateres.\n\nNår en pakke er installert må du “laste” den for at funksjonene skal være tilgjengelig i din R-sesjon. Hvis du restarter R, så må du laste pakkene på nytt.\n\nlibrary(pakkenavn)\n\nFor denne boken trenger du følgende pakker:\n\ninstall.packages( c(\"tidyverse\", \"haven\", \"gtsummary\", \"gt\", \"modelsummary\",\n                    \"labelled\", \"marginaleffects\",\n                    \"causaldata\", \"gapminder\", \"palmerpenguins\",\n                    \"sf\", \"tmap\", \"spData\",\n                    \"tidygraph\", \"ggraph\")\n            )\n\nInstallering av pakker gjør du bare én gang. Du må derimot laste pakker hver gang du starter R på nytt.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "intro_R.html#r-dialekter",
    "href": "intro_R.html#r-dialekter",
    "title": "2  En veldig kjapp intro til R",
    "section": "2.4 R-dialekter",
    "text": "2.4 R-dialekter\nDe funksjonene som følger med grunnleggende installasjon av R kalles “base R”. Man kan gjøre svært mye med bare base R. Men noen R-pakker inneholder ikke bare enkeltfunksjoner, men nesten et helt programmeringsspråk i seg selv. Det er lurt å holde seg innenfor samme “dialekt” da man ellers kan bli veldig forvirret. I denne boken bruker vi dialekten tidyverse konsekvent.\nMerk at det finnes andre dialekter som er spesialiserte for spesifikke formål. Et eksempel er {data.table} som er lynrask for store datasett (se eget kapittel). Dette gjør at det kan være vanskelig å søke på nettet etter løsninger fordi du kan få svar i en annen dialekt enn den du kan.\n\n2.4.1 Tidyverse\nNår man laster pakken {tidyverse} laster man egentlig flere pakker som også kan lastes individuelt. “Tidy” betyr “ryddig” og hensikten er et språk som er så ryddig og logisk som mulig. Full oversikt over pakkene som inngår i Tidyverse finner du på deres hjemmeside.\nGrunnleggende datahåndtering med tidyverse dekkes i et eget kapittel (Del III). Grafikk med ggplot dekkes i Del IV. Her introduseres bare det aller mest grunnleggende.\n\n\n2.4.2 Pipe: %&gt;%\nEt viktig konsept i tidyverse er “pipen” %&gt;% (hurtigtast: Ctrl + Shift + M). Den betyr “gjør deretter”. Du kan binde sammen flere operasjoner i en arbeidsflyt:\n\ndinedata %&gt;%\n  mutate(ny_variabel = gammel * 2) %&gt;%\n  filter(gruppe == \"a\")\n\nDette leses som: “start med dinedata, lag deretter en ny variabel, filtrer deretter på gruppe a.”\n\n\n2.4.3 Logiske operatorer\nI mange sammenhenger setter man hvis-krav. Her er grunnleggende logiske operatorer:\n\n\n\nUttrykk\nKode\n\n\n\n\ner lik\n==\n\n\ner ikke lik\n!=\n\n\nog\n&\n\n\neller\n|\n\n\nstørre/mindre enn\n&gt; eller &lt;\n\n\nstørre/mindre enn eller er lik\n&lt;= eller &gt;=\n\n\n\n\n\n2.4.4 Lagre data\nDu kan som et utgangspunkt tenke at du ikke skal lagre bearbeidede data på disk. Scriptet ditt starter med å lese inn de originale dataene og gjør alt du trenger fra start til slutt. På den måten har du reproduserbare script.\nHvis du likevel trenger å lagre data til disk, bruk .rds-formatet:\n\nsaveRDS(dinedata, \"data/dinedata_temp.rds\")\n\nFor permanent lagring og deling av data, bruk csv-format:\n\nwrite_csv(dinedata, \"data/dinedata_temp.csv\")",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "intro_R.html#hjelpfiler-og-dokumentasjon",
    "href": "intro_R.html#hjelpfiler-og-dokumentasjon",
    "title": "2  En veldig kjapp intro til R",
    "section": "2.5 Hjelpfiler og dokumentasjon",
    "text": "2.5 Hjelpfiler og dokumentasjon\nDokumentasjonen i R åpnes med ? foran funksjonsnavnet, f.eks. ?read.csv. Hjelpfiler har en fast struktur: Usage viser syntaks med forvalgsverdier, Arguments forklarer hvert argument, Examples viser kodeeksempler.\nMange pakker har også “vignetter” som gir mer utfyllende forklaringer. Disse finnes på pakkens CRAN-side eller på egne nettsider.\n\n2.5.1 Bruke pakker uten å laste dem\nEn funksjon fra en spesifikk pakke kan angis med pakkenavn::funksjon(). Dette er nyttig hvis det er navnekonflikt mellom pakker:\n\ndplyr::summarise(dinedata, antall = n(), snitt = mean(varA))\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>En veldig kjapp intro til R</span>"
    ]
  },
  {
    "objectID": "ki_koding.html",
    "href": "ki_koding.html",
    "title": "3  Bruk KI som kodehjelp",
    "section": "",
    "text": "3.1 Hva er en KI-kodehjelp?\nKI-verktøy (kunstig intelligens) har blitt svært gode til å skrive kode i mange språk, deriblant R. Du kan bruke dem til å forstå kode, finne feil, og generere nye løsninger. Det finnes mange slike verktøy, blant annet ChatGPT, Claude, GitHub Copilot og Gemini. Prinsippene i dette kapittelet gjelder uansett hvilket verktøy du bruker, og vi omtaler dem samlet som KI-verktøy.\nMen la det være helt klart: KI-verktøy gjør ikke at du kan hoppe over å lære å kode selv. Du må forstå koden for å vite om den gjør det du faktisk ønsker, og du må kunne vurdere om resultatene er riktige. KI er et hjelpemiddel – ikke en erstatning for forståelse.\nMange universiteter og høyskoler har egne retningslinjer for bruk av KI-verktøy. Ved UiO finnes det for eksempel en egen tjeneste kalt GPT UiO som er tilpasset personvernkravene ved universitetet. Sjekk hvilke verktøy som er godkjent ved din institusjon.\nDisse verktøyene utvikler seg raskt. Konkrete funksjoner og grensesnitt kan endres, men prinsippene for hvordan du bruker dem effektivt er de samme.\nMed KI-kodehjelp mener vi verktøy basert på store språkmodeller som du kan kommunisere med via tekst. Du skriver en instruksjon – et prompt – og verktøyet gir deg et svar i form av kode, forklaringer, eller begge deler.\nDet finnes to hovedtyper:\nFor nybegynnere anbefaler vi å starte med et chat-basert verktøy. Det gjør at du ser hele samtalen og kan følge med på hva som skjer. De fleste har gratis versjoner som er mer enn tilstrekkelige for studentbruk.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#hva-er-en-ki-kodehjelp",
    "href": "ki_koding.html#hva-er-en-ki-kodehjelp",
    "title": "3  Bruk KI som kodehjelp",
    "section": "",
    "text": "Chat-baserte verktøy (ChatGPT, Claude, Gemini): Du åpner en nettside, limer inn kode eller skriver et spørsmål, og får svar i en samtale. Dette er den enkleste måten å komme i gang på.\nIntegrerte verktøy (GitHub Copilot, Positron-assistenten): Disse er bygd inn i kodeeditoren din og kan foreslå kode mens du skriver. Det krever litt mer oppsett, men kan være effektivt når du har kommet i gang.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#bruk-ki-til-å-forstå-kode",
    "href": "ki_koding.html#bruk-ki-til-å-forstå-kode",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.2 Bruk KI til å forstå kode",
    "text": "3.2 Bruk KI til å forstå kode\nDet beste stedet å begynne er å bruke KI til å forstå kode du har problemer med. Det er mye mer lærerikt enn å la verktøyet skrive koden for deg.\nFor å få et godt svar bør du spesifisere hva det er du ikke forstår. Si gjerne at du er nybegynner, og at du foretrekker forklaringer som bruker tidyverse. Her er et eksempel på et prompt du kan prøve:\n\nKan du forklare følgende R-kode linje for linje?\nJeg er nybegynner og bruker tidyverse.\n\n  dinedata %&gt;%\n  group_by(gruppe) %&gt;%\n  mutate(antall = n(), gjennomsnitt = mean(varA),\n         avvik = varA - gjennomsnitt) %&gt;%\n  arrange(gruppe, desc(avvik)) %&gt;%\n  filter(row_number() == 1)\n\n\n\n\n\n\n\nEksempel på svar fra KI-verktøy\n\n\n\nDenne koden bruker tidyverse og gjør følgende steg for steg:\n\ndinedata %&gt;% — tar datasettet dinedata og sender det videre med pipe-operatoren (%&gt;%).\ngroup_by(gruppe) — grupperer dataene etter variabelen gruppe. Alle påfølgende operasjoner gjøres innenfor hver gruppe.\nmutate(...) — legger til tre nye kolonner uten å fjerne eksisterende rader:\n\nantall = n() — antall observasjoner i hver gruppe.\ngjennomsnitt = mean(varA) — gjennomsnittet av varA innenfor gruppen.\navvik = varA - gjennomsnitt — hvor mye hver observasjon avviker fra gruppegjennomsnittet.\n\narrange(gruppe, desc(avvik)) — sorterer radene etter gruppe, og innenfor hver gruppe etter avvik i synkende rekkefølge (størst avvik først).\nfilter(row_number() == 1) — beholder bare den første raden i hver gruppe, altså observasjonen med størst avvik fra gjennomsnittet.\n\nResultatet er et datasett med én rad per gruppe: den observasjonen som avviker mest fra gruppens gjennomsnitt.\n\n\nDu vil typisk få en forklaring av hva hver linje gjør. Men husk: du må selv vurdere om forklaringen gir mening i din kontekst. Prøv å kjøre koden selv og se om resultatet stemmer med det verktøyet forklarte.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#bruk-ki-til-feilsøking-debugging",
    "href": "ki_koding.html#bruk-ki-til-feilsøking-debugging",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.3 Bruk KI til feilsøking (debugging)",
    "text": "3.3 Bruk KI til feilsøking (debugging)\nKI-verktøy er også nyttige for å finne feil i kode som ikke fungerer som forventet. For å få et godt svar er det viktig å gi verktøyet god kontekst. Beskriv:\n\nHva du forsøkte å gjøre\nHva du forventet skulle skje\nHva som faktisk skjedde (inkluder gjerne feilmeldingen)\n\nHer er et eksempel:\n\nJeg ønsker å få aggregerte statistikker for et datasett\nmed en linje per gruppe, men resultatet gir en linje\nper observasjon i stedet. Kan du finne feilen?\n\n  dinedata %&gt;%\n  group_by(gruppe) %&gt;%\n  mutate(antall = n(), gjennomsnitt = mean(varA),\n         avvik = varA - gjennomsnitt) %&gt;%\n  arrange(gruppe, desc(avvik)) %&gt;%\n  filter(row_number() == 1)\n\n\n\n\n\n\n\nEksempel på svar fra KI-verktøy\n\n\n\nProblemet er at du bruker mutate(), som legger til nye kolonner men beholder alle radene. For å få én rad per gruppe med aggregerte verdier, bør du bruke summarise() i stedet.\nHer er den korrigerte koden:\ndinedata %&gt;%\n  group_by(gruppe) %&gt;%\n  summarise(antall = n(),\n            gjennomsnitt = mean(varA))\nsummarise() kollapser hver gruppe til én rad og beregner de ønskede statistikkene. mutate() derimot legger til kolonner mens alle opprinnelige rader beholdes, og det er derfor du fikk én linje per observasjon.\n\n\nEt nyttig tips er å lime inn feilmeldinger direkte. KI-verktøy er gode til å tolke R-feilmeldinger og kan ofte forklare hva som gikk galt.\nMerk at verktøyet vil foreslå en løsning, men det er ikke gitt at det forstår problemet ditt korrekt. Løsningen er heller ikke nødvendigvis riktig. Du må alltid teste den foreslåtte løsningen selv og sjekke at den faktisk gir de resultatene du forventer.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#bruk-ki-til-å-generere-kode",
    "href": "ki_koding.html#bruk-ki-til-å-generere-kode",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.4 Bruk KI til å generere kode",
    "text": "3.4 Bruk KI til å generere kode\nDu kan også be KI-verktøy om å skrive helt ny kode for deg. For at dette skal fungere godt, må du ha en klar idé om hva du ønsker. Vær spesifikk om:\n\nHvilke pakker du vil bruke (f.eks. tidyverse, ggplot2)\nHva slags data du har (variabler, typer)\nHva resultatet skal se ut som\n\nHer er et eksempel på et prompt:\n\nLag en ggplot-figur som viser sammenhengen mellom\nvariablene alder og lønn med et scatterplot.\nBruk ulike farger for variabelen kjønn.\nBruk tidyverse og ggplot2. Datasettet heter abu89.\n\n\n\n\n\n\n\nEksempel på svar fra KI-verktøy\n\n\n\nHer er koden for et scatterplot med ulike farger for kjønn:\nlibrary(tidyverse)\n\nggplot(abu89, aes(x = alder, y = lonn, color = kjonn)) +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Alder\", y = \"Lønn\", color = \"Kjønn\") +\n  theme_minimal()\nKoden bruker aes() til å knytte variabler til visuelle egenskaper: x og y for aksene, og color for å gi ulike farger per kjønn. alpha = 0.5 gjør punktene halvt gjennomsiktige, slik at overlappende punkter blir synlige.\n\n\nFørste forsøk er sjelden perfekt. Bruk oppfølgingsspørsmål for å justere: “Kan du legge til en regresjonslinje?”, “Kan du endre til theme_minimal()?”, osv. Det er slik man jobber effektivt med KI-verktøy – som en samtale der du gradvis presiserer hva du vil ha.\nDet viktigste prinsippet: les og forstå hver linje i den genererte koden før du bruker den. Hvis det er noe du ikke forstår, be verktøyet forklare akkurat den delen. Kopier aldri kode blindt inn i analysene dine.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#gi-ki-verktøy-grunnleggende-instruksjoner",
    "href": "ki_koding.html#gi-ki-verktøy-grunnleggende-instruksjoner",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.5 Gi KI-verktøy grunnleggende instruksjoner",
    "text": "3.5 Gi KI-verktøy grunnleggende instruksjoner\nDe fleste KI-verktøy lar deg sette opp faste instruksjoner som gjelder for alle samtaler. I ChatGPT heter dette “Custom Instructions”, i Claude kan du opprette “Projects” med egne instruksjoner, og andre verktøy har tilsvarende løsninger. Konseptet er det samme: du forteller verktøyet hvem du er og hva du foretrekker, slik at du slipper å gjenta deg.\nHer er et eksempel på slike instruksjoner som er tilpasset dette kurset:\n\nJeg er nybegynner i dataanalyse i R innen samfunnsvitenskap. Jeg har bare grunnleggende forståelse av R. Jeg foretrekker kode basert på tidyverse fremfor base-R og data.table. Kode som er lettlest er viktigere enn effektivitet. For deskriptive tabeller, bruk pakken gtsummary. For regresjonstabeller, bruk pakken modelsummary. Forklar koden trinn for trinn.\n\nDe viktigste tingene å spesifisere er:\n\nDitt nivå (nybegynner)\nForetrukne pakker (tidyverse, gtsummary, modelsummary)\nKodestil (lettlest fremfor effektivt)",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#vibe-coding-og-agentiske-verktøy",
    "href": "ki_koding.html#vibe-coding-og-agentiske-verktøy",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.6 Vibe coding og agentiske verktøy",
    "text": "3.6 Vibe coding og agentiske verktøy\nDet har i det siste dukket opp to begreper som er verdt å kjenne til: vibe coding og agentiske verktøy.\nVibe coding er et begrep som ble populært i 2025 og beskriver en arbeidsform der du beskriver hva du vil i naturlig språk og lar KI generere all koden – uten at du leser eller forstår koden selv. Du styrer etter “vibben”: ser resultatet riktig ut? Fungerer det? Hvis ja, gå videre. Noen erfarne programmerere bruker dette for å lage prototyper raskt, men da kan de også vurdere og feilsøke resultatet når noe går galt.\nFor studenter er vibe coding ikke en god strategi. Poenget med et metodekurs er å lære å forstå dataanalyse, og det innebærer å forstå koden. Hvis du lar KI skrive alt uten å lese det, lærer du ingenting – og du kan ikke oppdage feil i analysen. Det er som å bruke maskinoversettelse til å skrive en stil i et språk du holder på å lære: resultatet kan se greit ut, men du har ikke lært noe, og du kan ikke fange opp feil.\nAgentiske verktøy er en nyere kategori KI-verktøy som går et steg videre. Verktøy som Claude Code, OpenAI Codex og Cursor kan ikke bare skrive kode, men også kjøre den, lese resultatene, og justere koden automatisk – alt uten at du gjør noe. Dette er kraftige verktøy for erfarne brukere, men for nybegynnere innebærer det enda mindre kontakt med selve koden.\nVær oppmerksom på at disse verktøyene finnes. Når du har bygget opp grunnleggende ferdigheter – for eksempel i forbindelse med en masteroppgave eller i arbeidslivet – kan de bli svært nyttige. Men først må du ha kompetansen til å vurdere det de produserer. Det finnes ingen snarvei forbi det å lære seg å kode.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#datasikkerhet-og-personvern",
    "href": "ki_koding.html#datasikkerhet-og-personvern",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.7 Datasikkerhet og personvern",
    "text": "3.7 Datasikkerhet og personvern\nNår du bruker et KI-verktøy, sendes alt du skriver i promptet til en ekstern server for prosessering. Det samme gjelder konteksten som verktøyet bruker: hvis du limer inn kode, data eller feilmeldinger, havner dette hos KI-leverandøren. For agentiske verktøy som Claude Code eller Cursor gjelder dette i enda større grad – de kan lese hele filer og prosjektmapper automatisk for å bygge kontekst, uten at du eksplisitt velger hva som sendes.\nDette har viktige implikasjoner for personvern og datasikkerhet.\n\n3.7.1 Hva er persondata?\nEtter personvernforordningen (GDPR) er persondata all informasjon som kan knyttes til en identifiserbar person. Det inkluderer opplagte ting som navn, fødselsnummer og e-postadresser, men også kombinasjoner av variabler som sammen kan identifisere enkeltpersoner – for eksempel alder, bosted og yrke. Helseopplysninger, etnisitet og politisk tilhørighet er i tillegg regnet som særlige kategorier med ekstra strengt vern.\nI samfunnsvitenskapelig forskning er dette svært relevant. Datasettene du jobber med kan inneholde slike opplysninger, og å lime inn rader fra et datasett i en KI-chat kan i praksis utgjøre en overføring av persondata til en tredjepart.\n\n\n3.7.2 Trening og datalagring\nDe fleste KI-tjenester bruker samtaledata til å trene og forbedre modellene sine – med mindre du aktivt reserverer deg. ChatGPT og Claude (i gratisversjonene) gjør dette som standard, men tilbyr mulighet for å skru det av i innstillingene. Data kan også lagres i en periode, typisk fra noen dager til flere uker, avhengig av tjeneste og abonnementstype.\nAPI-tilgang og bedriftsavtaler har vanligvis strengere regler: data brukes normalt ikke til trening, og lagringstiden er kortere. Men detaljene varierer mellom leverandører og endres jevnlig. Les alltid gjeldende vilkår, og anta som hovedregel at det du skriver kan bli lagret.\n\n\n3.7.3 Agentiske verktøy – ekstra utfordringer\nMens du i et chatvindu selv velger hva du limer inn, kan agentiske verktøy lese og sende filinnhold automatisk. Et verktøy som Claude Code eller Cursor kan indeksere hele prosjektmappen din for å gi bedre svar. Dersom prosjektet inneholder datasett med personopplysninger, konfigurasjonsfiler med passord, eller andre sensitive data, kan disse bli sendt til leverandørens servere uten at du er klar over det.\nHvis du jobber med sensitive data, er det avgjørende å forstå hvilke filer verktøyet har tilgang til, og hva som faktisk sendes. Noen verktøy tilbyr en «Privacy Mode» som begrenser hva som deles, men dette må aktiveres eksplisitt.\n\n\n3.7.4 Hva bør du gjøre?\n\nAldri lim inn reelle persondata i et KI-verktøy. Bruk anonymiserte eller syntetiske eksempeldata når du trenger hjelp med kode.\nSjekk institusjonens retningslinjer. De fleste universiteter har egne regler for bruk av KI-verktøy – følg disse.\nVurder abonnementstype. For prosjekter med sensitive data kan API-tilgang eller bedriftsavtaler med strengere personvernvilkår være nødvendig.\nVær ekstra varsom med agentiske verktøy som har tilgang til hele prosjektmappen. Sørg for at sensitive datafiler ikke ligger i samme mappe som kodeprosjektet, eller bruk verktøyets innstillinger for å ekskludere dem.\nVurder om du trenger KI-hjelp i det hele tatt for den konkrete oppgaven. Noen ganger er det tryggere å løse problemet selv.\n\n\n\n3.7.5 Lokale modeller\nFor situasjoner der data ikke kan forlate maskinen, finnes det modeller som kan kjøres helt lokalt. Verktøy som Ollama gjør det mulig å kjøre åpne modeller som Llama og DeepSeek på egen maskin, og OpenClaw lar deg koble lokale modeller til agentiske arbeidsflyter. Da sendes ingen data til eksterne servere. Per i dag krever dette en viss teknisk kompetanse og en maskin med tilstrekkelig kapasitet, men terskelen er i ferd med å synke raskt.\n\n\n3.7.6 Regulering og veien videre\nNorge innfører en ny lov om kunstig intelligens, basert på EUs AI Act, med planlagt ikrafttredelse sommeren 2026. Loven stiller krav til transparens, dokumentasjon og risikovurdering for KI-systemer. Datatilsynet følger utviklingen tett og har blant annet en egen sandkasse for KI-prosjekter som ønsker veiledning om personvern.\nForvent at det kommer tydeligere regler for bruk av KI-verktøy i forskning og utdanning i årene fremover. Grunnprinsippet vil uansett bestå: du er selv ansvarlig for at persondata behandles i tråd med regelverket, uansett hvilket verktøy du bruker.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#tips-for-effektiv-bruk",
    "href": "ki_koding.html#tips-for-effektiv-bruk",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.8 Tips for effektiv bruk",
    "text": "3.8 Tips for effektiv bruk\n\nStart med å forstå, deretter feilsøk, og til slutt generer ny kode. Denne rekkefølgen gir best læring.\nLes alltid koden du får fra KI-verktøy før du bruker den. Hvis du ikke forstår en linje, be verktøyet forklare den.\nTest på egne data. Kode som ser riktig ut kan likevel gi feil resultater med dine data.\nVær spesifikk i promptene. Nevn pakker, variabelnavn, og hva slags output du forventer.\nBruk oppfølgingsspørsmål. Første svar er sjelden perfekt – juster med nye instruksjoner.\nSett opp faste instruksjoner med dine preferanser, slik at du får konsistente svar.\nHusk at KI kan ta feil. Verktøyene høres alltid selvsikre ut, også når svaret er galt. Dobbeltsjekk alltid.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "ki_koding.html#en-note-om-læring",
    "href": "ki_koding.html#en-note-om-læring",
    "title": "3  Bruk KI som kodehjelp",
    "section": "3.9 En note om læring",
    "text": "3.9 En note om læring\nDette er et godt sted for en liten bemerkning om læring og studier, selv om denne boken ellers er svært praktisk orientert. Det er åpenbart slik at KI kan lage ferdige produkter for deg, uten at du selv behøver å skjønne så mye av hva som skjer. Hvorfor skal du derfor lære disse tingene selv? Noen svar har blitt antydet ovenfor knyttet til de-bugging etc.\nEn viktigere grunn er at utdanning handler om å trene opp analytiske evner og ferdigheter. For å kunne analysere data må du skjønne en del om data og databehandling, analysemuligheter og -teknikker. Å jobbe med kode kan være krevende og tidvis svært frustrerende når man ikke skjønner hvorfor noe ikke fungerer. Men det er her læringen ligger: du lærer bare når hjernen anstrenger seg. Du lærer mer når du finner ut av ting selv enn når du får løsningen servert. Du må selv vurdere hvor mye du skal jobbe selv før du bruker f.eks. KI til å hjelpe deg.\nFor de som er glad i fysisk trening (sport etc), så er en parallell at du blir ikke sterkere av å henge rundt på trengingssenteret. Du blir sterkere av å løfte tungt (eller hva du nå driver med), så det faktum at det finnes kraner og vinsjer som kan løfte for deg er ikke relevant. For læring gjelder det samme: det er din egen anstrengelse som er hele poenget. Hvis du ikke gjør det, vil du neppe lære noe særlig og du kaster egentlig bort tiden.",
    "crumbs": [
      "Del I: Kom igang",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bruk KI som kodehjelp</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html",
    "href": "forste_analyse.html",
    "title": "4  Din første analyse",
    "section": "",
    "text": "4.1 Laste pakker\nI de forrige kapitlene har du installert R og RStudio, og fått en kort introduksjon til grunnleggende konsepter. Nå skal vi gjøre noe annerledes: vi skal kjøre gjennom en hel analyse fra start til mål – lese inn ekte data og lage ekte figurer.\nMålet med dette kapittelet er at du skal oppleve at R faktisk fungerer, og at du kan produsere noe meningsfullt med bare noen få linjer kode. Ikke bekymre deg om du ikke forstår alle detaljene. Hvert tema forklares grundig i senere kapitler. Her handler det om å følge med, kjøre koden, og se resultatene.\nDataene vi bruker er kriminalitetsstatistikk fra SSB (Statistisk sentralbyrå), hentet fra tabell 09415. De viser siktede for lovbrudd per 1000 innbyggere, fordelt på alder.\nÅpne RStudio, sørg for at prosjektet ditt er aktivt (se kapittelet om installering), og opprett et nytt R-script (File → New File → R Script). Skriv koden inn i scriptet og kjør den linje for linje med Ctrl + Enter.\nFør vi kan bruke spesialiserte funksjoner, må vi laste pakkene som inneholder dem. Hvis du ikke allerede har installert disse pakkene, gjør det først:\n# Installer pakker (trenger bare gjøres én gang)\ninstall.packages(c(\"tidyverse\", \"readxl\"))\nDeretter laster vi pakkene. Dette må gjøres hver gang du starter R på nytt:\n# Laste pakker (gjøres hver gang du starter R)\nlibrary(tidyverse)   # Pakke for datahåndtering og grafikk\nlibrary(readxl)      # Pakke for å lese Excel-filer\nFunksjonen install.packages() laster ned pakken til maskinen din, mens library() aktiverer den i den gjeldende R-sesjonen. Se kapittelet om introduksjon til R for mer om pakker.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#lese-inn-data",
    "href": "forste_analyse.html#lese-inn-data",
    "title": "4  Din første analyse",
    "section": "4.2 Lese inn data",
    "text": "4.2 Lese inn data\nNå leser vi inn en Excel-fil med kriminalitetsdata. Funksjonen read_excel() leser filen, og &lt;- lagrer resultatet i et objekt vi kaller krim:\n\n# Lese inn en Excel-fil med kriminalitetsdata fra SSB\n# read_excel() leser filen, &lt;- lagrer resultatet i objektet \"krim\"\nkrim &lt;- read_excel(\"data/SSB_09415_enkel2024.xlsx\")\n\nNå ligger dataene i objektet krim. Filstien \"data/SSB_09415_enkel2024.xlsx\" betyr at filen ligger i en undermappe som heter data i prosjektmappen din. Innlesning av data dekkes grundig i Del II.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#ta-en-titt-på-dataene",
    "href": "forste_analyse.html#ta-en-titt-på-dataene",
    "title": "4  Din første analyse",
    "section": "4.3 Ta en titt på dataene",
    "text": "4.3 Ta en titt på dataene\nFør vi lager figurer bør vi sjekke at dataene ser fornuftige ut. To nyttige funksjoner for dette er head() og glimpse():\n\n# Se på de første radene i datasettet\n# head() viser de 6 første observasjonene\nhead(krim)\n\n# A tibble: 6 × 2\n  alder  vold\n  &lt;dbl&gt; &lt;dbl&gt;\n1     5  0.02\n2     6  0.05\n3     7  0.03\n4     8  0.19\n5     9  0.27\n6    10  0.63\n\n\n\n# En annen måte å se på dataene\n# glimpse() viser variabelnavn, datatype og de første verdiene\nglimpse(krim)\n\nRows: 45\nColumns: 2\n$ alder &lt;dbl&gt; 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2…\n$ vold  &lt;dbl&gt; 0.02, 0.05, 0.03, 0.19, 0.27, 0.63, 1.18, 2.80, 6.36, 9.41, 5.36…\n\n\nVi ser at datasettet har to kolonner: alder (gjerningspersonens alder) og vold (antall siktede for vold per 1000 innbyggere i den aldersgruppen, for 2024). La oss se hva disse tallene viser grafisk.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#din-første-figur",
    "href": "forste_analyse.html#din-første-figur",
    "title": "4  Din første analyse",
    "section": "4.4 Din første figur",
    "text": "4.4 Din første figur\nNå lager vi vår første figur. Vi bruker ggplot, som er det standard systemet for grafikk i R. Prinsippet er lagvis oppbygging: du starter med et grunnlag og legger til nye elementer ett om gangen. La oss se det steg for steg.\n\n4.4.1 Steg 1: Bare en linje\n\n# Start et plot: alder på x-aksen, vold på y-aksen\n# geom_line() tegner en linje mellom datapunktene\nggplot(krim, aes(x = alder, y = vold)) +\n  geom_line()\n\n\n\n\n\n\n\n\nHer skjer tre ting: ggplot(krim, ...) sier “bruk datasettet krim”. Inni aes() (kort for aesthetics) angir vi at alder skal på x-aksen og vold på y-aksen. Til slutt sier geom_line() at dataene skal vises som en linje. Resultatet er et minimalt, men fungerende plot.\n\n\n4.4.2 Steg 2: Legg til punkter\n\n# Legg til geom_point() for å vise hvert datapunkt\nggplot(krim, aes(x = alder, y = vold)) +\n  geom_line() +\n  geom_point()\n\n\n\n\n\n\n\n\nVi legger til geom_point() med +. Nå ser vi hvert enkelt datapunkt i tillegg til linjen. + i ggplot betyr “legg til et nytt lag”.\n\n\n4.4.3 Steg 3: Legg til tittel\n\n# Legg til en overskrift med ggtitle()\nggplot(krim, aes(x = alder, y = vold)) +\n  geom_line() +\n  geom_point() +\n  ggtitle(\"Voldslovbrudd etter alder\")\n\n\n\n\n\n\n\n\nggtitle() legger til en overskrift på figuren. Enda et lag oppå de forrige.\n\n\n4.4.4 Steg 4: Legg til akselabels og kilde\n\n# labs() styrer akseetiketter, undertittel og kildeangivelse\nggplot(krim, aes(x = alder, y = vold)) +\n  geom_line() +\n  geom_point() +\n  ggtitle(\"Voldslovbrudd etter alder\",\n          subtitle = \"Siktede per 1000 innbyggere, 2024\") +\n  labs(x = \"Alder\",\n       y = \"Siktede per 1000 innbyggere\",\n       caption = \"Kilde: SSB, tabell 09415\")\n\n\n\n\n\n\n\n\nlabs() lar deg sette egne etiketter på aksene. subtitle legger til en undertekst under tittelen, og caption legger til en kildeangivelse nederst.\n\n\n4.4.5 Steg 5: Endre tema og lagre i et objekt\n\n# theme_minimal() gir et renere utseende\n# Vi lagrer figuren i objektet p1 slik at vi kan bruke den igjen\np1 &lt;- ggplot(krim, aes(x = alder, y = vold)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  ggtitle(\"Voldslovbrudd etter alder\",\n          subtitle = \"Siktede per 1000 innbyggere, 2024\") +\n  labs(x = \"Alder\",\n       y = \"Siktede per 1000 innbyggere\",\n       caption = \"Kilde: SSB, tabell 09415\") +\n  theme_minimal()\n\n# Vis figuren\np1\n\n\n\n\n\n\n\n\ntheme_minimal() endrer det visuelle temaet til et renere design uten grå bakgrunn. linewidth = 1 gjør linjen litt tykkere. Ved å skrive p1 &lt;- ggplot(...) lagrer vi hele figuren i et objekt, slik at vi kan vise den igjen ved å skrive p1.\nLegg merke til hva figuren forteller: voldskriminalitet stiger bratt i tenårene, topper rundt 18–20 år, og faller deretter jevnt. Du har nå laget en informativ figur med ekte data, fra start til slutt.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#filtrere-data",
    "href": "forste_analyse.html#filtrere-data",
    "title": "4  Din første analyse",
    "section": "4.5 Filtrere data",
    "text": "4.5 Filtrere data\nHva om vi vil se nærmere på bare ungdomsgruppen? Da kan vi filtrere dataene med funksjonen filter(), som velger ut rader som oppfyller et krav:\n\n# Velg ut bare aldersgruppen 10-18 år\n# %&gt;% (pipe) sender dataene videre til neste operasjon\n# filter() beholder rader der kravet er oppfylt\n# & betyr \"og\" -- begge krav må være oppfylt\nkrim_ung &lt;- krim %&gt;%\n  filter(alder &gt; 10 & alder &lt; 18)\n\n# Lag en rask figur av ungdomsgruppen\nggplot(krim_ung, aes(x = alder, y = vold)) +\n  geom_line() +\n  geom_point() +\n  ggtitle(\"Voldslovbrudd blant ungdom\") +\n  labs(x = \"Alder\", y = \"Siktede per 1000 innbyggere\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHer bruker vi %&gt;% (pipe-operatoren) som betyr “ta dette, og gjør deretter”. Vi tar krim, sender det til filter(), og beholder bare rader der alder er mellom 10 og 18. Resultatet lagres i et nytt objekt krim_ung.\nFiguren viser den bratte økningen i ungdomsårene enda tydeligere. Pipen (%&gt;%) og filter() er grunnleggende verktøy i tidyverse som dekkes grundig i Del III.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#større-datasett-med-flere-variable",
    "href": "forste_analyse.html#større-datasett-med-flere-variable",
    "title": "4  Din første analyse",
    "section": "4.6 Større datasett med flere variable",
    "text": "4.6 Større datasett med flere variable\nLa oss nå jobbe med et større datasett fra samme SSB-tabell, men med mer detalj: fordelt på type lovbrudd, kjønn og år. Denne Excel-filen er litt mer komplisert – de tre første radene inneholder overskriftstekst fra SSB som ikke er data, og kolonnene har ikke gode variabelnavn:\n\n# Lese inn et større datasett\n# skip = 3 hopper over de 3 første radene (overskriftstekst fra SSB)\n# col_names angir variabelnavn vi velger selv\n# Vi bruker variabelnavn uten æøå for å unngå tegnkodingsproblemer\nkrim_alle &lt;- read_excel(\"data/SSB_09415_alderSiktet.xlsx\",\n                         skip = 3,\n                         col_names = c(\"lovbruddsgruppe\", \"kjonn\",\n                                       \"alder\", \"aar\", \"pr1000\"))\n\n\n# Se på de første radene\nhead(krim_alle)\n\n# A tibble: 6 × 5\n  lovbruddsgruppe       kjonn       alder aar   pr1000\n  &lt;chr&gt;                 &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Alle lovbruddsgrupper Begge kjønn     5 2002    0.26\n2 Alle lovbruddsgrupper Begge kjønn     5 2003    0.27\n3 Alle lovbruddsgrupper Begge kjønn     5 2004    0.13\n4 Alle lovbruddsgrupper Begge kjønn     5 2005    0.12\n5 Alle lovbruddsgrupper Begge kjønn     5 2006    0.1 \n6 Alle lovbruddsgrupper Begge kjønn     5 2007    0.07\n\n\n\n# Se hvilke lovbruddsgrupper som finnes\n# table() teller opp hvor mange ganger hver verdi forekommer\ntable(krim_alle$lovbruddsgruppe)\n\n\n          Alle lovbruddsgrupper                  Annet lovbrudd \n                           3174                            3174 \n         Annet vinningslovbrudd                   Eiendomsskade \n                           3174                            3174 \n                 Eiendomstyveri Ordens- og integritetskrenkelse \n                           3174                            3174 \n              Rusmiddellovbrudd                 Seksuallovbrudd \n                           3174                            3174 \n            Trafikkovertredelse             Vold og mishandling \n                           3174                            3174 \n\n\nVi ser at datasettet inneholder flere lovbruddsgrupper. $-tegnet brukes for å hente ut én enkelt variabel fra datasettet. La oss filtrere til bare voldskriminalitet:\n\n# Velg ut bare voldskriminalitet for begge kjønn\nkrim_vold &lt;- krim_alle %&gt;%\n  filter(lovbruddsgruppe == \"Vold og mishandling\",\n         kjonn == \"Begge kjønn\")",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#figur-med-flere-grupper",
    "href": "forste_analyse.html#figur-med-flere-grupper",
    "title": "4  Din første analyse",
    "section": "4.7 Figur med flere grupper",
    "text": "4.7 Figur med flere grupper\nNå har vi data for voldskriminalitet over flere år. La oss bygge opp en figur steg for steg igjen.\n\n4.7.1 Steg 1: Enkel linje – noe er galt\n\n# Prøv å tegne en enkel linje -- dette blir rotete!\nggplot(krim_vold, aes(x = alder, y = pr1000)) +\n  geom_line()\n\n\n\n\n\n\n\n\nDenne figuren ser kaotisk ut. Det er fordi ggplot prøver å tegne alle datapunktene – fra alle år – som én sammenhengende linje. Vi må fortelle ggplot at hvert år er en egen gruppe.\n\n\n4.7.2 Steg 2: Gruppering og farge\n\n# group = aar gjør at hvert år får sin egen linje\n# color = aar gir ulike farger for hvert år\nggplot(krim_vold, aes(x = alder, y = pr1000, group = aar, color = aar)) +\n  geom_line()\n\n\n\n\n\n\n\n\nNå er det mye bedre. group = aar forteller ggplot at datapunktene skal deles inn etter år, og color = aar gir hver gruppe en egen farge. Vi ser alderskurven for voldskriminalitet for hvert år.\n\n\n4.7.3 Steg 3: Titler og tema\n\n# Legg til titler og renere tema\nggplot(krim_vold, aes(x = alder, y = pr1000, group = aar, color = aar)) +\n  geom_line() +\n  ggtitle(\"Voldslovbrudd etter alder og år\") +\n  labs(x = \"Alder\",\n       y = \"Siktede per 1000 innbyggere\",\n       color = \"År\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSamme prinsipp som før: vi legger til lag for tittel, akselabels og tema. color = \"År\" i labs() endrer etiketten på fargelegenden.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#avgrense-ytterligere",
    "href": "forste_analyse.html#avgrense-ytterligere",
    "title": "4  Din første analyse",
    "section": "4.8 Avgrense ytterligere",
    "text": "4.8 Avgrense ytterligere\nFiguren ovenfor har mange linjer og kan være vanskelig å lese. La oss avgrense til ungdom og velge ut bare noen utvalgte år:\n\n# Avgrense til alder 10-18 og hvert tredje år fra 2002 til 2024\n# %in% sjekker om en verdi finnes i en liste\n# seq() lager en tallrekke: 2002, 2005, 2008, ..., 2024\nkrim_utvalg &lt;- krim_vold %&gt;%\n  filter(alder &gt; 10, alder &lt; 18) %&gt;%\n  filter(aar %in% seq(2002, 2024, by = 3))\n\n# Figur med tykkere linjer og punkter\nggplot(krim_utvalg, aes(x = alder, y = pr1000, group = aar, color = aar)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  ggtitle(\"Voldslovbrudd blant ungdom, utvalgte år\") +\n  labs(x = \"Alder\",\n       y = \"Siktede per 1000 innbyggere\",\n       color = \"År\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHer kombinerer vi flere filtreringer: først avgrenser vi til ungdom, deretter velger vi ut hvert tredje år. seq(2002, 2024, by = 3) lager tallrekken 2002, 2005, 2008, …, 2024, og %in% sjekker om verdien av aar finnes i denne listen.\nFiguren blir mye lettere å lese, og mønsteret er tydelig: vi kan se hvordan ungdomskriminaliteten har utviklet seg over tid.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#tidstrend-for-utvalgte-aldersgrupper",
    "href": "forste_analyse.html#tidstrend-for-utvalgte-aldersgrupper",
    "title": "4  Din første analyse",
    "section": "4.9 Tidstrend for utvalgte aldersgrupper",
    "text": "4.9 Tidstrend for utvalgte aldersgrupper\nTil nå har vi hatt alder på x-aksen og brukt farger for å skille mellom år. Vi kan også snu perspektivet: sette år på x-aksen og bruke farger for å skille mellom aldersgrupper. Da ser vi tidstrenden – hvordan kriminaliteten har utviklet seg over tid for ulike aldersgrupper.\n\n# Velg ut noen utvalgte aldersgrupper\n# factor() gjør alder om til en kategori slik at fargene blir diskrete\nkrim_alder &lt;- krim_vold %&gt;%\n  filter(alder %in% c(12, 14, 15, 18, 25, 30)) %&gt;%\n  mutate(alder = factor(alder))\n\n# Tidstrend: år på x-aksen, en linje per aldersgruppe\nggplot(krim_alder, aes(x = aar, y = pr1000, group = alder, color = alder)) +\n  geom_line(linewidth = 1) +\n  geom_point() +\n  ggtitle(\"Tidstrend i voldslovbrudd for utvalgte aldersgrupper\") +\n  labs(x = \"År\",\n       y = \"Siktede per 1000 innbyggere\",\n       color = \"Alder\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLegg merke til at koden er nesten identisk med den forrige figuren – vi har bare byttet hva som er på x-aksen (aar i stedet for alder) og hva som styrer fargene (alder i stedet for aar). factor(alder) gjør at alder behandles som en kategori med diskrete farger i stedet for en sammenhengende skala.\nFiguren viser at utviklingen er svært ulik for ulike aldersgrupper. 18-åringene har det høyeste nivået, men alle aldersgrupper kan studeres over tid. Med noen få endringer i koden har vi et helt annet perspektiv på de samme dataene.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#oppsummering",
    "href": "forste_analyse.html#oppsummering",
    "title": "4  Din første analyse",
    "section": "4.10 Oppsummering",
    "text": "4.10 Oppsummering\nI dette kapittelet har du gjennomført en hel analyse fra start til mål:\n\nLastet pakker med library()\nLest inn data fra en Excel-fil med read_excel()\nUtforsket dataene med head(), glimpse() og table()\nLaget figurer med ggplot(), geom_line() og geom_point()\nLagt til titler og etiketter med ggtitle() og labs()\nEndret utseende med theme_minimal()\nFiltrert data med filter() og pipen %&gt;%\n\nAlt dette er verktøy du vil bruke gjennom hele boken. Hvert tema dekkes grundig i sine egne kapitler: innlesning av data i Del II, datahåndtering med tidyverse i Del III, og grafikk med ggplot i Del IV.\nHvis det er noe du ikke helt forsto – det er helt normalt. Poenget nå var å se at R fungerer, at du kan produsere noe meningsfullt med noen få linjer kode, og at den lagvise oppbyggingen av figurer gir deg full kontroll over resultatet.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "forste_analyse.html#oppgaver",
    "href": "forste_analyse.html#oppgaver",
    "title": "4  Din første analyse",
    "section": "4.11 Oppgaver",
    "text": "4.11 Oppgaver\n\nExercise 4.1 Kjør all koden i dette kapittelet selv i RStudio. Gjør noen endringer og kjør på nytt – for eksempel, prøv å endre tittelen på en figur, legg til geom_point(color = \"red\") i stedet for geom_point(), eller filtrer på en annen aldersgruppe. Målet er at du skal se at endringene dine faktisk fungerer.\n\n\nExercise 4.2 Filtrer krim_alle på en annen lovbruddsgruppe enn “Vold og mishandling”. Bruk table(krim_alle$lovbruddsgruppe) for å se hvilke grupper som finnes. Lag en figur tilsvarende den vi lagde for voldskriminalitet.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Din første analyse</span>"
    ]
  },
  {
    "objectID": "grafikk.html",
    "href": "grafikk.html",
    "title": "5  Grafikk med ggplot",
    "section": "",
    "text": "5.1 Lagvis grafikk\nResten av dette heftet belager seg på å bruke datasettet abu89 som er benyttet i en annen lærebok. Dataene kan lastes ned fra den bokens hjemmeside.\nFørst må dataene leses inn. Siden dette er data i stata-formatet dta, så brukes importfunksjonen read_stata(). Som nevnt tidligere bør variabler av typen labelled gjøres om til factor. Vi sletter også labler som ikke er i faktisk bruk. Disse to tingene gjørs med as_factor() og fct_drop(), men de er lagt inn i en funksjon som går gjennom alle variable i datasettet, across() og sjekker om de er av labelled-typen where(is.labelled). Detaljene her er ikke sentrale for dette kurset: bare se å få lest inn dataene i R.\nI R er det mange funksjoner for å lage grafikk. Noen er spesialiserte og knyttet til spesielle analysemetoder og gir deg akkurat det du trenger. Vi skal her bruke et generelt system for grafikk som heter ggplot som kan brukes til all slags grafikk. Funksjonen ggplot er bygget opp som en gramatikk for grafisk fremstilling. Det ligger en teori til grunn som er utledet i boken ved omtrent samme navn: The grammar of graphics. Det er mye som kan sies om dette, men det viktige er at grafikken er bygget opp rundt noen bestanddeler. Når du behersker disse kan du fremstille nær sagt hva som helst av kvantitativ informasjon grafisk. Dette er altså et system for grafikk, ikke bare kommandoer for spesifikke typer plot. Vi skal likevel bare se på grunnleggende typer plot her.\nSystemet er bygd opp lagvis. Det gjelder selve koden, men også hvordan det ser ut visuelt. Man kan utvide plottet med flere lag i samme plot og det legges da oppå hverandre i den rekkefølgen som angis i koden.\nFor enkle plot som vi skal bruke her angir man i denne rekkefølgen og med en + mellom hver del (vanligvis per linje, men linjeskift spiller ingen rolle). Hver del av koden spesifiserer enten hva som skal plottes eller hvordan det plottes, mens andre deler kan kontrollere utseende på akser, fargeskalaer, støttelinjer eller andre ting som har med layout å gjøre.\nDette blir tydeligere i eksemplene og forklares underveis.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Grafikk med ggplot</span>"
    ]
  },
  {
    "objectID": "grafikk.html#lagvis-grafikk",
    "href": "grafikk.html#lagvis-grafikk",
    "title": "5  Grafikk med ggplot",
    "section": "",
    "text": "Angi data og hva som skal plottes med ggplot()\nAngi hvordan det skal plottes med geom_*()\nAngi andre spesifikasjoner (farger, titler, koordinatsystemer osv)\n\n\n\nDet første argumentet i ggplot er data. Altså: hvilket datasett informasjonen hentes fra.\nInni ggplot() må det spesifiseres aes(), “aestethics”, som er hvilke variable som skal plottes. Først og fremst hva som skal på x-akse og y-akse (og evt. z-akse), men også spesifikasjon av om linjer (farge, linjetype) og fyllfarger, skal angis etter en annen variabel.\ngeom_* står for geometric og sier noe om hvordan data skal se ut. Det kan være punkter, histogram, stolper, linjer osv.\ncoord_* definerer koordinatsystemet. Stort sett blir dette bestemt av variablene. Men du kan også snu grafen eller definere sirkulært koordinatsystem, eller andre enklere ting.\nfacet_* definerer hvordan du vil dele opp grafikken i undergrupper",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Grafikk med ggplot</span>"
    ]
  },
  {
    "objectID": "grafikk.html#kategoriske-variabel",
    "href": "grafikk.html#kategoriske-variabel",
    "title": "5  Grafikk med ggplot",
    "section": "5.2 Kategoriske variabel",
    "text": "5.2 Kategoriske variabel\n\n5.2.1 Stolpediagram\n\nlibrary(ggforce)\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nNoen ganger ønsker man å vise fordelingen for to ulike grupper, la oss si for kjønn. En mulighet er da å rett og slett lage to stolpediagram ved siden av hverandre. Til dette kan man spesifisere at dataene er gruppert etter variabelen female og at fyllfargen skal settes etter denne variablen med fill = factor(female). Merk bruken av factor(female) fordi variabelen er numerisk og det vil da ellers brukes en kontinuerlig fargeskale, mens å gjøre om variabelen til kategorisk brukes en annen fargeskala.\nI tillegg gjør vi her to ting til: setter et annet grafisk tema med theme_minimal() og snur plotvinduet slik at kategoriene er litt lettere å lese. Dette er smak og behag.\n\nggplot(abu89, aes(x = klasse89, group = female, fill = factor(female))) +\n  geom_bar(position=\"dodge\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 90))+\n  coord_flip()\n\n\n\n\n\n\n\n\nEt alternativ er å plassere grafikken for menn og kvinner ved siden av hverandre. Å legge til facet_wrap() gjør dette.\n\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  facet_wrap(~factor(female)) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nEt automatisk forvalg for geom_bar() er hvordan gruppene plasseres som er position=\"stack\". Det betyr at gruppene stables oppå hverandre. Dette er godt egnet hvis poenget er å vise hvor mange av hvert kjønn som er i hver gruppe. Det er mindre egnet hvis du ønsker å sammenligne menn og kvinner. Da er alternativet å velge position=\"dodge\" som følger:\n\n\n5.2.2 Kakediagram\nGenerelt er ikke kakediagram å anbefale da korrekt tolkning involverer å tolke et areal som inneholder vinkel. Med få kategorier som er rimelig forskjellig kan det gi et ok inntrykk, men ofte ender man opp med å måtte skrive på tallene likevel. Vi tar det med her egentlig bare fordi mange insisterer på å bruke det. Så vet du at det er mulig.\nDet enkleste er å bruke funksjonen pie() som gir følgende resultat.\n\ntab &lt;- table(abu89$klasse89) \ntab\n\n\n    I Øvre serviceklasse   II Nedre serviceklasse   III Rutinefunksjonærer \n                     328                     1181                     1248 \n V-VI Faglærte arbeidere VIIa Ufaglærte arbeidere \n                     648                      637 \n\npie(tab)\n\n\n\n\n\n\n\n\nMen hvis man skal bruke ggplot er det litt mer jobb. Fordelen med ggplot er at du har bedre kontroll for å lage publiserbar kvalitet. (Akkurat for kakediagram er det kanskje ikke så farlige, for du bør ikke bruke det i publikasjoner hvis du kan la være).\n\npc &lt;- abu89 %&gt;% \n  group_by(klasse89) %&gt;% \n  summarise(n = n()) %&gt;% \n  mutate(pct = n/sum(n)*100) %&gt;% \n  ungroup()\n\nggplot(pc, aes(x = \"\", y = pct, fill = (klasse89))) +\n  geom_bar(stat=\"identity\", width=1) +\n  coord_polar(\"y\", start=0) +\n  theme_void()+\n  geom_text( aes(label = paste0( round(pct,1), \"%\"), x = 1.4), \n            position = position_stack(vjust=.5), check_overlap = F) +\n  labs(x = NULL, y = NULL, fill = NULL)+\n  theme(axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank()) +\n  scale_fill_brewer(palette=\"Blues\", direction = -1)",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Grafikk med ggplot</span>"
    ]
  },
  {
    "objectID": "grafikk.html#kontinuerlige-variable",
    "href": "grafikk.html#kontinuerlige-variable",
    "title": "5  Grafikk med ggplot",
    "section": "5.3 Kontinuerlige variable",
    "text": "5.3 Kontinuerlige variable\n\n5.3.1 Histogram\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nDet er også vanlig å fremstille det samme på en “tetthetsskala”, der arealet summeres til 1. Det betyr at arealet for hvert intervall tilsvarer en andel. Visuelt sett er det vel så mye arealet vi oppfatter som høyden på stolpene. Men det er bare skalaen på y-aksen som har endret seg. Visuelt sett, ser histogrammene helt like ut.\n\nggplot(abu89, aes(x = time89, y = ..density..)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n5.3.2 Density plot\nDensity plot er en måte å fremstille det samme på, men i stedet for å dele inn i intervaller som i histogram lager vi en glattet kurve. Det blir på skalaen “tetthet” som i histogrammet ovenfor.\n\nggplot(abu89, aes(x = time89)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram(aes(y = ..density..), fill = \"lightgrey\", col = \"grey\") +\n  geom_density(col = \"red\", linewidth = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEn fordel med denne fremstillingen er at det er lettere å sammenligne grupper. Her er et eksempel med density plot etter hvor mye man drikker.\n\nggplot(abu89, aes(x = time89, group = klasse89, linetype = klasse89)) +\n  geom_density(linewidth = 1)+\n  guides(fill = guide_legend(override.aes = list(shape = 1 ) ) ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_density(linewidth = 1)+\n  theme_minimal()+\n  facet_wrap(~klasse89, scales=\"free\")\n\n\n\n\n\n\n\n\n\nggplot(abu89, aes(x = time89, group = female,  fill = factor(female))) +\n  geom_density(alpha = .3)+\n  guides(fill=guide_legend(title=\"Kjønn\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n5.3.3 Flere variable samtidig\n\n5.3.3.1 Boksplot\n\nggplot(abu89, aes(y = time89, group = klasse89)) +\n  geom_boxplot()+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n5.3.3.2 Scatterplot\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_point(alpha=.3)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_jitter(alpha=.1, width = .3)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n5.3.3.3 Ridgeplot\nRidgeplot er en annen måte å sammenligne en kontinuerlig fordeling betinget på en gruppering.\n\nlibrary(ggridges)\nggplot( abu89,  aes(y = klasse89, x = time89)) +\n  geom_density_ridges()",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Grafikk med ggplot</span>"
    ]
  },
  {
    "objectID": "grafikk.html#oppgaver",
    "href": "grafikk.html#oppgaver",
    "title": "5  Grafikk med ggplot",
    "section": "5.4 Oppgaver",
    "text": "5.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 5.1 Last ned datasettet abu89 fra angitt hjemmeside og les inn dataene til R som vist ovenfor. Lag den samme grafikken som vist her, gjør noen endringer på kodene for å endre utseendet på plottene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 5.2 Last inn datasettet wagepan fra pakken wooldridge i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Grafikk med ggplot</span>"
    ]
  },
  {
    "objectID": "deskriptive_tabeller.html",
    "href": "deskriptive_tabeller.html",
    "title": "6  Deskriptive tabeller",
    "section": "",
    "text": "6.1 Quick-and-dirty oppsummeringer\nDet kan være ulike grunner til å lage deskriptiv statistikk, og hva du skal bruke tabellene til kan ha betydning for hvordan du lager dem. Noen ganger skal du bare sjekke noen tall, og da er det ingen grunn til å bruke tid på å gjøre tabellen spesiell pen. Andre ganger skal tabellen publiseres i en rapport, på en nettside eller i en vitenskapelig artikkel - eller mest aktuelt på kort sikt: i en masteroppgave. Da må tabellene se ordentlige ut. Nedenfor skal vi se på begge mulighetene.\nFørst og fremst har vi funksjonen summary(). Når denne brukes på et objekt vil hva slags output du får avhenge av objekttypen. Derfor vil summary() gi forskjellig output om det er en vektor, et datasett eller et regresjonsobjekt etc. Vi avgrenser oss til datasett her.\nHer er output for hele datasettet.\nsummary(abu89)\n\n     io_nr          time89             ed             age       \n Min.   :   3   Min.   : 25.00   Min.   : 0.00   Min.   :16.00  \n 1st Qu.:1542   1st Qu.: 71.00   1st Qu.: 1.00   1st Qu.:30.00  \n Median :3093   Median : 83.33   Median : 3.00   Median :39.00  \n Mean   :3105   Mean   : 90.15   Mean   : 2.69   Mean   :39.65  \n 3rd Qu.:4644   3rd Qu.:102.56   3rd Qu.: 3.00   3rd Qu.:48.00  \n Max.   :6258   Max.   :343.75   Max.   :11.00   Max.   :74.00  \n                NA's   :368                                     \n     female                           klasse89    promot          fexp       \n Min.   :0.0000   I Øvre serviceklasse    : 328   NEI:2568   Min.   :0.0000  \n 1st Qu.:0.0000   II Nedre serviceklasse  :1181   JA :1559   1st Qu.:0.2000  \n Median :0.0000   III Rutinefunksjonærer  :1248              Median :0.7000  \n Mean   :0.4686   V-VI Faglærte arbeidere : 648              Mean   :0.9451  \n 3rd Qu.:1.0000   VIIa Ufaglærte arbeidere: 637              3rd Qu.:1.4000  \n Max.   :1.0000   NA's                    :  85              Max.   :4.9000  \n                                                                             \n    private    \n Public :1602  \n Private:2525\nMerk at summary() rapporterer forskjellig basert på om variabelen er kontinuerlig eller kategorisk. For kontinuerlige variable gis min/max, kvartiler, median og gjennomsnitt. For kategoriske variable gis det antall i hver kategori. Hvis det er manglende verdier på en variabel står det oppført nederst som antall NA's.\nMerk her at variabelen female er definert som kontinuerlig selv om det bare er to verdier. Det ville være mer hensiktsmessig å gjøre om denne variabelen til kategorisk.\nMan kan også bruke summary() på enkeltvariable med bruk av $ som følger:\nsummary(abu89$time89)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  25.00   71.00   83.33   90.15  102.56  343.75     368\nDa får man altså bare tallene for den variabelen man har angitt etter dollartegnet.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive tabeller</span>"
    ]
  },
  {
    "objectID": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "href": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "title": "6  Deskriptive tabeller",
    "section": "",
    "text": "6.1.1 Enkeltfunksjoner\nMan kan hente ut hvert av disse tallene spesifikt fremfor å bruke summary(). Det er egne funksjoner for dette, og de kan også brukes når man gjør databearbeiding for litt andre formål. Vi ser her på de viktigste.\nHva om man vil ha en kvartil som ikke er oppgitt i forvalget? Da kan man bruke funksjonen quantile(). Argumentene i denne funksjonen er hvilken variabel og hvilket prosentil. Som vi ovenfor inneholder time89 noen NA. Vi må i tillegg bestemme hva vi ønsker å gjøre med NA i beregningen, og vi vil her se bort fra disse ved å angi na.rm = TRUE. Ellers får man feilmelding.\nHer er eksempel med første kvartil som skal gi samme svar som ovenfor:\n\nquantile(abu89$time89, .25, na.rm = TRUE)\n\n25% \n 71 \n\n\nHer er en variant der man ber om 95-prosentilen:\n\nquantile(abu89$time89, .95, na.rm = TRUE)\n\n     95% \n148.0362 \n\n\nMan kan også be om flere prosentiler. Da listes disse opp innenfor en c() som følger. Her gis prosentilene for 5, 10, 90 og 95 prosent.\n\nquantile(abu89$time89, c(.05, .10, .90, .95), na.rm = TRUE)\n\n       5%       10%       90%       95% \n 54.91651  61.00000 127.77778 148.03618 \n\n\nGjennomsnittet av en variabel gis ved funksjonen mean():\n\nmean(abu89$time89, na.rm = TRUE)\n\n[1] 90.14948\n\n\nStandardavviket gis ved sd():\n\nsd(abu89$time89, na.rm = TRUE)\n\n[1] 30.31473\n\n\nMedianen kan angis med quantile(), men enklere med median():\n\nmedian(abu89$time89, na.rm = TRUE)\n\n[1] 83.33333\n\n\nVi trenger også ofte antall. nrow() gir antall rader, dvs. antall observasjoner i datasettet\n\nnrow(abu89)\n\n[1] 4127\n\n\nTilsvarende gir ncol() antall kolonner, mens dim() gir begge deler:\n\nncol(abu89)\n\n[1] 9\n\ndim(abu89)\n\n[1] 4127    9",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive tabeller</span>"
    ]
  },
  {
    "objectID": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "href": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "title": "6  Deskriptive tabeller",
    "section": "6.2 Professjonelle tabeller med gtsummary",
    "text": "6.2 Professjonelle tabeller med gtsummary\nFor å lage ordentlig professjonelle tabeller kreves det mer. For det første skal de se ordentlige ut, men de skal også kunne eksporteres til andre formater på en hensiktsmessig måte.\nI R finnes det en hel rekke slike funksjoner. Her har vi vektlagt pakken gtsummary fordi den gir gode tabeller fra helt enkle til ganske avanserte relativt lett. Det er også mange muligheter for å justere tabellene slik du vil. Dessuten kan resultatene eksporteres lett til de fleste aktuelle formater (Word, html, pdf, Excel, latex).\nAvanserte brukere vil muligens se begrensningene i denne pakken og foretrekke noe annet. De fleste vil kunne lage det aller meste med denne pakken.\nVi starter med en enkel oversiktstabell med alle variablene i datasettet. Men vi fjerner løpenummeret for person, nemlig variabelen io_nr fordi den ikke inneholder noe analyserbar informasjon.\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 4,1271\n\n\n\n\nGjennomsnittlig timelønn 1989\n83 (71, 103)\n\n\n    Unknown\n368\n\n\nÅr utdanning\n\n\n\n\n    0\n839 (20%)\n\n\n    1\n1,156 (28%)\n\n\n    3\n1,121 (27%)\n\n\n    5\n483 (12%)\n\n\n    7\n308 (7.5%)\n\n\n    9\n205 (5.0%)\n\n\n    11\n15 (0.4%)\n\n\nAlder\n39 (30, 48)\n\n\nRespondentens kjønn\n1,934 (47%)\n\n\nGoldthorpe klasse 1989\n\n\n\n\n    I Øvre serviceklasse\n328 (8.1%)\n\n\n    II Nedre serviceklasse\n1,181 (29%)\n\n\n    III Rutinefunksjonærer\n1,248 (31%)\n\n\n    V-VI Faglærte arbeidere\n648 (16%)\n\n\n    VIIa Ufaglærte arbeidere\n637 (16%)\n\n\n    Unknown\n85\n\n\nNoen gang forfremmet\n\n\n\n\n    NEI\n2,568 (62%)\n\n\n    JA\n1,559 (38%)\n\n\nBedriftserfaring\n0.70 (0.20, 1.40)\n\n\nPrivat sektor\n\n\n\n\n    Public\n1,602 (39%)\n\n\n    Private\n2,525 (61%)\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nLegg merke til at tbl_summary gjør en del ting automatisk. Først og fremst er bruker den variabel label og factor levels i sidespalten. Ofte vil ikke variable ha slike labler, og da vil det vises variabelnavnene. Variabelen kjønn har ikke angitt factor levels, og variabelen har bare verdiene 0 og 1, og da rapporteres kun den ene kategorien (dvs. verdien 1). Vi kan legge til annen tekst hvis vi ønsker.\nDernest er det en forhåndsinnstilling som angir at det for kontinuerlige variable skal rapporteres median og interquartile range (IQR), dvs. nedre og øvre kvartil i parentes. Det gir en god beskrivelse av variablene, men vi skal endre dette nedenfor. For kategoriske variable rapporteres det antall observasjoner og andelen i prosent i parentes.\nMen merk at for antall år utdanning og kjønn, så er det rapportert som kategoriske variable selv om variabeltypen er kontinuerlig. tbl_summary gjør dette fordi det er relativt få kategorier slik at median og IQR ikke er så interessant uansett.\nLa oss først endre slik at det rapporteres gjennomsnitt og standardavvik i stedet. Det er mer vanlig å gjøre selv om det ikke er noen regel for dette. Funksjonen theme_gtsummary_mean_sd() endrer standardvalget for tbl_summary i alle etterfølgende tabeller. Dermed slipper du endre neste gang. Flere themes finner du på pakkens hjemmeside. For å gå tilbake til opprinnelig theme brukes funksjonen reset_gtsummary_theme().\nVi kan endre andre ting ved tabellen med noen enkle grep. Alle variable kan endre navn i forspalten med å legge til argumentet label =. Nedenfor er to variable endret for å vise hvordan man endrer flere variable. Når det er flere variable må de spesifiseres innenfor argumentet list() som nedenfor. Her endrer vi også label for variabelen female og klasse89.\nNoen ganger kan man også ønske å endre hvordan en variabel presenteres. Et vanlig behov er å presisere hvilken type en variabel er. I dette tilfellet er utdanning antall år etter obligatorisk skolenivå, så det er egentlig en kontinuerlig variabel selv om antall verdier er få. Vi kan velge å presisere at denne er av typen continuous. Nedenfor presiserer vi også at female er kategorisk, dichotomous, selv om denne ble presentert riktig uansett. Vi bruker argumentet type = og flere variable må oppgis innenfor list().\nEn siste ting vi kan endre er å ikke rapportere NA. Det er ikke oppgitt timelønn for alle, så antall NA er rapportert for seg. Det kan være fint, men kan også hende vi ikke ønsker det. Nedenfor er det derfor også lagt til missing = \"no\".\n\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  tbl_summary(label = list(female ~ \"Kjønn\", klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\", female ~ \"dichotomous\"), \n              missing = \"no\")\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 4,1271\n\n\n\n\nGjennomsnittlig timelønn 1989\n90 (30)\n\n\nÅr utdanning\n2.69 (2.56)\n\n\nAlder\n40 (12)\n\n\nKjønn\n1,934 (47%)\n\n\nKlasse\n\n\n\n\n    I Øvre serviceklasse\n328 (8.1%)\n\n\n    II Nedre serviceklasse\n1,181 (29%)\n\n\n    III Rutinefunksjonærer\n1,248 (31%)\n\n\n    V-VI Faglærte arbeidere\n648 (16%)\n\n\n    VIIa Ufaglærte arbeidere\n637 (16%)\n\n\nNoen gang forfremmet\n\n\n\n\n    NEI\n2,568 (62%)\n\n\n    JA\n1,559 (38%)\n\n\nBedriftserfaring\n0.95 (0.91)\n\n\nPrivat sektor\n\n\n\n\n    Public\n1,602 (39%)\n\n\n    Private\n2,525 (61%)\n\n\n\n1 Mean (SD); n (%)\n\n\n\n\n\n\n\n\nOfte vil vi ha en tabell som ikke bare viser univariat fordeling, men bi-variate, altså fordelt på to eller flere grupper. Det er f.eks. ganske vanlig å vise tabeller fordelt på kjønn. Det kan vi også gjøre her ved å legge til argumentet by = female. Nedenfor er det også forenklet argumentene for label = og type =. I slike tilfeller vil vi ofte ha totalen i tillegg til per gruppe, og det gjør vi ved å legge til funksjonen add_overall().\nFor de kontinuerlige variablene får vi ikke antallet som inngår i beregningene. Vi vil gjerne vise antall ikke-missing verdier - særlig fordi vi tok vekk NA som egen rad ovenfor. Dette gjør vi ved å legge til funksjonen add_n().\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_overall() %&gt;% \n  add_n()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOverall\nN = 4,1271\nKvinner\nN = 1,9341\nMenn\nN = 2,1931\n\n\n\n\nGjennomsnittlig timelønn 1989\n3,759\n90 (30)\n79 (24)\n100 (32)\n\n\nÅr utdanning\n4,127\n2.69 (2.56)\n2.38 (2.40)\n2.96 (2.66)\n\n\nAlder\n4,127\n40 (12)\n40 (13)\n40 (12)\n\n\nKlasse\n4,042\n\n\n\n\n\n\n\n\n    I Øvre serviceklasse\n\n\n328 (8.1%)\n74 (3.9%)\n254 (12%)\n\n\n    II Nedre serviceklasse\n\n\n1,181 (29%)\n555 (29%)\n626 (29%)\n\n\n    III Rutinefunksjonærer\n\n\n1,248 (31%)\n986 (52%)\n262 (12%)\n\n\n    V-VI Faglærte arbeidere\n\n\n648 (16%)\n46 (2.4%)\n602 (28%)\n\n\n    VIIa Ufaglærte arbeidere\n\n\n637 (16%)\n244 (13%)\n393 (18%)\n\n\nNoen gang forfremmet\n4,127\n\n\n\n\n\n\n\n\n    NEI\n\n\n2,568 (62%)\n1,308 (68%)\n1,260 (57%)\n\n\n    JA\n\n\n1,559 (38%)\n626 (32%)\n933 (43%)\n\n\nBedriftserfaring\n4,127\n0.95 (0.91)\n0.83 (0.81)\n1.05 (0.97)\n\n\nPrivat sektor\n4,127\n\n\n\n\n\n\n\n\n    Public\n\n\n1,602 (39%)\n1,016 (53%)\n586 (27%)\n\n\n    Private\n\n\n2,525 (61%)\n918 (47%)\n1,607 (73%)\n\n\n\n1 Mean (SD); n (%)\n\n\n\n\n\n\n\n\nMen vi kan lage mer kompliserte tabeller også. La oss si at vi ønsker å lage den samme tabellen som over, men fordelt på to grupper. Det kan være relevant å sammenligne offentlig og privat sektor. En mulighet er å lage en ny grupperingsvariabel ved å slå sammen kjønn og sektor slik at vi får fire kategorier. Men vi får et bedre resultat ved å lage en stratifisert tabell med funksjonen tbl_strata(). Det er litt kryptisk syntaks, men det viktige er å angi hvilken variabel det skal stratifiseres etter med argumentet strata = etterfulgt av .tbl_fun = ~ .x %&gt;%, så kommer tble_summary etter dette. Her er det også lagt til en ekstra header med antall observasjoner.\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %&gt;%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nPublic, N = 1602\n\n\nPrivate, N = 2525\n\n\n\nN\nKvinner\nN = 1,0161\nMenn\nN = 5861\nN\nKvinner\nN = 9181\nMenn\nN = 1,6071\n\n\n\n\nGjennomsnittlig timelønn 1989\n1,403\n82 (23)\n100 (28)\n2,356\n76 (24)\n100 (33)\n\n\nÅr utdanning\n1,602\n2.88 (2.67)\n4.22 (3.12)\n2,525\n1.82 (1.92)\n2.50 (2.31)\n\n\nAlder\n1,602\n42 (12)\n43 (11)\n2,525\n37 (13)\n39 (12)\n\n\nKlasse\n1,592\n\n\n\n\n2,450\n\n\n\n\n\n\n    I Øvre serviceklasse\n\n\n55 (5.4%)\n150 (26%)\n\n\n19 (2.1%)\n104 (6.7%)\n\n\n    II Nedre serviceklasse\n\n\n340 (34%)\n196 (34%)\n\n\n215 (24%)\n430 (28%)\n\n\n    III Rutinefunksjonærer\n\n\n507 (50%)\n64 (11%)\n\n\n479 (54%)\n198 (13%)\n\n\n    V-VI Faglærte arbeidere\n\n\n5 (0.5%)\n114 (20%)\n\n\n41 (4.6%)\n488 (31%)\n\n\n    VIIa Ufaglærte arbeidere\n\n\n104 (10%)\n57 (9.8%)\n\n\n140 (16%)\n336 (22%)\n\n\nNoen gang forfremmet\n1,602\n\n\n\n\n2,525\n\n\n\n\n\n\n    NEI\n\n\n696 (69%)\n318 (54%)\n\n\n612 (67%)\n942 (59%)\n\n\n    JA\n\n\n320 (31%)\n268 (46%)\n\n\n306 (33%)\n665 (41%)\n\n\nBedriftserfaring\n1,602\n0.93 (0.85)\n1.15 (0.94)\n2,525\n0.72 (0.74)\n1.01 (0.98)\n\n\n\n1 Mean (SD); n (%)\n\n\n\n\n\n\n\n\nDet går også an å lage langt mer avanserte tabeller enn dette, og alle deler kan modifiseres. Men vi går ikke inn på dette her. Ved behov finner du instruksjoner på pakkens hjemmeside.\n\n6.2.1 Eksport av tabeller\nDu skal aldri bruke “klipp og lim” for å få en tabell over i et tekstbehandlingsprogram. Trikset er å konvertere tabellen til gt-format som har en eksportfunksjon til MS Word.\nFørst lagres tabellen i et eget objekt.\n\nfintabell &lt;- abu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %&gt;%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\nSå kan tabellen eksporteres til Word, og evt. redigeres videre der hvis det trengs. På dette nivået kan det være mer tidsbesparende å gjøre siste justeringer i Word fremfor å lære alle triks for å lage tabellen fiks ferdig i R. (Skal du lage mange tabeller kan det likevel lønne seg å gjøre mest mulig i R).\n\nfintabell %&gt;% \n  as_gt() %&gt;% \n  gt::gtsave(filename = \"output/fintabell.docx\")\n\nMerk at eksport til docx-formatet krever at du har en relativt ny installasjon av pakkene {gt} og {gtsummary}. Filhalen “.docx” innebærer at filen lagres i dette formatet. Tilsvarende kan du lagre i .html, .pdf, .rtf, .png, .tex eller .ltex bare ved å endre filhalen.\nEn tilsvarende variant som noen av dere har lært på sosgeo1120 er å bruke as_flextable og en tilsvarende eksportfunksjon. Det er selvsagt også helt ok. En tidligere versjon av {gt} kunne som sagt ikke eksportere til Word, så da var {flextable} beste løsning. Men pakken {flextable} har vist seg å være litt trøblete å installere på noen pc’er, så da er det bedre å bruke {gt}.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive tabeller</span>"
    ]
  },
  {
    "objectID": "deskriptive_tabeller.html#manuelle-tabeller",
    "href": "deskriptive_tabeller.html#manuelle-tabeller",
    "title": "6  Deskriptive tabeller",
    "section": "6.3 Manuelle tabeller",
    "text": "6.3 Manuelle tabeller\nNoen ganger trenger man å lage ganske spesifikke ting.\n\n6.3.1 For datasettet totalt\n\n\n6.3.2 Grupperte statistikker",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive tabeller</span>"
    ]
  },
  {
    "objectID": "deskriptive_tabeller.html#oppgaver",
    "href": "deskriptive_tabeller.html#oppgaver",
    "title": "6  Deskriptive tabeller",
    "section": "6.4 Oppgaver",
    "text": "6.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 6.1 Bruk datasettet abu89 og lag de samme tabellene som vist her, gjør noen endringer på kodene for å endre utseendet på tabellene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 6.2 Last inn datasettet wagepan fra pakken wooldridge i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive tabeller</span>"
    ]
  },
  {
    "objectID": "kart.html",
    "href": "kart.html",
    "title": "7  Kart og romlige data",
    "section": "",
    "text": "7.1 Geografiske data og sf-pakken\nI samfunnsvitenskapen er vi ofte interessert i geografisk variasjon. Hvordan varierer kriminaliteten mellom kommuner? Hvor er det flest barnefamilier? Er det regionale forskjeller i valgdeltakelse? Slike sporsmal er mye lettere a forstaa med et kart enn med en tabell. Et kart gir deg umiddelbar oversikt over romlige monstre som kan vaere vanskelig a fange opp ellers.\nI R kan vi lage kart med de samme verktoyene vi allerede kjenner fra ggplot. Det er pakken sf (som star for simple features) som gjor det mulig a jobbe med geografiske data, og den fungerer smutt sammen med tidyverse.\nGeografiske data er i bunn og grunn vanlige datasett med en ekstra kolonne som inneholder geometri – alts de geografiske formene. Det kan vaere polygoner (som kommunegrenser), linjer (som veier) eller punkter (som adresser). Pakken sf handterer alt dette og lar deg bruke vanlige tidyverse-funksjoner som filter(), mutate() og left_join() pa geografiske data.\nHvis du ikke har installert sf fra for, gjor du det slik:\ninstall.packages(\"sf\")",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#lese-inn-kartdata",
    "href": "kart.html#lese-inn-kartdata",
    "title": "7  Kart og romlige data",
    "section": "7.2 Lese inn kartdata",
    "text": "7.2 Lese inn kartdata\nKartdata kommer typisk i formater som shapefile (.shp) eller GeoJSON (.geojson). Funksjonen st_read() leser begge deler. Her henter vi kommunegrenser fra Geonorge, som er den nasjonale portalen for geografiske data i Norge.\n\nkommuner &lt;- st_read(\"https://nedlasting.geonorge.no/geonorge/Basisdata/Kommuner/GeoJSON/Basisdata_0000_Norge_25833_Kommuner_GeoJSON.geojson\")\n\nDenne filen er ganske stor, sa det kan ta litt tid a laste ned. Hvis du har lastet ned filen til din egen maskin, leser du den inn slik:\n\nkommuner &lt;- st_read(\"sti/til/kommuner.geojson\")\n\nLa oss se hva vi har fatt:\n\nglimpse(kommuner)\n\nDu vil se at dette ser ut som en vanlig data.frame, men med en ekstra kolonne som heter geometry. Det er der de geografiske formene ligger. Ellers har du kolonner med kommunenummer, kommunenavn og annen informasjon.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#grunnleggende-kart-med-ggplot",
    "href": "kart.html#grunnleggende-kart-med-ggplot",
    "title": "7  Kart og romlige data",
    "section": "7.3 Grunnleggende kart med ggplot",
    "text": "7.3 Grunnleggende kart med ggplot\nNar du har et sf-objekt, kan du plotte det direkte med geom_sf(). Det er like enkelt som annen ggplot-grafikk:\n\nggplot(kommuner) +\n  geom_sf() +\n  theme_minimal()\n\nDette gir deg et enkelt kart over alle kommuner i Norge. Merk at du ikke trenger a spesifisere x- og y-akser – det ordner geom_sf() selv basert pa geometrien.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#koropletkart-fargelegge-regioner-etter-en-variabel",
    "href": "kart.html#koropletkart-fargelegge-regioner-etter-en-variabel",
    "title": "7  Kart og romlige data",
    "section": "7.4 Koropletkart: fargelegge regioner etter en variabel",
    "text": "7.4 Koropletkart: fargelegge regioner etter en variabel\nEt koropletkart er et kart der omradene er fargelagt etter en variabel. For a lage dette trenger vi forst noen data a koble pa kartet. La oss lage et lite eksempeldatasett med fiktive verdier:\n\n# Anta at kommuner-datasettet har en kolonne \"kommunenummer\"\n# Vi lager noen eksempeldata\neksempel &lt;- kommuner %&gt;%\n  mutate(tilfeldig_verdi = rnorm(n()))\n\nNa kan vi fargelegge kartet etter denne variabelen:\n\nggplot(eksempel) +\n  geom_sf(aes(fill = tilfeldig_verdi)) +\n  scale_fill_viridis_c() +\n  theme_minimal() +\n  labs(fill = \"Verdi\")\n\nFunksjonen scale_fill_viridis_c() gir en fargeskala som er lesbar ogsa for fargeblinde. Du kan ogsa bruke andre fargeskalaer, f.eks. scale_fill_gradient(low = \"white\", high = \"red\").",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#koble-data-til-kartgeometrier",
    "href": "kart.html#koble-data-til-kartgeometrier",
    "title": "7  Kart og romlige data",
    "section": "7.5 Koble data til kartgeometrier",
    "text": "7.5 Koble data til kartgeometrier\nI praksis har du som regel dataene dine i et eget datasett og kartgeometriene i et annet. Da ma du koble dem sammen med left_join(). Nokkelfeltet er typisk kommunenummer.\nLa oss si at du har et datasett med befolkningstall per kommune:\n\n# Eksempel: les inn dine data\nmine_data &lt;- data.frame(\n  kommunenummer = c(\"0301\", \"1103\", \"4601\", \"5001\"),\n  innbyggere = c(709037, 144704, 291189, 212660),\n  kommune = c(\"Oslo\", \"Stavanger\", \"Bergen\", \"Trondheim\")\n)\n\n# Koble til kartdata\nkart_med_data &lt;- kommuner %&gt;%\n  left_join(mine_data, by = \"kommunenummer\")\n\n# Plott\nggplot(kart_med_data) +\n  geom_sf(aes(fill = innbyggere)) +\n  scale_fill_viridis_c(labels = scales::comma) +\n  theme_minimal() +\n  labs(fill = \"Innbyggere\")\n\nMerk at kolonnenavnet for kommunenummer ma vaere likt i begge datasettene. Sjekk ogsa at formatet er det samme (f.eks. at begge er tekststrenger med ledende nuller).",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#legge-til-punkter-pa-kartet",
    "href": "kart.html#legge-til-punkter-pa-kartet",
    "title": "7  Kart og romlige data",
    "section": "7.6 Legge til punkter pa kartet",
    "text": "7.6 Legge til punkter pa kartet\nNoen ganger onsker du a plotte enkeltlokasjoner pa kartet, for eksempel hendelser eller institusjoner. Da trenger du koordinater (lengde- og breddegrad) som du gjor om til et sf-objekt med st_as_sf().\n\nsteder &lt;- data.frame(\n  navn = c(\"Oslo\", \"Bergen\", \"Trondheim\", \"Tromso\"),\n  lon = c(10.75, 5.33, 10.40, 18.96),\n  lat = c(59.91, 60.39, 63.43, 69.65)\n)\n\n# Gjor om til sf-objekt med koordinatreferansesystem WGS84 (EPSG:4326)\nsteder_sf &lt;- st_as_sf(steder, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# Transformer til samme CRS som kartdataene\nsteder_sf &lt;- st_transform(steder_sf, st_crs(kommuner))\n\nNa kan du legge punktene opppa kartet som et eget lag:\n\nggplot() +\n  geom_sf(data = kommuner, fill = \"grey90\", color = \"grey70\") +\n  geom_sf(data = steder_sf, color = \"red\", size = 3) +\n  theme_minimal()\n\nLegg merke til at vi her bruker ggplot() uten a spesifisere data forst, og i stedet angir data = i hvert geom_sf()-lag. Det gir oss full kontroll over hvilke datasett som brukes i hvert lag.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#koordinatreferansesystemer-crs",
    "href": "kart.html#koordinatreferansesystemer-crs",
    "title": "7  Kart og romlige data",
    "section": "7.7 Koordinatreferansesystemer (CRS)",
    "text": "7.7 Koordinatreferansesystemer (CRS)\nAlle geografiske data har et koordinatreferansesystem (CRS) som sier noe om hvordan posisjoner pa jordkloden er representert. De to viktigste a vite om er:\n\nEPSG:4326 (WGS84): Lengde- og breddegrad i grader. Dette er det GPS bruker og det du finner pa Google Maps.\nEPSG:25833 (UTM sone 33N): Et projisert system i meter som er vanlig for norske kartdata. Geonorge bruker typisk dette.\n\nHvis du skal kombinere data med ulike CRS, ma du transformere til samme system:\n\n# Sjekk CRS\nst_crs(kommuner)\n\n# Transformer til en annen CRS\nkommuner_wgs84 &lt;- st_transform(kommuner, 4326)\n\nI praksis trenger du sjelden a tenke sa mye pa dette sa lenge du transformer til samme system for du kombinerer datasett.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#interaktive-kart-med-leaflet",
    "href": "kart.html#interaktive-kart-med-leaflet",
    "title": "7  Kart og romlige data",
    "section": "7.8 Interaktive kart med leaflet",
    "text": "7.8 Interaktive kart med leaflet\nNoen ganger er det nyttig med et interaktivt kart der man kan zoome og klikke. Pakken leaflet gjor dette enkelt:\n\ninstall.packages(\"leaflet\")\n\n\nlibrary(leaflet)\n\n# Leaflet bruker WGS84, sa vi transformer forst\nkommuner_ll &lt;- st_transform(kommuner, 4326)\n\nleaflet(kommuner_ll) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(\n    fillColor = \"steelblue\",\n    weight = 1,\n    color = \"white\",\n    fillOpacity = 0.5\n  )\n\nLeaflet-kart fungerer best i HTML-dokumenter og er saerlig nyttige nar du utforsker dataene selv. De er ikke egnet for trykte rapporter.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#kilder-til-norske-geodata",
    "href": "kart.html#kilder-til-norske-geodata",
    "title": "7  Kart og romlige data",
    "section": "7.9 Kilder til norske geodata",
    "text": "7.9 Kilder til norske geodata\nFor norske kartdata finnes det flere gode kilder:\n\nGeonorge (geonorge.no): Norges nasjonale portal for geografiske data. Her finner du kommunegrenser, fylkesgrenser, kystlinjer og mye mer. Data er gratis og tilgjengelig i flere formater.\nSSB (ssb.no): Statistisk sentralbyra tilbyr kartdata tilpasset deres statistikk, inkludert grunnkretser og delomrader.\nKartverket (kartverket.no): Forvalter de offisielle kartdataene i Norge og tilbyr bl.a. topografiske data, stedsnavn og eiendomsdata.\n\nTil vanlig bruk i samfunnsvitenskapelige analyser er kommunegrensene fra Geonorge det du oftest trenger. Husk at kommuneinndelingen endrer seg over tid (kommunesammenslaainger), sa pass pa at kartdataene matcher tidsperioden i dine analysedata.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#praktisk-eksempel-kriminalitetskart-over-oslo",
    "href": "kart.html#praktisk-eksempel-kriminalitetskart-over-oslo",
    "title": "7  Kart og romlige data",
    "section": "7.10 Praktisk eksempel: kriminalitetskart over Oslo",
    "text": "7.10 Praktisk eksempel: kriminalitetskart over Oslo\nLa oss na bruke det vi har laert til a lage et kriminalitetskart. Vi bruker en shapefil med Oslos 16 bydeler og et datasett med syntetiske kriminalitetshendelser som har x/y-koordinater. Dataene er generert for undervisningsformel, men illustrerer en realistisk arbeidsflyt for romlig analyse.\n\n7.10.1 Lese inn shapefil\nShapefiler er et vanlig format for geografiske data. De bestar egentlig av flere filer (.shp, .dbf, .prj, .shx), men st_read() handterer dette automatisk – du peker bare pa .shp-filen:\n\noslo &lt;- st_read(\"data/shapefiles/oslo.shp\", quiet = TRUE)\n\n\nglimpse(oslo)\n\nRows: 16\nColumns: 5\n$ AREA       &lt;dbl&gt; 13752297, 7727095, 8257591, 7506340, 4752848, 7041704, 1224…\n$ PERIMETER  &lt;dbl&gt; 24549.228, 15484.756, 28349.785, 37783.397, 12090.874, 2304…\n$ KODE       &lt;chr&gt; \"030112\", \"030109\", \"030105\", \"030101\", \"030102\", \"030110\",…\n$ BYDELSNAVN &lt;chr&gt; \"ALNA\", \"BJERKE\", \"FROGNER\", \"GAMLE OSLO\", \"GRÜNERLØKKA\", \"…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((268660.9 66..., MULTIPOLYGON (…\n\n\nVi ser at datasettet har 16 rader (en per bydel) med bydelskode, bydelsnavn og geometri. Geometrikolonnen inneholder polygonene som tegner bydelsgrensene.\n\n\n7.10.2 Grunnkart over Oslo\nLa oss bygge opp et kart steg for steg, akkurat som med vanlig ggplot.\nDet enkleste mulige kartet:\n\nggplot(oslo) +\n  geom_sf()\n\n\n\n\n\n\n\n\ngeom_sf() forstar geometrien automatisk – du trenger ikke spesifisere x- og y-akser. La oss forbedre utseendet:\n\nggplot(oslo) +\n  geom_sf(fill = \"gray95\") +\n  theme_void()\n\n\n\n\n\n\n\n\ntheme_void() fjerner akser og bakgrunn, som passer bedre for kart enn theme_minimal(). Na lagrer vi grunnkartet i et objekt slik at vi kan legge nye lag oppa:\n\nkart &lt;- ggplot(oslo) +\n  geom_sf(fill = \"gray95\") +\n  coord_sf(datum = st_crs(oslo)) +\n  theme_void()\nkart\n\n\n\n\n\n\n\n\ncoord_sf(datum = st_crs(oslo)) sorger for at projeksjonen matcher kartdataene.\n\n\n7.10.3 Lese inn og utforske kriminalitetsdata\nNa leser vi inn kriminalitetsdataene. Disse er lagret som en RDS-fil, som er et R-format vi har sett tidligere:\n\nkrim &lt;- readRDS(\"data/shapefiles/syntetisk_krim.rds\")\n\n\nhead(krim)\n\n    saksnr krimtypekodenavn  aar maaned dag time      x       y\n1 14039877     05 NARKOTIKA 2017    Mar   4   21 270800 6653100\n2 13917288          03 VOLD 2016    Nov   2    3 261900 6649700\n3 14377224     05 NARKOTIKA 2018    Feb   6   20 262900 6649300\n4 13796941       02 VINNING 2016    Jul   3   23 262500 6649700\n5 14406573       02 VINNING 2017    Apr   7    0 264300 6649700\n6 14449912       02 VINNING 2018    May   4   14 261100 6649100\n\n\n\nglimpse(krim)\n\nRows: 198,365\nColumns: 8\n$ saksnr           &lt;dbl&gt; 14039877, 13917288, 14377224, 13796941, 14406573, 144…\n$ krimtypekodenavn &lt;chr&gt; \"05 NARKOTIKA\", \"03 VOLD\", \"05 NARKOTIKA\", \"02 VINNIN…\n$ aar              &lt;dbl&gt; 2017, 2016, 2018, 2016, 2017, 2018, 2018, 2017, 2016,…\n$ maaned           &lt;chr&gt; \"Mar\", \"Nov\", \"Feb\", \"Jul\", \"Apr\", \"May\", \"Mar\", \"Sep…\n$ dag              &lt;dbl&gt; 4, 2, 6, 3, 7, 4, 6, 5, 6, 5, 3, 6, 2, 3, 3, 5, 3, 1,…\n$ time             &lt;dbl&gt; 21, 3, 20, 23, 0, 14, 0, 0, 0, 14, 12, 21, 0, 18, 0, …\n$ x                &lt;dbl&gt; 270800, 261900, 262900, 262500, 264300, 261100, 26400…\n$ y                &lt;dbl&gt; 6653100, 6649700, 6649300, 6649700, 6649700, 6649100,…\n\n\n\ntable(krim$krimtypekodenavn)\n\n\n  02 VINNING      03 VOLD 05 NARKOTIKA 06 SKADEVERK \n      119387        29921        27455        21602 \n\n\nDatasettet har omtrent 198 000 hendelser. Hver rad er en kriminell hendelse med koordinater (x og y i UTM-meter), kriminalitetstype, ar, maned, ukedag og klokkeslett. Koordinatene er avrundet til 100-meters ruter.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#punktkart",
    "href": "kart.html#punktkart",
    "title": "7  Kart og romlige data",
    "section": "7.11 Punktkart",
    "text": "7.11 Punktkart\nDen enkleste maten a vise hendelsene pa kartet er a plotte hvert punkt:\n\nkart +\n  geom_point(data = krim, aes(x = x, y = y),\n             color = \"red\", alpha = 0.01, size = 0.01)\n\n\n\n\n\n\n\n\nMed alpha = 0.01 (nesten gjennomsiktig) og size = 0.01 (sma punkter) kan vi vise alle hendelsene uten at kartet blir helt rodt. Tettere omrader far sterkere farge fordi mange halvgjennomsiktige punkter legges oppa hverandre.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#rasterkart-heatmap",
    "href": "kart.html#rasterkart-heatmap",
    "title": "7  Kart og romlige data",
    "section": "7.12 Rasterkart (heatmap)",
    "text": "7.12 Rasterkart (heatmap)\nPunktkartet over er nyttig for a se det overordnede monsteret, men for a sammenligne omrader mer presist trenger vi a aggregere dataene. Siden koordinatene allerede er avrundet til 100-meters ruter, kan vi telle antall hendelser per rute:\n\nkrimplot &lt;- krim %&gt;%\n  group_by(x, y) %&gt;%\n  summarise(antall = n()) %&gt;%\n  mutate(antall = ifelse(antall &gt;= 200, 200, antall))\n\nVi begrenser verdiene til maksimalt 200 for a unnga at noen ekstremt tette ruter (typisk sentrum) dominerer hele fargeskalaen.\nNa kan vi lage et rasterkart der hver rute er fargelagt etter antall hendelser:\n\nggplot(krimplot, aes(x = x, y = y, fill = antall)) +\n  geom_tile() +\n  coord_sf(datum = st_crs(oslo)) +\n  theme_void() +\n  scale_fill_distiller(palette = \"Spectral\")\n\n\n\n\n\n\n\n\ngeom_tile() tegner en firkant per rute, fargelagt etter antall hendelser. scale_fill_distiller(palette = \"Spectral\") gir en fargeskala som gar fra blatt (fa hendelser) til rodt (mange hendelser).\nFor bedre kontekst legger vi til Oslos omriss oppa heatmapen:\n\noslo_omkr &lt;- st_union(oslo)\n\nkart +\n  geom_tile(data = krimplot, aes(x = x, y = y, fill = antall), alpha = 0.75) +\n  scale_fill_distiller(palette = \"Spectral\") +\n  geom_sf(data = oslo_omkr, color = \"black\", fill = NA) +\n  labs(fill = \"Hendelser\")\n\n\n\n\n\n\n\n\nst_union() slar sammen alle bydelspolygonene til en ytre grense. fill = NA gjor at bare grenselinjen tegnes, slik at heatmapen synes gjennom. Merk at vi bruker grunnkartet (kart) som utgangspunkt og legger nye lag oppa – akkurat samme prinsipp som med vanlige ggplot-figurer.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#oppdelt-etter-kriminalitetstype",
    "href": "kart.html#oppdelt-etter-kriminalitetstype",
    "title": "7  Kart og romlige data",
    "section": "7.13 Oppdelt etter kriminalitetstype",
    "text": "7.13 Oppdelt etter kriminalitetstype\nMed facet_wrap() kan vi lage ett delkart per kriminalitetstype. Vi aggregerer pa nytt, men na ogsa gruppert etter type:\n\nkrimplot_type &lt;- krim %&gt;%\n  group_by(x, y, krimtypekodenavn) %&gt;%\n  summarise(antall = n()) %&gt;%\n  mutate(antall = ifelse(antall &gt;= 150, 150, antall))\n\nkart +\n  geom_tile(data = krimplot_type, aes(x = x, y = y, fill = antall), alpha = 0.75) +\n  scale_fill_distiller(palette = \"Spectral\") +\n  geom_sf(data = oslo_omkr, color = \"black\", fill = NA) +\n  facet_wrap(~krimtypekodenavn) +\n  labs(fill = \"Hendelser\")\n\n\n\n\n\n\n\n\nNa ser vi at de ulike kriminalitetstypene har svart forskjellig geografisk fordeling. Vinningskriminalitet er spredt over hele byen, mens narkotika er mer konsentrert. facet_wrap() fungerer pa kart akkurat som pa vanlige ggplot-figurer.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "kart.html#oppsummering",
    "href": "kart.html#oppsummering",
    "title": "7  Kart og romlige data",
    "section": "7.14 Oppsummering",
    "text": "7.14 Oppsummering\nKart i R folger samme logikk som annen ggplot-grafikk: du har data, du velger en geometrisk form (geom_sf()), og du tilpasser utseendet. Med sf-pakken kan du lese inn kartfiler, koble pa dine egne data, og lage bade statiske og interaktive kart. De viktigste funksjonene a huske er:\n\n\n\nFunksjon\nHva den gjor\n\n\n\n\nst_read()\nLeser inn geografiske data\n\n\ngeom_sf()\nPlotter sf-objekter i ggplot\n\n\nst_as_sf()\nGjor vanlig data.frame om til sf-objekt\n\n\nst_transform()\nEndrer koordinatreferansesystem\n\n\nst_crs()\nSjekker koordinatreferansesystemet\n\n\nst_union()\nSlar sammen geometrier til en\n\n\ngeom_tile()\nTegner rasterkart (heatmap)\n\n\nfacet_wrap()\nDeler kartet opp etter en variabel",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Kart og romlige data</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html",
    "href": "nettverksanalyse.html",
    "title": "8  Nettverksanalyse",
    "section": "",
    "text": "8.1 Hva er et nettverk?\nNettverksanalyse handler om relasjoner mellom enheter. Mens vi i regresjonsanalyse fokuserer på egenskaper ved individer (f.eks. alder, inntekt, utdanning), fokuserer nettverksanalyse på forbindelsene mellom dem. Hvem kjenner hvem? Hvem samarbeider med hvem? Hvilke organisasjoner har overlappende styremedlemmer? Dette er typiske sporsmal som nettverksanalyse kan belyse.\nEt nettverk bestar av to grunnleggende byggeklosser: noder og kanter. Nodene er enhetene i nettverket (f.eks. personer, organisasjoner, land), mens kantene er forbindelsene mellom dem (f.eks. vennskap, handelsrelasjoner, kommunikasjon).\nI samfunnsvitenskap er vi ofte interessert i sosiale nettverk, der nodene er personer og kantene representerer en eller annen form for relasjon. Men nettverksanalyse brukes ogsa pa mange andre typer data.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#typer-nettverk",
    "href": "nettverksanalyse.html#typer-nettverk",
    "title": "8  Nettverksanalyse",
    "section": "8.2 Typer nettverk",
    "text": "8.2 Typer nettverk\nDet finnes ulike typer nettverk, og det er viktig a vite hvilken type man jobber med:\n\nUrettet nettverk: Kantene gar begge veier. Vennskap er et typisk eksempel: hvis A er venn med B, sa er B venn med A.\nRettet nettverk: Kantene har en retning. Twitter-folging er et eksempel: A kan folge B uten at B folger A tilbake.\nVektet nettverk: Kantene har en styrke. F.eks. kan man vekte etter hvor mange ganger to personer har kommunisert.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#lage-nettverksobjekter-med-igraph",
    "href": "nettverksanalyse.html#lage-nettverksobjekter-med-igraph",
    "title": "8  Nettverksanalyse",
    "section": "8.3 Lage nettverksobjekter med igraph",
    "text": "8.3 Lage nettverksobjekter med igraph\nPakken igraph er det mest brukte verktøyet for nettverksanalyse i R. La oss starte med a lage et lite eksempelnettverk. Tenk deg en liten vennegjeng:\n\nvenner &lt;- graph_from_literal(Anna -- Bjorn,\n                             Anna -- Cecilie,\n                             Bjorn -- Cecilie,\n                             Bjorn -- David,\n                             Cecilie -- Elin,\n                             David -- Elin,\n                             David -- Fredrik)\nvenner\n\nIGRAPH 1d7292d UN-- 6 7 -- \n+ attr: name (v/c)\n+ edges from 1d7292d (vertex names):\n[1] Anna   --Bjorn   Anna   --Cecilie Bjorn  --Cecilie Bjorn  --David  \n[5] Cecilie--Elin    David  --Elin    David  --Fredrik\n\n\nHer har vi laget et urettet nettverk med seks personer og syv relasjoner. Dobbel bindestrek -- betyr urettet kant. Hadde vi brukt +-+ ville det blitt rettet.\nVi kan plotte dette med en gang:\n\nplot(venner,\n     vertex.color = \"lightblue\",\n     vertex.size = 30,\n     vertex.label.cex = 0.9,\n     edge.color = \"gray50\",\n     main = \"Vennenettverket\")",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#kantlister-og-nabomatriser",
    "href": "nettverksanalyse.html#kantlister-og-nabomatriser",
    "title": "8  Nettverksanalyse",
    "section": "8.4 Kantlister og nabomatriser",
    "text": "8.4 Kantlister og nabomatriser\nI praksis lager man sjelden nettverk for hand slik som ovenfor. Data kommer ofte som en kantliste (edge list), som er en tabell med to kolonner: fra-node og til-node. Hver rad representerer en forbindelse mellom to noder.\nLa oss lese inn det samme vennenettverket fra en CSV-fil:\n\nkantliste &lt;- read_csv(\"data/venner_kantliste.csv\")\n\nLa oss se pa datastrukturen:\n\nkantliste\n\n# A tibble: 7 × 2\n  fra     til    \n  &lt;chr&gt;   &lt;chr&gt;  \n1 Anna    Bjorn  \n2 Anna    Cecilie\n3 Bjorn   Cecilie\n4 Bjorn   David  \n5 Cecilie Elin   \n6 David   Elin   \n7 David   Fredrik\n\n\nKantlisten er en helt vanlig tabell med to kolonner: fra og til. Hver rad er en kant i nettverket. Dette er den vanligste maten a lagre nettverksdata pa, og formatet er lett a lage i Excel eller eksportere fra andre systemer.\nFra en slik kantliste kan vi lage et nettverksobjekt:\n\ng &lt;- graph_from_data_frame(kantliste, directed = FALSE)\nplot(g,\n     vertex.color = \"lightblue\",\n     vertex.size = 30,\n     vertex.label.cex = 0.9)\n\n\n\n\n\n\n\n\nEn annen vanlig representasjon er en nabomatrise (adjacency matrix), der radene og kolonnene er noder, og cellene angir om det er en kant mellom dem (1) eller ikke (0):\n\nas_adjacency_matrix(g, sparse = FALSE)\n\n        Anna Bjorn Cecilie David Elin Fredrik\nAnna       0     1       1     0    0       0\nBjorn      1     0       1     1    0       0\nCecilie    1     1       0     0    1       0\nDavid      0     1       0     0    1       1\nElin       0     0       1     1    0       0\nFredrik    0     0       0     1    0       0\n\n\nNabomatrisen er symmetrisk fordi nettverket er urettet. For rettede nettverk ville matrisen typisk ikke vaert symmetrisk.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#nettverksmaal",
    "href": "nettverksanalyse.html#nettverksmaal",
    "title": "8  Nettverksanalyse",
    "section": "8.5 Nettverksmaal",
    "text": "8.5 Nettverksmaal\nNettverksanalyse tilbyr en rekke mal for a beskrive bade hele nettverket og enkeltnoders posisjon. Her ser vi pa tre av de mest sentrale:\n\n8.5.1 Grad (degree)\nGrad er det enkleste malet: hvor mange kanter har en node? I et vennskapsnettverk betyr det rett og slett hvor mange venner en person har.\n\ndegree(g)\n\n   Anna   Bjorn Cecilie   David    Elin Fredrik \n      2       3       3       3       2       1 \n\n\nBjorn og David har flest forbindelser, mens Fredrik bare har en.\n\n\n8.5.2 Mellomleddsentralitet (betweenness)\nMellomleddsentralitet maler hvor ofte en node ligger pa den korteste veien mellom andre noder. En person med hay mellomleddsentralitet fungerer som en bro i nettverket.\n\nbetweenness(g)\n\n   Anna   Bjorn Cecilie   David    Elin Fredrik \n    0.0     3.0     1.5     4.5     1.0     0.0 \n\n\n\n\n8.5.3 Naerhetssentralitet (closeness)\nNaerhetssentralitet maler hvor naer en node er alle andre noder i nettverket. En person med hay naerhetssentralitet kan na alle andre raskt.\n\ncloseness(g)\n\n      Anna      Bjorn    Cecilie      David       Elin    Fredrik \n0.11111111 0.14285714 0.12500000 0.14285714 0.12500000 0.09090909 \n\n\nLa oss samle disse malene i en tabell:\n\nsentralitet &lt;- tibble(\n  navn = V(g)$name,\n  grad = degree(g),\n  mellomled = round(betweenness(g), 1),\n  naerhet = round(closeness(g), 3)\n)\nsentralitet\n\n# A tibble: 6 × 4\n  navn     grad mellomled naerhet\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Anna        2       0     0.111\n2 Bjorn       3       3     0.143\n3 Cecilie     3       1.5   0.125\n4 David       3       4.5   0.143\n5 Elin        2       1     0.125\n6 Fredrik     1       0     0.091\n\n\nVi ser at Bjorn og David skiller seg ut som de mest sentrale personene i dette nettverket, uansett hvilket mal vi bruker.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#visualisering-med-ggraph",
    "href": "nettverksanalyse.html#visualisering-med-ggraph",
    "title": "8  Nettverksanalyse",
    "section": "8.6 Visualisering med ggraph",
    "text": "8.6 Visualisering med ggraph\nFor finere grafisk kontroll kan vi bruke pakken ggraph, som bygger pa ggplot-logikken:\n\nlibrary(ggraph)\n\nggraph(g, layout = \"fr\") +\n  geom_edge_link(color = \"gray60\") +\n  geom_node_point(size = 8, color = \"steelblue\") +\n  geom_node_text(aes(label = name), repel = TRUE, size = 4) +\n  theme_void() +\n  ggtitle(\"Vennenettverket med ggraph\")\n\n\n\n\n\n\n\n\nHer bruker vi Fruchterman-Reingold-algoritmen (layout = \"fr\") for a plassere nodene. geom_edge_link() tegner kantene, geom_node_point() tegner nodene, og geom_node_text() legger pa navnene. Merk at dette folger ggplot-logikken med lag oppå lag.\nVi kan ogsa la nodestorrelsen reflektere grad:\n\nggraph(g, layout = \"fr\") +\n  geom_edge_link(color = \"gray60\") +\n  geom_node_point(aes(size = degree(g)), color = \"steelblue\") +\n  geom_node_text(aes(label = name), repel = TRUE, size = 4) +\n  scale_size_continuous(range = c(4, 12), name = \"Grad\") +\n  theme_void()",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#samfunnsdeteksjon",
    "href": "nettverksanalyse.html#samfunnsdeteksjon",
    "title": "8  Nettverksanalyse",
    "section": "8.7 Samfunnsdeteksjon",
    "text": "8.7 Samfunnsdeteksjon\nEn vanlig oppgave i nettverksanalyse er a identifisere grupper (communities/klynger) av noder som er tettere knyttet til hverandre enn til resten av nettverket. Det finnes flere algoritmer for dette. Her bruker vi en enkel metode:\n\ngrupper &lt;- cluster_walktrap(g)\nmembership(grupper)\n\n   Anna   Bjorn Cecilie   David    Elin Fredrik \n      2       2       2       1       1       1 \n\n\nVi kan fargelegge nettverket etter gruppemedlemskap:\n\nplot(grupper, g,\n     vertex.size = 30,\n     vertex.label.cex = 0.9,\n     main = \"Grupper i vennenettverket\")",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#praktisk-eksempel-samarbeidsnettverk",
    "href": "nettverksanalyse.html#praktisk-eksempel-samarbeidsnettverk",
    "title": "8  Nettverksanalyse",
    "section": "8.8 Praktisk eksempel: samarbeidsnettverk",
    "text": "8.8 Praktisk eksempel: samarbeidsnettverk\nTenk deg et forskningssamarbeid mellom ansatte pa et institutt. Vi leser inn en kantliste der hver rad er et samarbeid mellom to forskere, og kolonnen antall_artikler angir hvor mange felles artikler de har:\n\nsamarbeid &lt;- read_csv(\"data/samarbeid_kantliste.csv\")\n\nLa oss se pa datastrukturen:\n\nsamarbeid\n\n# A tibble: 11 × 3\n   forsker1 forsker2 antall_artikler\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Ola      Kari                   5\n 2 Ola      Per                    2\n 3 Kari     Liv                    3\n 4 Kari     Mona                   1\n 5 Per      Jan                    4\n 6 Liv      Jan                    6\n 7 Liv      Mona                   2\n 8 Liv      Ola                    1\n 9 Jan      Mona                   3\n10 Jan      Ola                    1\n11 Mona     Per                    1\n\n\nDenne kantlisten har tre kolonner: forsker1 og forsker2 angir hvem som samarbeider, mens antall_artikler er en vekt som sier noe om styrken pa relasjonen. Slike vektede kantlister er svart vanlige i praksis.\nNa kan vi lage et nettverksobjekt og bruke vektene:\n\ng2 &lt;- graph_from_data_frame(samarbeid, directed = FALSE)\nE(g2)$weight &lt;- samarbeid$antall_artikler\n\nggraph(g2, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.6, color = \"gray40\") +\n  geom_node_point(aes(size = degree(g2)), color = \"tomato\") +\n  geom_node_text(aes(label = name), repel = TRUE, size = 4) +\n  scale_edge_width_continuous(range = c(0.5, 3), name = \"Artikler\") +\n  scale_size_continuous(range = c(4, 12), name = \"Grad\") +\n  theme_void() +\n  ggtitle(\"Samarbeidsnettverk\")\n\n\n\n\n\n\n\n\nHer ser vi at kanttykkelsen viser antall felles artikler, mens nodestorrelsen viser antall samarbeidspartnere. Liv og Jan ser ut til a vaere sentrale i dette nettverket.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "nettverksanalyse.html#nar-er-nettverksanalyse-nyttig",
    "href": "nettverksanalyse.html#nar-er-nettverksanalyse-nyttig",
    "title": "8  Nettverksanalyse",
    "section": "8.9 Nar er nettverksanalyse nyttig?",
    "text": "8.9 Nar er nettverksanalyse nyttig?\nNettverksanalyse er et godt valg nar:\n\nDu er interessert i relasjoner mellom enheter, ikke bare egenskaper ved enhetene selv.\nDu vil identifisere sentrale aktorer i et nettverk (f.eks. nøkkelpersoner i en organisasjon).\nDu vil forstå hvordan informasjon eller innflytelse sprer seg.\nDu vil finne grupper eller klynger i data.\nDu vil studere strukturen i et sosialt system.\n\nNettverksanalyse er mye brukt i sosiologi, statsvitenskap, kriminologi, folkehelse og mange andre fagfelt. Det er et kraftig verktoy for a forstå sosiale strukturer som ikke lar seg fange med tradisjonelle regresjonsmodeller.",
    "crumbs": [
      "Del II: Deskriptiv analyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettverksanalyse</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html",
    "href": "lineaer_regresjon.html",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "",
    "text": "9.1 Scatterplot\nVi skal her se på helt grunnleggende lineær regresjon med en og to forklaringsvariable.\nBivariat regresjon beskriver sammenhengen mellom to variable. En naturlig start er å se på et scatterplot. Her er en figur som viser hvordan timelønn varierer med alder. I det nedenforstående er det brukt jitter og gjennomsiktig farge for å håndtere overplotting.\nI tillegg er det tegnet inn en linje som illustrerer trenden i gjennomsnittlig lønn med alder. Denne linjen skrår svakt oppover, som altså betyr at gjennomsnittlig lønn øker noe med alder. Vi ser med det blotte øyet at en rett linje ikke beskriver denne sammenhengen perfekt. Først og fremst er det en stor variasjon rundt denne linjen, så det er mye annet som påvirker lønna enn alder. Det er også verd å legge merke til at i de yngste aldersgruppene er lønna en god del lavere - og kanskje litt lavere i eldste aldersgrupper også. Så en rett linje er kanskje ikke optimalt i utgangspunktet. Fordelen med en rett linje er at vi kan si noe slikt som at “gjennosmsnittslønna øker med x antall kroner for hvert år eldre man blir”. Hvis linja er kurvlineær blir det litt mer komplisert. Så et første poeng er at en slik linje er en forenkling, og det er en tilsiktet forenkling.\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\nDet er en viss tendens til at lønnen øker med alder, men det er ikke helt lett å si hvor mye. Poenget med lineær regresjon er å beskrive en gjennomsnittlig trend.\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\nDenne trendlinja er hva vi vanligvis kaller regresjonslinje.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#regresjonslinja",
    "href": "lineaer_regresjon.html#regresjonslinja",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.2 Regresjonslinja",
    "text": "9.2 Regresjonslinja\nRegresjonslinja kan beskrives med et stigningstall, som sier hvor bratt linjen er. Substansielt sett betyr det hvor mye utfallsvariabelen (y-aksen) endres med økning i forklaringsvariabelen (x-aksen). I tillegg trenger vi også vite hvor høyt/lavt linjen ligger.1 Til det bruker vi startpunktet for linjen, der hvor \\(x\\) har verdien 0. Dette må regnes ut, og det er akkurat dette estimering av lineær regresjon gir oss.\nUtregningen av regresjonslinja går vi ikke inn på her, men intuitivt sett ønsker vi jo den beste linja og ikke en hvilken som helst omtrentlig linje. Datapunktene (de svarte punktene i grafen) er spredt rundt linja, og avstanden mellom linje og punkt kalles residualer. Summen av disse residualene er grunnlaget for mål på hvor godt regresjonslinja beskriver de faktiske dataene. Den beste linja er definert som den som minimerer residualene. Det er dette som kalles “minste kvadraters metode”.\nI R estimeres regresjonsmodeller med funksjonen lm. Første argument er en formel på formen utfallsvariabel ~ forklaringsvariabel. Rekkefølgen variablene oppgis i er altså viktig. Dernest må det spesifiseres hvilket datasett som skal brukes med data = .2\nLegg alltid resultatene i et eget objekt med et navnt som er rimelig enkelt å forstå hva er. I følgende kode legges resultatet i en nytt objekt lm_est1. Deretter bruker kan man hente ut de delene av resultatet vi er interessert i. I aller første omgang er bare interessert i regresjonslinjas konstantledd (startpunktet) og stigningstall. Disse kaller vi vanligvis regresjonskoeffisienter. Det kan vi få ut ved å bruke funksjonen coef. (Vi kommer tilbake til å se på de fulle resultatene senere, som vi oftest er interessert i).\n\nlm_est1 &lt;- lm(time89 ~ age, data = abu89)\ncoef(lm_est1)\n\n(Intercept)         age \n 71.1101883   0.4828415 \n\n\nRegresjonslingningen kan skrives på formel der \\(\\alpha\\) er konstantleddet og \\(\\beta\\) er stigningstallet slik:\n\\[\n\\operatorname{time89} = \\alpha + \\beta_{1}(\\operatorname{age}) + \\epsilon\n\\]\nNår vi setter inn de estimerte koeffisientene inn i ligningen får vi følgende:\n\\[\n\\operatorname{\\widehat{time89}} = 71.11 + 0.48(\\operatorname{age})\n\\]\nTolkningen her er at gjennomsnittlig forskjell i timelønn mellom grupper der aldersforskjellen er ett år er 0.48 kroner i favør av den eldre gruppen.3 Merk enheten her: stigningstallet tolkes på den skalaen utfallsvariabelen er på, i dette tilfellet kroner. Det er også uttrykt endring ved at forklaringsvariabelen endres med nøyaktig 1.\nVi sier gjerne at regresjonslinjen er estimert, og det innebærer at det er usikkerhet i estimatene. Vi kommer tilbake til dette, men en vanligere output fra regresjonsmodeller er å bruke funksjonen summary. Da får man med mye mer detaljer og output vil se ut som følger:\n\nsummary(lm_est1)\n\n\nCall:\nlm(formula = time89 ~ age, data = abu89)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-69.287 -19.131  -6.304  12.864 255.258 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 71.11019    1.62232   43.83   &lt;2e-16 ***\nage          0.48284    0.03926   12.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.73 on 3757 degrees of freedom\n  (368 observations deleted due to missingness)\nMultiple R-squared:  0.0387,    Adjusted R-squared:  0.03844 \nF-statistic: 151.2 on 1 and 3757 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#dummy-variable",
    "href": "lineaer_regresjon.html#dummy-variable",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.3 Dummy-variable",
    "text": "9.3 Dummy-variable\nHvis en forklaringsvariabel har kun to verdier vil vi typisk gi den ene kategorien verdien 0 og den andre kategorien 1. Dette kalles en «dummy variabel» eller en «indikator variabel». For eksempel vil et datasett ofte ha en variabel for kjønn med verdiene «Mann» og «Kvinne». Da kan vi la mann få verdien 0 og kvinne verdien 1. Ofte vil man da gi variabelen et navn som indikerer hvilken verdi som er 1. Så i dette eksempelet er det hensiktsmessig å gi den nye variabelen navnet «Kvinne». I dette eksempelet vil man også kunne si at variabelen er en «dummy for kvinne» (altså: den kategorien som får verdien 1).\nDet spiller ingen rolle hvilken kategori som får verdien 0 og 1. I dette eksempelet kunne man like gjerne gjort det motsatt, og latt det være en «dummy for mann». Da ville det være naturlig å kalle variabelen «mann» i stedet for «kvinne». Som vi skal se nedenfor vil det bare påvirke fortegnet når vi bruker variabelen i en regresjonsanalyse.\nI datasettet abu89 er variabelen “female” en slik variabel som har verdiene 0 eller 1, og der 0 betyr “mann” og 1 betyr “kvinne”.\n\n\n\nKjønn\nFemale\n\n\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\n\nI R vil vi ofte ha slike variable som factor-variable. Da er variabelen definert som kategorisk og selv om det er tekst-verdier i variabelen, så vil R automatisk behandle den som om verdiene var 0 og 1 i estimeringen av regresjonsmodellen.\n\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  select(female, time89) %&gt;% \n  tbl_summary(by = female) \n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0\nN = 2,1931\n1\nN = 1,9341\n\n\n\n\nGjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n\n\n    Unknown\n190\n178\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est_i &lt;- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est_i)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\nRegresjonskoeffisenten for variabelen female uttrykker nettopp differansen mellom menn og kvinner, som er 21 kroner. Husk at \\(\\beta\\) er hvor mye \\(y\\)-variabelen endres når man sammenligner \\(x\\)-variabelen med akkurat 1 enhets forskjell. Her er mann 0 og kvinner 1, så da er dette faktisk 1 enhets forskjell. Altså: når \\(x\\) går fra 0 til 1, så reduseres \\(y\\) med 21. Derfor negativt fortegn.\nI R vil vi ofte gjøre om kategoriske variable til såkalte factor-variable. En factor-variabel vil håndtere kategoriske variable som tekst, men med en underliggende numerisk verdi. Da kan man bruke factor-variable i alle standard analysemetoder. I regresjon vil R automatisk bruke den første kategorien som referansekategori.\nVi kan gjøre den samme analysen med kjønn som en factor variabel og få de samme resultatene som ovenefor.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %&gt;% \n  filter(!is.na(time89))\n\nlm_est2 &lt;- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\n\n9.3.1 Dummy-variable med mer enn en kategori\nNoen ganger har vi forklaringsvariable med flere enn to kategorier. Det kan vi løse på en tilsvarende måte ved å lage flere dummy-variable. Et eksempel kan være sosial klasse. I datasettet abu89 er det fem kategorier.\nEn dummy-variabel har bare to kategorier: 0 og 1, men vi kan lage flere dummy-variable. Vi kan lager en ny variabel «klasse II» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Altså en dummy. Så kan vi lage en ny variabel «Klasse III» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Slik kan man lage en dummy-variabel for hver av kategoriene. Da har vi altså flere dummy-variable som til sammen fanger opp informasjonen i den opprinnelige variabelen.\n\n\n\nUtdanning\nKlasse II\nKlasse III\nKlasse V-VI\nKlasse VII\n\n\n\n\nKlasse I\n0\n0\n0\n0\n\n\nKlasse II\n1\n0\n0\n0\n\n\nKlasse III\n0\n1\n0\n0\n\n\nKlasse V-VI\n0\n0\n1\n0\n\n\nKlasse VII\n0\n0\n0\n1\n\n\n\nMerk at her er det ingen dummy for “Klasse I”. Denne gruppen brukes som referansekategori slik at estimatene for de andre dummyene blir tolkbare som forskjellen til denne referansekategorien. Mer om det siden, men man kan velge å bruke en annen referansekategori hvis man vil.\nLa oss først se på et plot. Her er det brukt en jitter-plot. Den røde linjen viser endring i gjennomsnitt mellom de kategoriene. En regresjonsanalyse vil gi slike estimater på differanser, men det er enklest hvis alle endringene er i forhold til samme referansekategori.\n\nggplot( abu89x, aes(x =klasse89, y = time89))+\n  geom_jitter(alpha = .3, width = .2)+\n  geom_point(aes(y=gr_snitt), col = \"red\", size = 3)+\n  #geom_hline(yintercept = mean(abu89x$time89, na.rm = TRUE))+\n  geom_line(aes(x = as.numeric(klasse89), y = smooth), col = \"red\", linewidth = 1) \n\n\n\n\n\n\n\n\nDen generelle regresjonsligningen skrives som \\(y=a+bx\\), der \\(x\\) er forklaringsvariabelen. Regresjonskoeffisienten, \\(b\\), tolkes som hvor forskjellen i gjennomsnittet på utfallsvariabelen, \\(y\\), mellom de som er en enhets forskjell på \\(x\\)-variabelen.\nSå kan vi kjøre en regresjon og få ut regresjonskoeffisientene på samme måte som før. Akkurat her er coef lagt inn i en parentes for data.frame, men det er bare for at det skal bli en pen kolonne. Vi kommer altså tilbake til teknikker for penere output nedenfor.\n\nest2 &lt;- lm(time89 ~ klasse89, data = abu89)  \ndata.frame(coef(est2)) \n\n                                 coef.est2.\n(Intercept)                       118.39851\nklasse89II Nedre serviceklasse    -14.49078\nklasse89III Rutinefunksjonærer    -42.89842\nklasse89V-VI Faglærte arbeidere   -29.68788\nklasse89VIIa Ufaglærte arbeidere  -36.95234\n\n\nHvert estimat for kategori for klasse sammenlignes med den første kategorien (altså den som mangler): klasse I. Det betyr at klasse VII (ufaglærte arbeidere) har en timelønn på -37 kroner mindre enn klasse I (øvre serviceklasse). Mens klasse II (nedre serviceklasse) tjener -14.5 kroner mindre enn klasse I.\nForskjellen mellom andre grupper er således differansen mellom disse estimatene. Altså: klasse VII tjener mindre enn klasse V-VI: \\(36.9 - 29.7 = 7.2\\) kroner. Se på plottet over, så ser du at disse tallene ser riktige ut.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#flere-variable",
    "href": "lineaer_regresjon.html#flere-variable",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.4 Flere variable",
    "text": "9.4 Flere variable\nDet er ikke så ofte vi bruker regresjon med bare en forklaringsvariabel, såklat “enkel lineær regresjon”.4 Langt mer vanlig er å bruke flere variable samtidig i det vi kaller “multippel regresjon”.5 I multippel regresjon kan man altså beskrive mer kompliserte mønstre i dataene.\nVi fortsetter med eksempelet om lønn og alder, men utvider med en dimensjon til, nemlig kjønn. La oss først se på kjønnsforskjellene i gjennomsnittlig timelønn.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %&gt;% \n  filter(!is.na(time89))\n\nabu89 %&gt;% \n  select(sex, time89) %&gt;% \n  tbl_summary(by = sex) \n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMale\nN = 2,0031\nFemale\nN = 1,7561\n\n\n\n\nGjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est2 &lt;- lm(time89 ~ sex , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)   sexFemale \n   99.84382   -20.75229 \n\n\nDet er altså slik at koeffisienten, \\(\\beta\\), gir den samme differansen som en enkel sammenligning av to gjennomsnitt.\nVi har allerede sett på alder og lønn, så vi kan utvide dette til å inkludere kjønn samtidig i et scatterplot.\nGrafisk er det da greit å bruke farger og slik vise for menn og kvinner for seg. I ggplot spesifiseres da group = sex og at fargene skal settes etter sammen grupperingen col = sex slik:\n\nggplot(abu89, aes(x = age, y = time89, group = sex, col = sex)) +\n  geom_jitter(alpha = .4)\n\n\n\n\n\n\n\n\n\nlm_est3 &lt;- lm(time89 ~ sex + age, data = abu89)\n\ncoef(lm_est3)\n\n(Intercept)   sexFemale         age \n 81.1014711 -20.6251051   0.4738042 \n\n\n\n9.4.1 Interaksjonsledd\nDet kan tenkes at hvordan inntekten varierer med alder er forskjellig for menn og kvinner. I modellen ovenfor er det derimot antatt at denne er lik. Vi kan beskrive forskjellen i aldersgradienten i inntekt mellom menn og kvinner ved å inkludere interaksjonsledd (samspill) mellom kjønn og alder.\nDette gjør vi ved å spesifisere en regresjonslikning som følger:\n\\[\ntime89 = \\alpha + \\beta_{1}(age) + \\beta_{2}(sex) + \\beta_{3}(age \\times sex)\n\\] Eller med andre ord: timelønn varierer med alder og kjønn, og kombinasjonen av disse. Merk hvordan dette skrives i R:\n\nlm_est4 &lt;- lm(time89 ~ sex + age + sex * age, data = abu89)\n\ncoef(lm_est4)\n\n  (Intercept)     sexFemale           age sexFemale:age \n   75.8535901    -9.9048054     0.6064699    -0.2719530 \n\n\nMerk nå at referansekategorien for kjønn er menn, så den estimerte koeffisienten er for kvinner. Det betyr at i utregningen får menn verdien 0 og kvinner får verdien 1. Sette man det inn i regresjonslikningen for menn blir det da som følger:\n\\[\ntime89 = \\alpha + \\beta_{1}(age) + \\beta_{2}\\times 0 + \\beta_{3}(age \\times 0)\n\\] Siden alt som multipliseres med 0 blir 0 kan vi også skrive dette som:\n\\[\ntime89 = \\alpha + \\beta_{1}(age)\n\\] For kvinner skal det derimot multipliseres med 1 og vi får:\n\\[\ntime89 = \\alpha + \\beta_{1}(age) + \\beta_{2}\\times 1 + \\beta_{3}(age \\times 1)\n\\] Det som multipliseres med 1 endres jo ikke, så da kan det skrives som:\n\\[\ntime89 = \\alpha + \\beta_{1}(age) + \\beta_{2} + \\beta_{3}(age)\n\\] Men siden vi har to termer for alder kan det forkortes til:\n\\[\ntime89 = \\alpha + (\\beta_{1} + \\beta_{3})(age) + \\beta_{2}\n\\] Kortere sagt: forskjellen i stigningstallet mellom menn og kvinner er \\(\\beta_{3}\\). I det empiriske eksempelet over betyr det at timelønn øker med alder for begge kjønn, men for kvinner øker det med 0.27 kroner mindre per år sammenlignet med menn. Eller sagt motsatt: menns lønn øker med 0.27 mer enn kvinner per år.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#prediksjon",
    "href": "lineaer_regresjon.html#prediksjon",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.5 Prediksjon",
    "text": "9.5 Prediksjon\nLineær regresjon kan også brukes til prediksjon selv om dette i liten grad er hva samfunnsvitere bruker regresjonsmodeller til. Vanligvis vil vi primært være interessert i å tolke regresjonskoeffisientene som sammenligninger mellom grupper. Man kan si at man da er opptatt av forklaringsvariablene. Når man predikerer er man derimot opptatt av utfallsvariabelen. Hvis man skulle være interessert i temaer som maskinlæring, vil dette være en god inngang til det.6\n\n9.5.1 Regne ut forventet verdi\nMerk at konstantleddet er tolkbart som forventet verdi på utfallsvariabelen når alle andre prediktorer er null. I eksempelet ovenfor med timelønn og klassetilhøringhet, er det altså ikke noen koeffisient for klasse I. Gjennomsnittlig timelønn i klasse I er når de andre dummyene er 0, altså 118.4 kroner. Gjennomsnittlig timelønn for klasse II er tilsvarende 118.4 + (-14.49) = 103.9.\nHvis du skulle gjette timelønna til en person uten å vite noe annet enn klasseposisjon ville det være fornuftig å gjette på gjennomsnittet for denne klassen. Så vi kan bruke regresjonsmodeller til å regne ut gjennomsnittslønn for gitte verdier av forklaringsvariable. I dette eksempelet er det kanskje litt i overkant komplisert da vi jo også bare kunne regnet ut gjennomsnittet per gruppe i en enkel tabell. Det ville faktisk gitt akkurat samme resultat. Det er mer nyttig med kontinuerlige variable og mer kompliserte modeller.\nLa oss se på regresjonsmodellen for hvordan timelønn varierer med alder i stedet. Alder er kontinuerlig, så det er få personer på hvert alderstrinn.\n\ncoef(lm_est1)\n\n(Intercept)         age \n 71.1101883   0.4828415 \n\n\nGjennomsnittlig timelønn ved 30 år vil da være 71.1 + 30 \\(\\times\\) 0.5 = 86.1 kroner. Ved 35 år blir det tilsvarende 71.1 + 35 \\(\\times\\) 0.5 = 88.6 kroner.\nDette kan vi altså regne ut for hånd, men man kan også bruke en r-funksjon, nemlig predict. Denne funksjonen tar som argument et regresjonsobjekt og en data.frame (altså et datasett eller tilsvarende struktur) med samme variabelnavn som ble brukt i opprinnelig regresjonsmodell.7\n\n\n9.5.2 Predikere for kontinuerlig variabel\nKoden nedenfor lager først et datasett med én variabel: alder med noen verdier man er interessert i utregning for. Så bruker man mutate til å lage en kolonne til med predikerte verdier.\n\nnyedata &lt;- data.frame(age = c(17, 20, 30, 40, 50, 60))\n\nnyedata %&gt;% \n  mutate(pred = predict(lm_est1, newdata = nyedata))\n\n  age      pred\n1  17  79.31849\n2  20  80.76702\n3  30  85.59543\n4  40  90.42385\n5  50  95.25226\n6  60 100.08068\n\n\n\n\n9.5.3 Predikere kategorisk variabel\nTilsvarende kan vi predikere for kategoriske variable slik som ble benyttet i regresjonsmodellen for klasse. I det nye datasettet spesifiseres f.eks. alle nivåene av en factor-variabel med funksjonen levels og predikerer for disse.\n\nnyedata &lt;- data.frame(klasse89 = levels(abu89$klasse89))\n\nnyedata %&gt;% \n  mutate(pred = predict(est2, newdata = nyedata))\n\n                  klasse89      pred\n1     I Øvre serviceklasse 118.39851\n2   II Nedre serviceklasse 103.90773\n3   III Rutinefunksjonærer  75.50009\n4  V-VI Faglærte arbeidere  88.71063\n5 VIIa Ufaglærte arbeidere  81.44618\n\n\n\n\n9.5.4 Predikere for multippel regresjon\nNytten av predict-funksjonen kommer mer til sin rett ved mer kompliserte modeller. Her er et eksempel med flere variable:\nSå kan vi regne ut estimert gjennomsnittlig verdi for de ulike kombinasjonene av utvalgte verdier som følger:\n\nnyedata &lt;- expand.grid(age = 30:35, \n                      sex = c(\"Female\", \"Male\"))\nnyedata %&gt;% \n  mutate(pred = predict(lm_est3, newdata = nyedata))\n\n   age    sex     pred\n1   30 Female 74.69049\n2   31 Female 75.16429\n3   32 Female 75.63810\n4   33 Female 76.11190\n5   34 Female 76.58571\n6   35 Female 77.05951\n7   30   Male 95.31560\n8   31   Male 95.78940\n9   32   Male 96.26320\n10  33   Male 96.73701\n11  34   Male 97.21081\n12  35   Male 97.68462\n\n\nFunksjonen predict fungerer på tilsvarende måte uansett hvor komplisert modellen måtte være. Men det kreves at det nye datasettet har samme variabelnavn og variabeltype som i opprinnelige data.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#pene-tabeller-og-eksport-til-fil",
    "href": "lineaer_regresjon.html#pene-tabeller-og-eksport-til-fil",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.6 Pene tabeller og eksport til fil",
    "text": "9.6 Pene tabeller og eksport til fil\nSlik resultatene ser ut med bruk av summary er forsåvidt fint, og du får den informasjonen du trenger. Men det er ikke særlig presentabelt som ferdig produkt i en analyse. Du trenger typisk to ting: 1) Samle flere regresjonsmodeller i samme tabell, og 2) gjøre tabellene penere og lettere å lese, og 3) eksportere til det tekstbehandlingsprogrammet du bruker, typisk Microsoft Word.\nR har en hel rekke funksjoner for dette. Det spiller egentlig ingen rolle hvilke funksjoner du bruker da det er noe smak og behag her, så det viktigste er at det fungerer rimelig greit for deg. Nedenfor presenteres tre pakker for dette formålet. Velg én av dem. Hvis du ikke har egne preferanser, så velg det første alternativet: {modelsummary}. Alle disse funksjonene håndterer svært mange typer modeller, gir gode muligheter for å ferdigstille tabellene fullstendig før eksport, og eksporterer til de formatene som er mest aktuelle. De har også mer avansert funksjonalitet som f.eks. å rapportere robuste standardfeil (av forskjellig type) i stedet for vanlige standardfeil (dette er pensum på SOS4020).\nVi vil som regel ha behov for å flytte resultatene over til et tekstbehandlingsprogram. En strategi som går ut på “klipp og lim” eller skjermbilde etc er uaktuelt og må unngås for nærmest enhver pris.8 Resultatene skal skrives til en fil på en effektiv måte. Det er en fordel om tabellene da ser ganske ok ut i utgangspunktet og du kan bruke samme prosedyre for å eksportere til flere typer format hvis behovet skulle melde seg. Det er jo MS Word som er viktigst for de fleste, mens de øvrige formatene nedenfor er for spesielt interessert - men noen av dere vil kanskje bli det på et senere tidspunkt. De viktigste formatene som er:\n\nMS Word - det vanligste tekstbehandlingsprogrammet som de aller fleste av dere bruker.\nrtf - rikt tekstformat. Er et enklere format som fungerer på tvers av de fleste programmer. Kan brukes i Word også.\nhtml - for websider\nlatex - for mer tekniske dokumenter, særlig hvis du har mye formler og stæsj\nMarkdown/Quarto - for dynamiske dokumenter med integrert R-kode og tekst, og kan eksportere ferdig dokument til alle ovennevnte formater9 Det som fungerer med Markdown fungerer også med Quarto for samme formål.\n\n\n9.6.1 Alt 1: Bruke modelsummary()\nEksporterer til bl.a. følgende formater: Word, rtf, html, latex, markdown\nFordel: Gir pene og oversiktlige tabeller med enkel kode, og relativt enkelt å modifisere videre. Eksporterer direkte til alle viktigste formater. Kan også lett integreres med andre eksterne verktøy, først og fremst “grammar of tables” i pakket {gt} Ulempe:\nHer er kode for en enkel tabell med to regresjonsmodeller som vist ovenfor. Merk at objektene med regresjonsresultatene må legges inni funksjonen list().\n\nlibrary(modelsummary)\nmodelsummary(list(lm_est2, lm_est3))\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  99.844\n                  81.101\n                \n                \n                  \n                  (0.637)\n                  (1.585)\n                \n                \n                  sexFemale\n                  -20.752\n                  -20.625\n                \n                \n                  \n                  (0.932)\n                  (0.912)\n                \n                \n                  age\n                  \n                  0.474\n                \n                \n                  \n                  \n                  (0.037)\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.117\n                  0.154\n                \n                \n                  R2 Adj.\n                  0.116\n                  0.153\n                \n                \n                  AIC\n                  35854.9\n                  35694.9\n                \n                \n                  BIC\n                  35873.6\n                  35719.8\n                \n                \n                  Log.Lik.\n                  -17924.434\n                  -17843.437\n                \n                \n                  F\n                  496.278\n                  341.699\n                \n                \n                  RMSE\n                  28.49\n                  27.88\n                \n        \n      \n    \n\n\n\nDenne tabellen inneholder mer enn du er interessert i. Nedre del av tabellen inneholder “goodness of fit” statistikker, altså mål på hvordan modellen passer til dataene. Det finnes mange slike, men ingen grunn til å gå seg vill i disse her. De kan fjernes med argumentet gof_omit = og så angis statistikkene med de navnene du ser i tabellen. Det skrives på en spesiell måte: som en tekststreng angitt med anførselstegn rundt, og | mellom hver. I koden nedenfor beholdes kun antall observasjoner, \\(r^2\\) og \\(F\\).10\nVi gjør et par andre justeringer samtidig for å demonstrere noe funksjonalitet. I stedet for å oppgi estimatet og standardfeil på forskjellig linje kan vi spesifisere å ha det på samme linje med argumentet estimate =. Merk at den statistikken du vil rapportere settes i parentes {…} og mellomrom og parentes er ellers som det står. Man har også andre valg, derav det vanligste i bruk er å angi p-verdier eller stjerner for å vise disse på en forenklet måte. Det angis ved {p.value} eller {stars} på tilsvarende måte.\nI stedet for standardfeil på egen linje er det her angitt konfidensintervall på neste linje. For konfidensintervall vil det som forvalg være 95%, men vi kan angi f.eks. 99% konfidensintervall i stedet ved conf_level =. Hvis man ikke vil ha noe på neste linje kan man angi statistic = NULL i stedet. Man kan også velge å sette inn p.value eller stars på denne linjen.\nMerk at utfallsvariabelen i modellene er timelønn i kroner. I forrige tabell ble estimatene gitt med tre desimaler. Det er i overkant mange desimaler. En desimal er mer passende og nedenfor endres dette med fmt =.\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  99.8 (0.6)\n                  81.1 (1.6)\n                \n                \n                  \n                  [98.2, 101.5]\n                  [77.0, 85.2]\n                \n                \n                  sexFemale\n                  -20.8 (0.9)\n                  -20.6 (0.9)\n                \n                \n                  \n                  [-23.2, -18.4]\n                  [-23.0, -18.3]\n                \n                \n                  age\n                  \n                  0.5 (0.0)\n                \n                \n                  \n                  \n                  [0.4, 0.6]\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.117\n                  0.154\n                \n                \n                  F\n                  496.278\n                  341.699\n                \n        \n      \n    \n\n\n\nTo siste ting å ta med her er å endre navn på variablene til noe mer presentabelt og eksportere til Word. Med argumentet coef_rename = angis variabelen slik den ser ut i output og spesifiserer hva du vil skal stå. Koden nedenfor viser eksempel.\nFor å eksportere til Word settes output = med filbane og filnavn, og der filhalen .docx angir Word format. Du kan eksportere til annet format ved å angi annen filhale f.eks. .rtf eller .html.\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        \n        \n                \n                  Konstant\n                  99.8 (0.6)\n                  81.1 (1.6)\n                \n                \n                  \n                  [98.2, 101.5]\n                  [77.0, 85.2]\n                \n                \n                  Kvinne\n                  -20.8 (0.9)\n                  -20.6 (0.9)\n                \n                \n                  \n                  [-23.2, -18.4]\n                  [-23.0, -18.3]\n                \n                \n                  Alder\n                  \n                  0.5 (0.0)\n                \n                \n                  \n                  \n                  [0.4, 0.6]\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.117\n                  0.154\n                \n                \n                  F\n                  496.278\n                  341.699\n                \n        \n      \n    \n\n\n\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE', \n             coef_rename = c(\"sexFemale\" = \"Kvinne\", \n                                   \"age\" = \"Alder\", \n                                  \"(Intercept)\" = \"Konstant\"), \n             output = \"output/reg_table.docx\")\n\nMerk at Word vil vise tabellen med de fonter etc som er forvalgt for Word. Dette kan du endre i Word etterpå. Det er en rekke funksjoner i Word for å formattere tabeller som du kan bruke.\nPakken {modelsummary} har også en rekke andre funksjoner for å redigere tabeller som du kan utforske ved behov. For avanserte brukere kan man også gjøre om tabellen til et gt-objekt og redigere videre med pakken {gt} eller tilsvarende med pakken {flextable}. Det er altså tilnærmet uendelige muligheter for avanserte tabeller. Dette går imidlertid langt utenfor hva de fleste av dere vil trenge. {modelsummary} har egen hjemmeside med mer detaljer og instruksjoner.\n\n\n9.6.2 Alt 2: Bruke {stargazer}\nMange R-brukere foretrekker pakken {stargazer}. Dette er en noe eldre funksjon og er derfor godt etablert.\nEksporterer til bl.a. følgende formater: rtf, html, latex, markdown\nFordel: Er en stand-alone pakke men gir enkelt veldig fine tabeller som antakeligvis er det du trenger Ulempe: Eksport til Word er ikke den beste, men god nok.\nStargazer lager tabeller i kun tre formater: latex, html, og ren tekst. Vi velger derfor type = \"text\" for at det skal se ok ut her.\n\nlibrary(stargazer)\nstargazer(lm_est2, lm_est3, type = \"text\")\n\n\n=======================================================================\n                                    Dependent variable:                \n                    ---------------------------------------------------\n                                          time89                       \n                               (1)                       (2)           \n-----------------------------------------------------------------------\nsexFemale                  -20.752***                -20.625***        \n                             (0.932)                   (0.912)         \n                                                                       \nage                                                   0.474***         \n                                                       (0.037)         \n                                                                       \nConstant                    99.844***                 81.101***        \n                             (0.637)                   (1.585)         \n                                                                       \n-----------------------------------------------------------------------\nObservations                  3,759                     3,759          \nR2                            0.117                     0.154          \nAdjusted R2                   0.116                     0.153          \nResidual Std. Error    28.495 (df = 3757)        27.891 (df = 3756)    \nF Statistic         496.278*** (df = 1; 3757) 341.699*** (df = 2; 3756)\n=======================================================================\nNote:                                       *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nVi kan modifisere tabellen tilsvarende som vi gjorde med {modelsummary}. Forklaringer av de enkelte argumenter finnes i manualen for stargazer.\ncovariate.labels = Angir teksten for variabelnavn. Merk at det oppgis i den rekkefølgen det skal stå, så være veldig nøye hvis du har mange variable! report = angir hva som skal inngå i tabellen, der hver bokstav viser til spesifikke deler: v = variabelnavn, c = koeffisient/estimat, s = standardfeil. single.row = setter statistikkene på samme linje fremfor under hverandre. keep.stat = angir hvilke “model fit statistics” som skal rapporteres. Hvis du skriver “all” her får du en lang remse tilsvarende vi fikk med {modelsummary}. digits = angir antall desimaler\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\", \n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1)\n\n\n=====================================================\n                           Dependent variable:       \n                    ---------------------------------\n                                 time89              \n                          (1)              (2)       \n-----------------------------------------------------\nKvinne                -20.8 (0.9)      -20.6 (0.9)   \nAlder                                   0.5 (0.04)   \nKonstant               99.8 (0.6)       81.1 (1.6)   \n-----------------------------------------------------\nObservations             3,759            3,759      \nR2                        0.1              0.2       \nResidual Std. Error 28.5 (df = 3757) 27.9 (df = 3756)\n=====================================================\nNote:                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nFor å eksportere til Word kan man bruke rikt tekstformat (.rtf) eller html. rtf-formatet er som navnet tilsier ren tekst og selv om det ser greit ut, så er videre redigering i et tekstbehandlingsprogram krøkete. (Prøv og se selv). Bruk heller html fordi da beholdes tabell-strukturen. Du kan åpne html-tabeller fra Word og redigere videre der ved behov.\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\",\n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1, \n          out = \"output/reg_starg.html\")\n\nMer detaljer finner du i {stargazer} sin vignette.\n\n\n9.6.3 Alt 3: Bruke {gtsummary}\nVi har tidligere brukt {gtsummary} for å lage deskriptive tabeller, som er det pakken er best til. Men den kan også lage gode regresjonstabeller. Det er imidlertid en stor ulempe for nybegynnere i R: det er ganske krøkete å sette sammen flere regresjonsmodeller i en samlet tabell. Derfor er rådet å ikke bruke denne pakken med mindre du har veldig lyst til å prøve.\nFordel med å bruke denne pakken er at man slipper å lære enda en ny pakke og slik sett ha ett sett med konsistent syntaks. En mulighet er selvsagt å ikke lage tabellene så ferdig i R, men eksportere til Word og redigere ferdig der mer manuelt.\n{gtsummary} kan eksportere til følgende formater: Word, rtf, html, latex og markdown. Resultatene kan også lett integreres med andre funksjoner, først og fremst “grammar of tables” i pakket {gt} og {flextable} - altså for mer avanserte ting som vi ikke dekker her.\nPrinsippet er å lage hver tabell for seg og så slå dem sammen med tbl_merge etterpå. Det innebærer en del mer kode, rett og slett. I utgangspunktet virker det ganske greit, men det er alltid en del småting som krever litt mer.\nFølgende kode lager først en ryddig tabell for hver regresionsmodell og så kobler sammen disse to tabellene.\n\nlm_tab1 &lt;- tbl_regression(lm_est2, intercept = T, \n                          estimate_fun = function(x) style_number(x, digits = 1),\n                          show_single_row = \"sex\",\n                          label = list(sex ~ \"Kvinne\")) %&gt;% \n    add_glance_table(include = c(nobs, r.squared, sigma))\n                     \nlm_tab2 &lt;- tbl_regression(lm_est3, intercept = T,\n                          estimate_fun = function(x) style_number(x, digits = 1), \n                          show_single_row = \"sex\",\n                          label = list(age ~ \"Alder\", sex ~ \"Kvinne\")) %&gt;% \n    add_glance_table(include = c(nobs, r.squared, sigma)\n  )\n\n\ntbl_merge(tbls = list(lm_tab1, lm_tab2)) %&gt;% \n  modify_table_body(\n    ~.x %&gt;% \n      dplyr::arrange(\n        row_type == \"glance_statistic\", # sort glance table to bottom\n        var_label                       # sort by the variable label (a hidden column) \n      )\n  )\n\nThe number rows in the tables to be merged do not match, which may result in\nrows appearing out of order.\nℹ See `tbl_merge()` (`?gtsummary::tbl_merge()`) help file for details. Use\n  `quiet=TRUE` to silence message.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nTable 1\n\n\nTable 2\n\n\n\nBeta\n95% CI\np-value\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n99.8\n98.6, 101.1\n&lt;0.001\n81.1\n78.0, 84.2\n&lt;0.001\n\n\nAlder\n\n\n\n\n\n\n0.5\n0.4, 0.5\n&lt;0.001\n\n\nKvinne\n-20.8\n-22.6, -18.9\n&lt;0.001\n-20.6\n-22.4, -18.8\n&lt;0.001\n\n\nNo. Obs.\n3,759\n\n\n\n\n3,759\n\n\n\n\n\n\nR²\n0.117\n\n\n\n\n0.154\n\n\n\n\n\n\nSigma\n28.5\n\n\n\n\n27.9\n\n\n\n\n\n\n\nAbbreviation: CI = Confidence Interval",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "lineaer_regresjon.html#footnotes",
    "href": "lineaer_regresjon.html#footnotes",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "",
    "text": "Du kan jo tenke deg flere parallelle linjer i plottet ovenfor med samme stigningstall↩︎\nGrunnen til det siste er at R kan ha flere datasett oppe samtidig, så R vet ikke nødvendigvis hvilket datasett du tenker på↩︎\nNoen ganger sier man at gjennomsnittslønna øker med 0.48 kroner for hvert år eldre man blir. Men det er ikke helt riktig, for dataene beskriver jo ikke individuell endringer over tid! Men hvis du synes det er lettere å tenke på det på den måten er det ok - men prøv å husk at det også er litt feil.↩︎\nDet er selvsagt ingenting enkelt med slike modeller utover at det finnes mer kompliserte varianter.↩︎\nNoen kaller dette også for multivariat regresjon, men det er tvetydig da det også kan bety modeller med flere utfallsvariable, som er noe ganske annet.↩︎\nf.eks. Et introduksjonskurs i maskinlæring som SOS2901 starter gjerne med nettopp prediksjon med lineær regresjon.↩︎\nHvis man ikke spesifiserer data.frame brukes opprinnelige data og predikerer for hver person. Det kan man også gjøre for å f.eks. regne ut residualer, men vi gjør ikke det her nå.↩︎\nHvis du blir tatt i å gjøre slikt vil faglærer sette fyr på datamaskinen din som straff.↩︎\nF.eks. dette dokumentet er skrevet i Quarto↩︎\nØvrige statistikker har selvsagt sitt bruksområde. De nevnte holder for de fleste formål.↩︎",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regresjon: Sammenheng mellom variable</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html",
    "href": "regresjon_utvidelser.html",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "",
    "text": "10.1 Polynomiske ledd: ikke-lineære sammenhenger\nI forrige kapittel så vi på helt grunnleggende lineær regresjon. Det er et godt utgangspunkt, men i praksis trenger man ofte å utvide modellene litt. I dette kapittelet ser vi på noen av de vanligste utvidelsene: ikke-lineære sammenhenger, log-transformasjoner, og robuste standardfeil. Alt dette er ting du vil møte i pensumlitteraturen og i empiriske artikler, så det er nyttig å vite hvordan det gjøres i R.\nI forrige kapittel så vi at sammenhengen mellom alder og timelønn ikke nødvendigvis er helt lineær. Kanskje lønna øker raskt i starten av karrieren, flater ut, og så synker litt mot slutten? En rett linje fanger ikke opp dette. En enkel løsning er å legge til et andregradsledd, altså alder i andre potens (\\(alder^2\\)). Da får vi en kurve i stedet for en rett linje.\nI R bruker vi funksjonen poly() eller legger til I(age^2) direkte i formelen. La oss prøve begge:\nest_lin &lt;- lm(time89 ~ age, data = abu89)\nest_poly &lt;- lm(time89 ~ age + I(age^2), data = abu89)\nLa oss sammenligne de to modellene:\nmodelsummary(list(\"Lineær\" = est_lin, \"Kvadratisk\" = est_poly),\n             fmt = 2,\n             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Lineær\n                Kvadratisk\n              \n        \n        \n        \n                \n                  (Intercept)\n                  71.11\n                  5.11\n                \n                \n                  \n                  (1.62)\n                  (4.60)\n                \n                \n                  age\n                  0.48\n                  4.01\n                \n                \n                  \n                  (0.04)\n                  (0.23)\n                \n                \n                  I(age^2)\n                  \n                  -0.04\n                \n                \n                  \n                  \n                  (0.00)\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.039\n                  0.095\n                \n                \n                  R2 Adj.\n                  0.038\n                  0.094\n                \n                \n                  F\n                  151.239\n                  197.015\nKoeffisienten for I(age^2) er negativ, noe som betyr at kurven bøyer nedover. Altså: lønna øker med alder, men økningen avtar. Dette gir en omvendt U-form som er ganske typisk for inntekt over livsløpet.\nMerk at når du har med et andregradsledd er det ikke lenger meningsfylt å tolke koeffisienten for age alene. De to koeffisientene må tolkes sammen fordi de beskriver ulike deler av den samme kurven. Den beste måten å forstå effekten på er å se på et plot:\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_jitter(alpha = .15) +\n  geom_smooth(method = \"lm\", formula = y ~ x,\n              se = FALSE, col = \"blue\", linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", formula = y ~ x + I(x^2),\n              se = FALSE, col = \"red\") +\n  labs(x = \"Alder\", y = \"Timelønn (kr)\") +\n  theme_minimal()\nDen stiplete blå linjen er den lineære modellen, mens den røde kurven er modellen med andregradsledd. Vi ser at den røde kurven fanger opp mønsteret i dataene bedre, særlig for de yngste og de eldste.\nMan kan i prinsippet legge til høyere ordens ledd (I(age^3) osv.), men i praksis er det sjelden nødvendig med mer enn andregradsledd. Høyere ordens polynomer gir fort rare kurver som er vanskelige å tolke og som gjerne bare tilpasser seg støy i dataene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#log-transformasjoner",
    "href": "regresjon_utvidelser.html#log-transformasjoner",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.2 Log-transformasjoner",
    "text": "10.2 Log-transformasjoner\nEn annen vanlig måte å håndtere ikke-lineære sammenhenger på er å bruke logaritmen av variablene. Dette er særlig nyttig for variable som inntekt, lønn, og andre økonomiske størrelser som ofte har en skjev fordeling med en lang hale til høyre.\n\n10.2.1 Logaritme av utfallsvariabelen\nHvis vi tar logaritmen av utfallsvariabelen (time89), endrer vi tolkningen av koeffisientene. Nå uttrykkes endringer i prosent i stedet for i kroner:\n\nest_log &lt;- lm(log(time89) ~ age, data = abu89)\n\nmodelsummary(list(\"Kroner\" = est_lin, \"Log(kroner)\" = est_log),\n             fmt = 3,\n             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Kroner\n                Log(kroner)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  71.110\n                  4.226\n                \n                \n                  \n                  (1.622)\n                  (0.016)\n                \n                \n                  age\n                  0.483\n                  0.006\n                \n                \n                  \n                  (0.039)\n                  (0.000)\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.039\n                  0.053\n                \n                \n                  R2 Adj.\n                  0.038\n                  0.053\n                \n                \n                  F\n                  151.239\n                  210.357\n                \n        \n      \n    \n\n\n\nI den første modellen (i kroner) betyr koeffisienten for alder at timelønna øker med ca. 0.48 kroner per år. I den andre modellen (log) betyr koeffisienten at timelønna øker med ca. 0.5% per år.1\n\n\n10.2.2 Logaritme av forklaringsvariabelen\nMan kan også ta logaritmen av forklaringsvariabelen. Da endres tolkningen til å handle om prosentvis endring i forklaringsvariabelen. Vi bruker et annet eksempel her fordi log av alder ikke er så meningsfylt, men log av f.eks. arbeidstid eller lignende variable kan gi mening i andre datasett.\n\n\n10.2.3 Oppsummering av log-transformasjoner\n\n\n\n\n\n\n\nModell\nTolkning av \\(\\beta\\)\n\n\n\n\n\\(y = \\alpha + \\beta x\\)\n\\(x\\) opp 1 enhet \\(\\rightarrow\\) \\(y\\) endres med \\(\\beta\\) enheter\n\n\n\\(\\log(y) = \\alpha + \\beta x\\)\n\\(x\\) opp 1 enhet \\(\\rightarrow\\) \\(y\\) endres med ca. \\(\\beta \\times 100\\) prosent\n\n\n\\(y = \\alpha + \\beta \\log(x)\\)\n\\(x\\) opp 1% \\(\\rightarrow\\) \\(y\\) endres med ca. \\(\\beta / 100\\) enheter\n\n\n\\(\\log(y) = \\alpha + \\beta \\log(x)\\)\n\\(x\\) opp 1% \\(\\rightarrow\\) \\(y\\) endres med ca. \\(\\beta\\) prosent (elastisitet)\n\n\n\nDenne tabellen er verd å ha i bakhodet. Det siste tilfellet, der begge er log-transformert, er det man kaller en elastisitet i økonomi.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#robuste-standardfeil",
    "href": "regresjon_utvidelser.html#robuste-standardfeil",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.3 Robuste standardfeil",
    "text": "10.3 Robuste standardfeil\nStandardfeilene fra vanlig OLS-regresjon bygger på en antakelse om at variansen i feilleddene er konstant (homoskedastisitet). Hvis denne antakelsen er brutt – noe den ofte er i praksis – kan standardfeilene bli feil. Konsekvensen er at konfidensintervaller og p-verdier ikke er til å stole på.\nLøsningen er å bruke robuste standardfeil, gjerne kalt “Huber-White” eller “sandwich” standardfeil. Disse gir korrekte standardfeil selv om variansen ikke er konstant.2\n\n10.3.1 Med modelsummary\nDen enkleste måten å rapportere robuste standardfeil i R er å bruke vcov-argumentet i modelsummary. Da trenger du ikke engang å laste ekstra pakker utover det du allerede har:\n\nmodelsummary(list(\"Vanlige SE\" = est_lin, \"Robuste SE\" = est_lin),\n             vcov = list(\"classical\", \"HC1\"),\n             fmt = 2,\n             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Vanlige SE\n                Robuste SE\n              \n        \n        \n        \n                \n                  (Intercept)\n                  71.11\n                  71.11\n                \n                \n                  \n                  (1.62)\n                  (1.52)\n                \n                \n                  age\n                  0.48\n                  0.48\n                \n                \n                  \n                  (0.04)\n                  (0.04)\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.039\n                  0.039\n                \n                \n                  R2 Adj.\n                  0.038\n                  0.038\n                \n                \n                  F\n                  151.239\n                  155.345\n                \n                \n                  Std.Errors\n                  Classical\n                  HC1\n                \n        \n      \n    \n\n\n\nHer er det nøyaktig samme modell i begge kolonnene, men med ulike standardfeil. \"HC1\" er den vanligste varianten av robuste standardfeil og tilsvarer det Stata bruker som forvalg.3\n\n\n10.3.2 Med lmtest og sandwich\nDu kan også bruke pakkene lmtest og sandwich direkte for å se robuste standardfeil:\n\ncoeftest(est_lin, vcov = vcovHC(est_lin, type = \"HC1\"))\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 71.11019    1.51953  46.797 &lt; 2.2e-16 ***\nage          0.48284    0.03874  12.464 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDette gir deg koeffisientene, robuste standardfeil, t-verdier og p-verdier. Funksjonen vcovHC beregner den robuste varians-kovariansmatrisen, og coeftest bruker denne til å beregne nye teststatistikker.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#klustrede-standardfeil",
    "href": "regresjon_utvidelser.html#klustrede-standardfeil",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.4 Klustrede standardfeil",
    "text": "10.4 Klustrede standardfeil\nI noen datasett er observasjonene gruppert, f.eks. elever innenfor skoler, eller ansatte innenfor bedrifter. Da kan observasjoner innenfor samme gruppe være mer like hverandre enn observasjoner på tvers av grupper. Vanlige standardfeil tar ikke hensyn til dette og kan bli for lave, noe som gjør at man feilaktig finner “statistisk signifikante” resultater.\nLøsningen er klustrede standardfeil, som tar hensyn til gruppestrukturen. I modelsummary kan dette gjøres med vcov-argumentet ved å angi en formel med klustervariabelen:\n\nmodelsummary(list(est_lin),\n             vcov = ~klasse89,\n             fmt = 2)\n\nKlustrede standardfeil er særlig viktig i paneldata og flernivådata. Vi går ikke dypere inn på dette her, men det er viktig å vite at det finnes og at det er enkelt å implementere.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#vektet-regresjon",
    "href": "regresjon_utvidelser.html#vektet-regresjon",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.5 Vektet regresjon",
    "text": "10.5 Vektet regresjon\nNoen ganger har vi data der observasjonene har ulik vekt. Det kan for eksempel være at noen observasjoner er mer pålitelige enn andre, eller at datasettet er et stratifisert utvalg der noen grupper er overrepresentert. I slike tilfeller bruker vi vektet regresjon.\nI R legger man til weights-argumentet i lm:\n\nest_vektet &lt;- lm(time89 ~ age + female, data = abu89, weights = en_vekt_variabel)\n\nVektet regresjon er vanlig i analyser av surveydata der ulike grupper har ulik trekkesannsynlighet. Mange norske datasett fra SSB kommer med slike vekter. Prinsippet er at observasjoner med høyere vekt teller mer i estimeringen.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#faste-effekter-fixed-effects",
    "href": "regresjon_utvidelser.html#faste-effekter-fixed-effects",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.6 Faste effekter (fixed effects)",
    "text": "10.6 Faste effekter (fixed effects)\nFaste effekter er en teknikk som brukes mye i paneldata, altså data der man observerer de samme enhetene over flere tidspunkter. Ideen er å kontrollere for alle tidskonstante egenskaper ved enhetene, også de man ikke har observert. For eksempel: hvis man ser på lønnsutvikling over tid, vil faste effekter for person fjerne all variasjon som skyldes uobserverte, stabile personegenskaper (motivasjon, evner, osv.).\nI praksis fungerer det ved at man sammenligner endringer innenfor hver enhet over tid, i stedet for å sammenligne nivåer mellom enheter. Det gjør at tidskonstante forstyrrende variable elimineres fra analysen.\nEn enkel (men lite effektiv) måte å estimere faste effekter på i R er å inkludere grupperingsvariabelen som en faktorvariabel:\n\nlm(time89 ~ age + factor(gruppe_id), data = paneldata)\n\nDette fungerer greit med få grupper, men er upraktisk med mange grupper (f.eks. tusenvis av personer). Da bruker man heller spesialiserte pakker som plm eller fixest. Spesielt fixest er blitt veldig populær fordi den er rask og håndterer mange typer faste effekter elegant:\n\nlibrary(fixest)\nfeols(time89 ~ age | person_id, data = paneldata)\n\nSyntaksen | person_id angir at det skal inkluderes faste effekter for person. Man kan inkludere faste effekter for flere grupperinger samtidig ved å skille dem med +, f.eks. | person_id + year.\nVi går ikke dypere inn på faste effekter her, men dette er et helt sentralt verktøy i kvantitativ samfunnsforskning og noe du vil møte i mer avanserte kurs.4",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#oppsummering",
    "href": "regresjon_utvidelser.html#oppsummering",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "10.7 Oppsummering",
    "text": "10.7 Oppsummering\nI dette kapittelet har vi sett på noen vanlige utvidelser av den lineære regresjonsmodellen:\n\nPolynomiske ledd lar oss fange opp kurvlineære sammenhenger ved å legge til f.eks. \\(x^2\\) som forklaringsvariabel.\nLog-transformasjoner er nyttige for skjeve fordelinger og gir tolkninger i prosent.\nRobuste standardfeil korrigerer for heteroskedastisitet og bør brukes som standard i de fleste analyser.\nKlustrede standardfeil tar hensyn til gruppestruktur i dataene.\nVektet regresjon brukes når observasjonene har ulik betydning.\nFaste effekter kontrollerer for uobserverte, tidskonstante egenskaper og er sentralt i paneldataanalyse.\n\nFelles for alle disse utvidelsene er at de bygger videre på den grunnleggende lineære regresjonsmodellen. Selve R-koden er ofte bare små justeringer, men tolkningen kan endre seg en del. Det er derfor viktig å tenke gjennom hva man gjør og hvorfor, fremfor å bare kjøre kode mekanisk.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "regresjon_utvidelser.html#footnotes",
    "href": "regresjon_utvidelser.html#footnotes",
    "title": "10  Utvidelser av regresjonsmodeller",
    "section": "",
    "text": "Teknisk sett er tolkningen at en enhets økning i alder er assosiert med en endring i log-timelønn på 0.005. For å få prosent-tolkning multipliserer man med 100. Denne tilnærmingen fungerer godt for små koeffisienter (under ca. 0.1), men for større koeffisienter bør man bruke den eksakte formelen: \\((e^\\beta - 1) \\times 100\\).↩︎\nDet som endres er altså bare standardfeilene og dermed p-verdier og konfidensintervaller. Selve koeffisientene (estimatene) er de samme.↩︎\nDet finnes flere varianter: HC0, HC1, HC2, HC3. HC1 er den mest brukte i praksis og inkluderer en korreksjon for antall observasjoner.↩︎\nFor en grundig innføring i faste effekter anbefales f.eks. (huntington2022?) eller tilsvarende pensumlitteratur for kausalanalyse.↩︎",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Utvidelser av regresjonsmodeller</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html",
    "href": "modelldiagnostikk.html",
    "title": "11  Modelldiagnostikk",
    "section": "",
    "text": "11.1 Hva er det vi sjekker?\nNår vi estimerer en regresjonsmodell gjør vi en del antakelser om dataene. Disse antakelsene er ikke bare formaliteter – de har betydning for om vi kan stole på resultatene. Modelldiagnostikk handler om å sjekke om disse antakelsene holder rimelig godt. Heldigvis finnes det enkle grafiske verktøy og tester som gjør dette ganske oversiktlig.\nVi bruker en enkel regresjonsmodell som utgangspunkt for diagnostikken. Her predikerer vi timelønn med alder og kjønn:\nDe viktigste antakelsene i lineær regresjon er:\nIngen av disse trenger å holde perfekt. Regresjon er ganske robust, og poenget er å avdekke grove brudd som kan påvirke konklusjonene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#hva-er-det-vi-sjekker",
    "href": "modelldiagnostikk.html#hva-er-det-vi-sjekker",
    "title": "11  Modelldiagnostikk",
    "section": "",
    "text": "Linearitet: Sammenhengen mellom forklaringsvariable og utfallsvariabel er tilnærmet lineær.\nNormalfordelte residualer: Residualene (avvikene fra regresjonslinjen) er tilnærmet normalfordelt.\nHomoskedastisitet: Variansen i residualene er omtrent lik for alle verdier av forklaringsvariablene.\nIngen ekstreme observasjoner som alene driver resultatene.\nIngen alvorlig multikollinearitet: Forklaringsvariablene er ikke for sterkt korrelert med hverandre.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#residualplot-residualer-mot-predikerte-verdier",
    "href": "modelldiagnostikk.html#residualplot-residualer-mot-predikerte-verdier",
    "title": "11  Modelldiagnostikk",
    "section": "11.2 Residualplot: Residualer mot predikerte verdier",
    "text": "11.2 Residualplot: Residualer mot predikerte verdier\nDet mest grunnleggende diagnostiske plottet er å sette residualene opp mot de predikerte (fitted) verdiene. Hvis alt er som det skal, vil punktene ligge tilfeldig spredt rundt null uten noe tydelig mønster.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(fitted_val = fitted(mod1),\n         resid_val  = residuals(mod1))\n\nggplot(abu89, aes(x = fitted_val, y = resid_val)) +\n  geom_point(alpha = .2) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  labs(x = \"Predikerte verdier\", y = \"Residualer\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHer ser vi etter systematiske mønstre. Hvis punktene danner en trakt (vifteform), tyder det på heteroskedastisitet. Hvis det er en kurve, kan det tyde på at sammenhengen ikke er lineær. I dette tilfellet ser vi at variansen ser ut til å øke noe med predikerte verdier, og det er noen observasjoner med veldig store residualer.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#qq-plot-for-normalitet",
    "href": "modelldiagnostikk.html#qq-plot-for-normalitet",
    "title": "11  Modelldiagnostikk",
    "section": "11.3 QQ-plot for normalitet",
    "text": "11.3 QQ-plot for normalitet\nEt QQ-plot (quantile-quantile plot) sammenligner fordelingen av residualene med en teoretisk normalfordeling. Hvis residualene er normalfordelt, vil punktene ligge omtrent langs en rett linje.\n\nggplot(abu89, aes(sample = resid_val)) +\n  stat_qq(alpha = .2) +\n  stat_qq_line(col = \"red\") +\n  labs(x = \"Teoretiske kvantiler\", y = \"Observerte kvantiler\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHer ser vi at punktene følger linjen rimelig bra i midten, men avviker i halene. Det betyr at fordelingen har tyngre haler enn normalfordelingen. Med store utvalg er dette sjelden et stort problem for estimatene, men det er greit å vite om.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#de-fire-standard-diagnostikkplottene",
    "href": "modelldiagnostikk.html#de-fire-standard-diagnostikkplottene",
    "title": "11  Modelldiagnostikk",
    "section": "11.4 De fire standard diagnostikkplottene",
    "text": "11.4 De fire standard diagnostikkplottene\nR har en innebygd funksjon som gir fire diagnostiske plot samtidig. Man bruker bare plot() på et lm-objekt:\n\npar(mfrow = c(2, 2))\nplot(mod1)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nDisse fire plottene viser:\n\nResiduals vs Fitted: Sjekker linearitet og homoskedastisitet (det vi allerede har sett på).\nNormal Q-Q: Sjekker normalitet i residualene.\nScale-Location: Sjekker homoskedastisitet. Linjen bør være tilnærmet flat.\nResiduals vs Leverage: Identifiserer innflytelsesrike observasjoner.\n\nLegg merke til at R merker noen observasjoner med radnummer. Det er de mest avvikende observasjonene som du kanskje bør se nærmere på.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#heteroskedastisitet",
    "href": "modelldiagnostikk.html#heteroskedastisitet",
    "title": "11  Modelldiagnostikk",
    "section": "11.5 Heteroskedastisitet",
    "text": "11.5 Heteroskedastisitet\nHeteroskedastisitet betyr at variansen i residualene varierer systematisk. Det påvirker ikke selve estimatene, men det gjør at standardfeilene kan bli feil – og dermed også p-verdier og konfidensintervaller.\nVi har allerede sett visuelt etter dette i residualplottet. Man kan også bruke en formell test. Breusch-Pagan-testen sjekker om variansen i residualene korrelerer med de predikerte verdiene:\n\nlibrary(lmtest)\nbptest(mod1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  mod1\nBP = 30.972, df = 2, p-value = 1.882e-07\n\n\nEn lav p-verdi (under 0.05) tyder på at heteroskedastisitet er til stede. Men husk at med store utvalg vil selv små avvik bli statistisk signifikante, så det visuelle inntrykket fra residualplottet er vel så viktig.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#innflytelsesrike-observasjoner-og-cooks-avstand",
    "href": "modelldiagnostikk.html#innflytelsesrike-observasjoner-og-cooks-avstand",
    "title": "11  Modelldiagnostikk",
    "section": "11.6 Innflytelsesrike observasjoner og Cooks avstand",
    "text": "11.6 Innflytelsesrike observasjoner og Cooks avstand\nNoen enkeltobservasjoner kan ha uforholdsmessig stor innflytelse på regresjonsresultatene. Cooks avstand (Cook’s distance) er et samlemål for hvor mye hvert datapunkt påvirker de estimerte koeffisientene. En tommelfingerregel er at verdier over \\(4/n\\) (der \\(n\\) er antall observasjoner) bør undersøkes nærmere.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(cooks_d = cooks.distance(mod1))\n\nggplot(abu89, aes(x = seq_along(cooks_d), y = cooks_d)) +\n  geom_point(alpha = .3) +\n  geom_hline(yintercept = 4 / nrow(abu89), col = \"red\", linetype = \"dashed\") +\n  labs(x = \"Observasjon\", y = \"Cooks avstand\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nPunktene over den røde linjen er observasjoner som har relativt stor innflytelse. Det betyr ikke nødvendigvis at de er feil eller at de bør fjernes, men det er lurt å sjekke hva slags observasjoner det er. I lønnsdata er det gjerne folk med uvanlig høy inntekt som trekker resultatene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#multikollinearitet-og-vif",
    "href": "modelldiagnostikk.html#multikollinearitet-og-vif",
    "title": "11  Modelldiagnostikk",
    "section": "11.7 Multikollinearitet og VIF",
    "text": "11.7 Multikollinearitet og VIF\nMultikollinearitet oppstår når forklaringsvariablene er sterkt korrelert med hverandre. Det gjør at det blir vanskelig å skille effektene fra hverandre, og standardfeilene blåses opp.\nVIF (Variance Inflation Factor) måler dette. En VIF på 1 betyr ingen korrelasjon med andre forklaringsvariable. Tommelfingerregler varierer, men VIF over 5 gir grunn til bekymring, og over 10 er et klart problem.\nLa oss utvide modellen med noen flere variable og sjekke VIF:\n\nmod2 &lt;- lm(time89 ~ age + female + ed, data = abu89)\n\nlibrary(car)\nvif(mod2)\n\n     age   female       ed \n1.004787 1.015293 1.019662 \n\n\nHer ser vi at VIF-verdiene er lave, noe som betyr at multikollinearitet ikke er et problem i denne modellen. Hvis du hadde inkludert variable som i praksis måler det samme, ville VIF blitt høyere.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#rask-diagnostikk-med-performance-pakken",
    "href": "modelldiagnostikk.html#rask-diagnostikk-med-performance-pakken",
    "title": "11  Modelldiagnostikk",
    "section": "11.8 Rask diagnostikk med performance-pakken",
    "text": "11.8 Rask diagnostikk med performance-pakken\nPakken {performance} har en veldig nyttig funksjon som gjør mye av diagnostikken i ett steg. Funksjonen check_model() lager et sett med diagnostiske plot som dekker de viktigste antakelsene.\n\nlibrary(performance)\ncheck_model(mod2)\n\n\n\n\n\n\n\n\nDette gir deg et samlet bilde av modellens egenskaper, inkludert linearitet, homoskedastisitet, normalitet, innflytelsesrike observasjoner og multikollinearitet. Det er en fin snarvei for en rask sjekk.\nDu kan også få en tekstbasert oppsummering:\n\ncheck_model(mod2, check = \"all\") |&gt; summary()\n\n            Length Class                Mode   \nVIF            3   check_collinearity   list   \nQQ             2   data.frame           list   \nNORM           3   data.frame           list   \nNCV            2   data.frame           list   \nHOMOGENEITY    2   data.frame           list   \nOUTLIERS    3759   check_outliers       logical\nINFLUENTIAL    7   data.frame           list   \nPP_CHECK      51   performance_pp_check list",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "modelldiagnostikk.html#hva-gjør-man-hvis-antakelsene-brytes",
    "href": "modelldiagnostikk.html#hva-gjør-man-hvis-antakelsene-brytes",
    "title": "11  Modelldiagnostikk",
    "section": "11.9 Hva gjør man hvis antakelsene brytes?",
    "text": "11.9 Hva gjør man hvis antakelsene brytes?\nI praksis er det sjelden at alle antakelser holder perfekt. Her er noen praktiske råd:\nHeteroskedastisitet: Bruk robuste standardfeil. Det endrer ikke estimatene, men gir korrekte standardfeil og p-verdier. I R kan du bruke pakken {sandwich} sammen med {lmtest}, eller rapportere robuste standardfeil direkte via {modelsummary}.\nIkke-normalfordelte residualer: Med store utvalg (over noen hundre observasjoner) er dette sjelden et problem for estimatene eller standardfeilene takket være sentralgrenseteoremet. Men det kan tyde på at modellen mangler noe viktig.\nInnflytelsesrike observasjoner: Sjekk hva slags observasjoner det er. Kjør modellen med og uten disse observasjonene. Hvis resultatene endrer seg mye, bør du diskutere dette.\nIkke-linearitet: Vurder å transformere variablene (f.eks. logaritme) eller inkludere polynomiske ledd.\nMultikollinearitet: Vurder om du trenger alle variablene i modellen. Kanskje noen av dem måler det samme og du kan droppe en av dem.\nDet viktigste er at du faktisk sjekker antakelsene. Det er mye bedre å gjøre en enkel sjekk og diskutere eventuelle problemer enn å ignorere diagnostikk fullstendig. Og husk: ingen modell er perfekt. Poenget er at den er nyttig nok til å fortelle oss noe meningsfullt om dataene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Modelldiagnostikk</span>"
    ]
  },
  {
    "objectID": "lineaer_sannsynlighetsmodell.html",
    "href": "lineaer_sannsynlighetsmodell.html",
    "title": "12  Lineær sannsynlighetsmodell",
    "section": "",
    "text": "12.1 Dummy som utfallsvariabel\nI samfunnsvitenskapen har vi ganske ofte kategoriske variable både som forklaringsvariable og utfallsvariable, eller en kombinasjon. I en regresjon vil vi behandle kategoriske variable dem som om de er tall på kontinuerlig akse, men der det typisk bare finnes to verdier: 0 og 1. Dette kalles en dummyvariabel eller en indikatorvariabel.\nNår man bruker kategoriske variable i en lineær regresjon er det derfor ikke egentlig noe nytt. Det som står i læreboken om kontinuerlige variable gjelder også for kategoriske variable (i hvert fall for alle praktiske formål som dekkes for dette kurset).\nI samfunnsvitenskapen er utfallsvariabelen ganske ofte kategorisk. I en regresjon vil vi behandle kategoriske variable dem som om de er tall på kontinuerlig akse, også der det typisk bare finnes to verdier: 0 og 1. Dette kalles en dummyvariabel eller en indikatorvariabel.\nNår man bruker kategoriske variable i en lineær regresjon er det derfor ikke egentlig noe nytt. Det som står i boken om kontinuerlige variable gjelder også for kategoriske variable (i hvert fall for alle praktiske formål som dekkes for dette kurset).\nHusk at tolkningen av regresjonskoeffisienten, \\(b\\), tolkes på den skalaen \\(y\\)-variabelen er på. Altså: hvis utfallsvariabelen er i kroner, så er tolkningen av \\(b\\) i måleenheten kroner. Hvis y-variabelen er i antall timer, så er tolkningen av \\(b\\) i antall timer, osv. Husk også at vi estimerer endring i gjennomsnitt.\nNår utfallsvariabelen er en dummy, så har den verdiene 0 eller 1. Da er gjennomsnittet det samme som en andel. For eksempel: hvis utfallet er om man er i jobb eller ikke, og koder å være i jobb som 1 og 0 ellers. Hvis man har 5 personer, derav 3 er i jobb får man så: \\(\\bar{y} = \\frac{(0+0+1+1+1)} {5} = \\frac{3}{5}=0.6\\) som er det samme som 60%.\nI regresjon med slike variable er dermed utfallet en andel og dette kalles derfor ofte en «lineær sannsynlighetsmodell». Men det er egentlig en helt vanlig regresjonsmodell. Vi tolker fremdeles på den skalaen y-variabelen er på, som altså er en andel. (Vi skal forresten senere omtale andeler som estimater på sannsynligheter). En økning i \\(x\\)-variabelen tilsvarer altså en endring, b, i andelen med den egenskapen som er kodet 1 på \\(y\\)-variabelen.\nLa oss si at vi er interessert i å beskrive kjønnsforskjell i hvorvidt menn og kvinner jobber i privat vs offentlig sektor. Variabelen “private” er en factor-variabel der første kategori er “public”, som da blir referansekategorien. R regner da privat sektor som 1 mens offentlig sektor er 0. Koeffisientene vil da uttrykke forskjell i sannsynlighet for å være i privat sektor.\nlm(private ~ female + ed + age, data = abu89)\n\n\nCall:\nlm(formula = private ~ female + ed + age, data = abu89)\n\nCoefficients:\n(Intercept)       female           ed          age  \n   2.167030    -0.287998    -0.049017    -0.007274\nVi ser her at sannsynligheten for at kvinner jobber i privat sektor er 0.28 lavere enn for menn, dvs. 28 prosentpoeng lavere. Dette er da kontrollert for utdanning og alder, slik at vi kan se bort fra at utdanningsnivå og forskjell i aldersfordeling i dataene kan være grunnen til forskjellene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Lineær sannsynlighetsmodell</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html",
    "href": "kontrollere_for.html",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "",
    "text": "13.1 Simpsons paradoks: Når helheten lyver\nI forrige kapittel så vi hvordan vi kan estimere regresjonsmodeller med en eller flere forklaringsvariable. Men hvorfor vil vi ha flere variable i modellen? Det handler om noe av det mest sentrale i kvantitativ samfunnsvitenskap: å kontrollere for bakenforliggende variable. I dette kapittelet skal vi se på hva det betyr, hvorfor det er viktig, og hvordan vi gjør det i praksis.\nLa oss starte med et tankeksperiment. Tenk deg at du sammenligner to sykehus for å finne ut hvilket som er best. Sykehus A har høyere dødelighet enn sykehus B totalt sett. Men når du ser på lette og alvorlige tilfeller hver for seg, er sykehus A faktisk bedre i begge gruppene. Hvordan er det mulig?\nForklaringen er at sykehus A er et spesialistsykehus som tar imot de mest alvorlige pasientene. Alvorlige tilfeller har naturligvis høyere dødelighet uansett sykehus. Når vi kontrollerer for alvorlighetsgrad – altså sammenligner likt med likt – snur bildet seg.\nDette fenomenet kalles Simpsons paradoks: en sammenheng som går i en retning totalt sett kan snu når man deler opp etter en tredje variabel. Det er ikke bare et teoretisk kuriosum. Det skjer hele tiden i samfunnsvitenskapelige data, og det er en av hovedgrunnene til at vi bruker multippel regresjon.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#hva-betyr-det-å-kontrollere-for-en-variabel",
    "href": "kontrollere_for.html#hva-betyr-det-å-kontrollere-for-en-variabel",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.2 Hva betyr det å “kontrollere for” en variabel?",
    "text": "13.2 Hva betyr det å “kontrollere for” en variabel?\nUttrykket “kontrollere for” er noe man hører hele tiden i metodeundervisning. Men hva betyr det egentlig?\nKort sagt betyr det at vi sammenligner grupper som er like på den variabelen vi kontrollerer for, men forskjellige på den variabelen vi er interessert i. Hvis vi kontrollerer for sosial klasse i en analyse av kjønnsforskjeller i lønn, betyr det at vi sammenligner menn og kvinner innenfor samme klasse. Vi sammenligner altså likt med likt, så godt det lar seg gjøre.\nI praksis gjør multippel regresjon dette for oss matematisk: når vi legger til en variabel i modellen, “renser” vi sammenhengen mellom de andre variablene og utfallet for den variabelen vi la til. Det er dette vi mener med å kontrollere for.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#praktisk-eksempel-kjønnsgapet-i-lønn",
    "href": "kontrollere_for.html#praktisk-eksempel-kjønnsgapet-i-lønn",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.3 Praktisk eksempel: Kjønnsgapet i lønn",
    "text": "13.3 Praktisk eksempel: Kjønnsgapet i lønn\nLa oss se på et konkret eksempel med abu89-datasettet. Vi starter med den enkle sammenhengen mellom kjønn og timelønn.\n\nmod1 &lt;- lm(time89 ~ female, data = abu89)\ncoef(mod1)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\nKoeffisienten for female viser forskjellen i gjennomsnittlig timelønn mellom kvinner og menn. Kvinner tjente altså betydelig mindre enn menn. Men er hele denne forskjellen fordi arbeidsgivere betaler kvinner mindre? Eller kan noe av forskjellen skyldes at menn og kvinner i gjennomsnitt har forskjellige yrker, utdanninger og klasseposisjoner?\nLa oss legge til sosial klasse i modellen:\n\nmod2 &lt;- lm(time89 ~ female + klasse89, data = abu89)\ncoef(mod2)\n\n                     (Intercept)                           female \n                       122.63676                        -18.19952 \n  klasse89II Nedre serviceklasse   klasse89III Rutinefunksjonærer \n                       -10.39630                        -32.70807 \n klasse89V-VI Faglærte arbeidere klasse89VIIa Ufaglærte arbeidere \n                       -32.60689                        -34.03860 \n\n\nLegg merke til hva som skjedde med koeffisienten for female. Den ble mindre (i absoluttverdi). Det betyr at noe av lønnsforskjellen mellom menn og kvinner kan tilskrives at de befinner seg i ulike klasseposisjoner. Når vi sammenligner menn og kvinner i samme klasse, er forskjellen mindre.\nVi kan utvide enda mer og legge til utdanning:\n\nmod3 &lt;- lm(time89 ~ female + klasse89 + ed, data = abu89)\ncoef(mod3)\n\n                     (Intercept)                           female \n                      104.807681                       -17.197749 \n  klasse89II Nedre serviceklasse   klasse89III Rutinefunksjonærer \n                       -4.945598                       -20.364392 \n klasse89V-VI Faglærte arbeidere klasse89VIIa Ufaglærte arbeidere \n                      -19.696567                       -19.227326 \n                              ed \n                        2.812244 \n\n\nOgså her kan vi se at koeffisienten for female endrer seg noe når vi legger til flere kontrollvariable.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#bivariat-vs.-multippel-regresjon",
    "href": "kontrollere_for.html#bivariat-vs.-multippel-regresjon",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.4 Bivariat vs. multippel regresjon",
    "text": "13.4 Bivariat vs. multippel regresjon\nI en bivariat regresjon (kun en forklaringsvariabel) beskriver koeffisienten den totale sammenhengen mellom variabelen og utfallet. Denne sammenhengen kan inneholde både en direkte effekt og indirekte effekter via andre variable.\nI en multippel regresjon (flere forklaringsvariable) beskriver koeffisienten sammenhengen mellom variabelen og utfallet gitt at de andre variablene holdes konstant. Det er dette “kontrollere for” betyr i praksis.\nForskjellen kan oppsummeres slik:\n\nBivariat: Hva er den gjennomsnittlige lønnsforskjellen mellom menn og kvinner?\nMultippel: Hva er den gjennomsnittlige lønnsforskjellen mellom menn og kvinner som er i samme sosiale klasse og har samme utdanningsnivå?\n\nDet er viktig å forstå at begge spørsmålene kan være relevante. Det avhenger av hva du er interessert i.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#sammenligne-modeller-med-modelsummary",
    "href": "kontrollere_for.html#sammenligne-modeller-med-modelsummary",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.5 Sammenligne modeller med modelsummary()",
    "text": "13.5 Sammenligne modeller med modelsummary()\nFor å virkelig se hva som skjer når vi legger til kontrollvariable er det nyttig å sette modellene ved siden av hverandre i en tabell. Da kan vi direkte se hvordan koeffisienten for female endres.\n\nmodelsummary(list(\"Bivariat\" = mod1,\n                  \"Med klasse\" = mod2,\n                  \"Med klasse og utd.\" = mod3),\n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE',\n             coef_rename = c(\"female\" = \"Kvinne\",\n                             \"educ\" = \"Utdanning (år)\",\n                             \"(Intercept)\" = \"Konstant\"))\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Bivariat\n                Med klasse\n                Med klasse og utd.\n              \n        \n        \n        \n                \n                  Konstant\n                  99.8 (0.6)\n                  122.6 (1.5)\n                  104.8 (2.0)\n                \n                \n                  Kvinne\n                  -20.8 (0.9)\n                  -18.2 (1.0)\n                  -17.2 (1.0)\n                \n                \n                  klasse89II Nedre serviceklasse\n                  \n                  -10.4 (1.7)\n                  -4.9 (1.7)\n                \n                \n                  klasse89III Rutinefunksjonærer\n                  \n                  -32.7 (1.8)\n                  -20.4 (2.0)\n                \n                \n                  klasse89V-VI Faglærte arbeidere\n                  \n                  -32.6 (1.8)\n                  -19.7 (2.0)\n                \n                \n                  klasse89VIIa Ufaglærte arbeidere\n                  \n                  -34.0 (1.8)\n                  -19.2 (2.1)\n                \n                \n                  ed\n                  \n                  \n                  2.8 (0.2)\n                \n                \n                  Num.Obs.\n                  3759\n                  3680\n                  3680\n                \n                \n                  R2\n                  0.117\n                  0.280\n                  0.312\n                \n                \n                  F\n                  496.278\n                  \n                  \n                \n        \n      \n    \n\n\n\nI den bivariate modellen (modell 1) ser vi den totale lønnsforskjellen mellom menn og kvinner. I modell 2 har vi kontrollert for klasse, og forskjellen er noe redusert. I modell 3 har vi i tillegg kontrollert for utdanning.\nLegg merke til to ting: For det første, koeffisienten for female endres mellom modellene. For det andre, \\(R^2\\) (forklart varians) øker når vi legger til flere variable. Det betyr at modellen passer bedre til dataene. Men det betyr ikke nødvendigvis at modellen er bedre for det vi er interessert i.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#når-skal-vi-kontrollere-og-når-skal-vi-la-være",
    "href": "kontrollere_for.html#når-skal-vi-kontrollere-og-når-skal-vi-la-være",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.6 Når skal vi kontrollere – og når skal vi la være?",
    "text": "13.6 Når skal vi kontrollere – og når skal vi la være?\nDet er fristende å tenke at man bør kontrollere for alt man har tilgang til. Men det er ikke riktig. Hvorvidt du bør kontrollere for en variabel avhenger av hva rollen til variabelen er i den sammenhengen du studerer.\nEn nyttig tommelfingerregel er at du bør kontrollere for variable som:\n\nPåvirker både forklaringsvariabelen og utfallsvariabelen (konfunderende variable)\nIkke selv er et resultat av forklaringsvariabelen\n\nPunkt 2 er viktig og leder oss til det som kalles bad controls.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#bad-controls-ikke-kontroller-for-konsekvenser",
    "href": "kontrollere_for.html#bad-controls-ikke-kontroller-for-konsekvenser",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.7 “Bad controls”: Ikke kontroller for konsekvenser",
    "text": "13.7 “Bad controls”: Ikke kontroller for konsekvenser\nEn vanlig feil er å kontrollere for variable som er konsekvenser av den forklaringsvariabelen du er interessert i. Tenk deg at du studerer effekten av utdanning på inntekt. Hvis du kontrollerer for yrke, kan du faktisk fjerne en viktig del av effekten – fordi utdanning påvirker inntekt delvis gjennom hvilket yrke man får. Ved å kontrollere for yrke fjerner du denne mekanismen fra estimatet.\nTilsvarende: Hvis du er interessert i effekten av kjønn på lønn, bør du tenke nøye gjennom om du skal kontrollere for variabler som arbeidstid eller stillingsnivå. Hvis kvinner systematisk styres mot lavere stillinger på grunn av kjønn, er stillingsnivå en konsekvens av kjønn – og da fjerner du en del av den faktiske kjønnseffekten ved å kontrollere for det.\nDet finnes ingen enkel mekanisk regel for dette. Du må tenke gjennom rekkefølgen av variablene: Hva kommer først? Hva påvirker hva? Et nyttig verktøy for å tenke gjennom dette er såkalte DAGs (Directed Acyclic Graphs), men det går vi ikke inn på her.1",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#steg-for-steg-bygge-modeller-i-r",
    "href": "kontrollere_for.html#steg-for-steg-bygge-modeller-i-r",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.8 Steg-for-steg: Bygge modeller i R",
    "text": "13.8 Steg-for-steg: Bygge modeller i R\nI praksis vil du ofte bygge opp modeller steg for steg. Her er en oppsummering av fremgangsmåten:\nSteg 1: Start med den bivariate sammenhengen du er interessert i.\n\nmod1 &lt;- lm(time89 ~ female, data = abu89)\n\nSteg 2: Legg til variable du mener er konfunderende (bakenforliggende).\n\nmod2 &lt;- lm(time89 ~ female + klasse89, data = abu89)\n\nSteg 3: Legg eventuelt til ytterligere kontrollvariable.\n\nmod3 &lt;- lm(time89 ~ female + klasse89 + ed, data = abu89)\n\nSteg 4: Sammenlign modellene i en tabell.\n\nmodelsummary(list(\"Modell 1\" = mod1,\n                  \"Modell 2\" = mod2,\n                  \"Modell 3\" = mod3),\n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE')\n\nDet viktige er ikke bare tallene, men hvordan koeffisienten du er interessert i endrer seg fra modell til modell. Hvis den endres mye, tyder det på at de variablene du la til er viktige konfunderende variable. Hvis den knapt endrer seg, betyr det at disse variablene ikke forklarer mye av den opprinnelige sammenhengen.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#oppsummering",
    "href": "kontrollere_for.html#oppsummering",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "13.9 Oppsummering",
    "text": "13.9 Oppsummering\n\nSimpsons paradoks viser at sammenhenger kan snu når man kontrollerer for en tredje variabel.\nÅ “kontrollere for” betyr å sammenligne grupper som er like på kontrollvariabelen.\nMultippel regresjon gjør dette for oss: koeffisienten uttrykker sammenhengen gitt at de andre variablene holdes konstant.\nDu bør kontrollere for variable som påvirker både forklaringsvariabel og utfall (konfunderende variable).\nDu bør ikke kontrollere for variable som er konsekvenser av forklaringsvariabelen (“bad controls”).\nBygg modeller steg for steg og sammenlign med modelsummary() for å se hva kontrollvariablene gjør med estimatene.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "kontrollere_for.html#footnotes",
    "href": "kontrollere_for.html#footnotes",
    "title": "13  Kontrollere for bakenforliggende variable",
    "section": "",
    "text": "DAGs er et tema som dekkes grundigere i videregående metodekurs.↩︎",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Kontrollere for bakenforliggende variable</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html",
    "href": "logistisk_regresjon.html",
    "title": "14  Logistisk regresjon",
    "section": "",
    "text": "14.1 Lage en binær utfallsvariabel\nI forrige kapittel om den lineære sannsynlighetsmodellen så vi at man kan bruke vanlig lineær regresjon selv om utfallsvariabelen er binær (0/1). Det fungerer greit i mange sammenhenger, men har noen begrensninger. Den viktigste er at modellen kan gi predikerte sannsynligheter som er under 0 eller over 1, noe som jo ikke gir mening. Logistisk regresjon løser dette problemet.\nLogistisk regresjon er den vanligste metoden når utfallsvariabelen er binær, altså har to verdier. I samfunnsvitenskapen brukes det veldig mye: er personen i jobb eller ikke? Stemte personen ved valget eller ikke? Har personen høy eller lav inntekt? Osv.\nVi skal bruke et eksempel der vi prøver å predikere hvem som har høy timelønn. Vi lager en ny variabel hoylonn som er 1 hvis timelønna er over medianen og 0 ellers.\nabu89 &lt;- abu89 %&gt;%\n  mutate(hoylonn = ifelse(time89 &gt; median(time89, na.rm = TRUE), 1, 0))\nLa oss sjekke fordelingen:\ntable(abu89$hoylonn)\n\n\n   0    1 \n1901 1858\nOmtrent halvparten har høy lønn, noe som gir mening siden vi delte ved medianen.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#hvorfor-ikke-bare-bruke-lineær-regresjon",
    "href": "logistisk_regresjon.html#hvorfor-ikke-bare-bruke-lineær-regresjon",
    "title": "14  Logistisk regresjon",
    "section": "14.2 Hvorfor ikke bare bruke lineær regresjon?",
    "text": "14.2 Hvorfor ikke bare bruke lineær regresjon?\nSom vi så i kapittelet om lineær sannsynlighetsmodell, kan vi bruke vanlig lm() også med binær utfallsvariabel. Koeffisientene tolkes da som endring i sannsynlighet (andel). Problemet oppstår spesielt når vi predikerer: vi kan få verdier under 0 eller over 1. Logistisk regresjon sørger for at predikerte sannsynligheter alltid ligger mellom 0 og 1.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#logit-transformasjonen-og-odds",
    "href": "logistisk_regresjon.html#logit-transformasjonen-og-odds",
    "title": "14  Logistisk regresjon",
    "section": "14.3 Logit-transformasjonen og odds",
    "text": "14.3 Logit-transformasjonen og odds\nIdeen bak logistisk regresjon er å modellere log-oddsen i stedet for sannsynligheten direkte. Men hva er egentlig odds?\nTenk deg at 80 av 100 personer i en gruppe er i jobb. Da er sannsynligheten 0.80 (80%). Oddsen er forholdet mellom sannsynligheten for å være i jobb og sannsynligheten for å ikke være i jobb: \\(0.80 / 0.20 = 4\\). Altså: det er fire ganger så sannsynlig å være i jobb som å ikke være det.\nLogistisk regresjon modellerer logaritmen av oddsen (log-odds). Fordelen er at log-odds kan variere fritt fra minus uendelig til pluss uendelig, mens sannsynligheter er begrenset mellom 0 og 1. Matematisk sett gjør dette at modellen alltid gir gyldige sannsynligheter.\nDu trenger ikke bekymre deg så mye om den matematiske detaljen her. Det viktigste å huske er:\n\nKoeffisientene fra logistisk regresjon er på log-odds-skalaen\nMan kan konvertere til odds-ratio ved å eksponentiere: exp(koeffisient)\nMan kan regne om til sannsynligheter med predict(..., type = \"response\")",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#estimere-logistisk-regresjon-i-r",
    "href": "logistisk_regresjon.html#estimere-logistisk-regresjon-i-r",
    "title": "14  Logistisk regresjon",
    "section": "14.4 Estimere logistisk regresjon i R",
    "text": "14.4 Estimere logistisk regresjon i R\nI R bruker vi glm() med argumentet family = binomial for å estimere logistisk regresjon. Syntaksen er ellers helt lik lm().\nLa oss starte enkelt med kjønn som forklaringsvariabel:\n\nlogit1 &lt;- glm(hoylonn ~ female, data = abu89, family = binomial)\nsummary(logit1)\n\n\nCall:\nglm(formula = hoylonn ~ female, family = binomial, data = abu89)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.66334    0.04717   14.06   &lt;2e-16 ***\nfemale      -1.48581    0.07007  -21.20   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5210.6  on 3758  degrees of freedom\nResidual deviance: 4728.7  on 3757  degrees of freedom\n  (368 observations deleted due to missingness)\nAIC: 4732.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nKoeffisienten for female er negativ, som betyr at kvinner har lavere log-odds for å ha høy lønn sammenlignet med menn. Men log-odds er ikke veldig intuitivt, så vi konverterer til odds-ratio.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#tolke-koeffisientene-odds-ratio",
    "href": "logistisk_regresjon.html#tolke-koeffisientene-odds-ratio",
    "title": "14  Logistisk regresjon",
    "section": "14.5 Tolke koeffisientene: odds-ratio",
    "text": "14.5 Tolke koeffisientene: odds-ratio\nFor å gjøre koeffisientene mer tolkbare konverterer vi fra log-odds til odds-ratio med exp():\n\nexp(coef(logit1))\n\n(Intercept)      female \n  1.9412628   0.2263188 \n\n\nEn odds-ratio på 1 betyr ingen forskjell. Over 1 betyr høyere odds, under 1 betyr lavere odds. Koeffisienten for female gir en odds-ratio under 1, som altså betyr at kvinner har lavere odds for høy lønn enn menn.\nMan kan også få ut konfidensintervaller for odds-ratioene:\n\nexp(confint(logit1))\n\n                2.5 %   97.5 %\n(Intercept) 1.7706203 2.130296\nfemale      0.1971601 0.259492",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#flere-forklaringsvariable",
    "href": "logistisk_regresjon.html#flere-forklaringsvariable",
    "title": "14  Logistisk regresjon",
    "section": "14.6 Flere forklaringsvariable",
    "text": "14.6 Flere forklaringsvariable\nLa oss utvide modellen med klasse og alder i tillegg til kjønn:\n\nlogit2 &lt;- glm(hoylonn ~ female + klasse89 + age, data = abu89, family = binomial)\nsummary(logit2)\n\n\nCall:\nglm(formula = hoylonn ~ female + klasse89 + age, family = binomial, \n    data = abu89)\n\nCoefficients:\n                                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                       1.806579   0.239652   7.538 4.76e-14 ***\nfemale                           -1.618252   0.093501 -17.307  &lt; 2e-16 ***\nklasse89II Nedre serviceklasse   -0.926952   0.217423  -4.263 2.01e-05 ***\nklasse89III Rutinefunksjonærer   -2.751740   0.217219 -12.668  &lt; 2e-16 ***\nklasse89V-VI Faglærte arbeidere  -2.624620   0.224599 -11.686  &lt; 2e-16 ***\nklasse89VIIa Ufaglærte arbeidere -2.990663   0.225225 -13.279  &lt; 2e-16 ***\nage                               0.025410   0.003199   7.944 1.96e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5100.9  on 3679  degrees of freedom\nResidual deviance: 3886.2  on 3673  degrees of freedom\n  (447 observations deleted due to missingness)\nAIC: 3900.2\n\nNumber of Fisher Scoring iterations: 5\n\n\nTolkningen av koeffisientene er litt annerledes enn i lineær regresjon. Hver koeffisient viser endring i log-odds for utfallet (høy lønn) per enhets endring i forklaringsvariabelen, kontrollert for de andre variablene. La oss se på odds-ratioene:\n\nexp(coef(logit2))\n\n                     (Intercept)                           female \n                      6.08958125                       0.19824496 \n  klasse89II Nedre serviceklasse   klasse89III Rutinefunksjonærer \n                      0.39575797                       0.06381675 \n klasse89V-VI Faglærte arbeidere klasse89VIIa Ufaglærte arbeidere \n                      0.07246732                       0.05025410 \n                             age \n                      1.02573524 \n\n\nOdds-ratioene tolkes slik: en odds-ratio for age på f.eks. 1.02 ville bety at for hvert års økning i alder øker oddsen for høy lønn med 2%, kontrollert for kjønn og klasse.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#predikere-sannsynligheter",
    "href": "logistisk_regresjon.html#predikere-sannsynligheter",
    "title": "14  Logistisk regresjon",
    "section": "14.7 Predikere sannsynligheter",
    "text": "14.7 Predikere sannsynligheter\nEn veldig nyttig ting med logistisk regresjon er at vi kan predikere sannsynligheter. Vi bruker predict() med type = \"response\" for å få sannsynligheter i stedet for log-odds:\n\nnyedata &lt;- expand.grid(\n  female = c(0, 1),\n  klasse89 = levels(abu89$klasse89)[1:2],\n  age = c(30, 40, 50)\n)\n\nnyedata$pred_sannsynlighet &lt;- predict(logit2, newdata = nyedata, type = \"response\")\nnyedata\n\n   female               klasse89 age pred_sannsynlighet\n1       0   I Øvre serviceklasse  30          0.9288310\n2       1   I Øvre serviceklasse  30          0.7212393\n3       0 II Nedre serviceklasse  30          0.8377956\n4       1 II Nedre serviceklasse  30          0.5059160\n5       0   I Øvre serviceklasse  40          0.9439043\n6       1   I Øvre serviceklasse  40          0.7693623\n7       0 II Nedre serviceklasse  40          0.8694397\n8       1 II Nedre serviceklasse  40          0.5689974\n9       0   I Øvre serviceklasse  50          0.9559366\n10      1   I Øvre serviceklasse  50          0.8113507\n11      0 II Nedre serviceklasse  50          0.8956791\n12      1 II Nedre serviceklasse  50          0.6299164\n\n\nNå har vi estimerte sannsynligheter for høy lønn for ulike kombinasjoner av kjønn, klasse og alder. Merk at alle verdier ligger mellom 0 og 1, slik det skal være.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#presentere-resultater-med-modelsummary",
    "href": "logistisk_regresjon.html#presentere-resultater-med-modelsummary",
    "title": "14  Logistisk regresjon",
    "section": "14.8 Presentere resultater med modelsummary()",
    "text": "14.8 Presentere resultater med modelsummary()\nVi kan bruke modelsummary() for å lage pene tabeller, akkurat som for lineær regresjon. Her viser vi først koeffisienter på log-odds-skalaen:\n\nmodelsummary(list(\"Log-odds\" = logit1, \"Log-odds\" = logit2),\n             fmt = 3,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|F|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Log-odds\n                Log-odds \n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.663 (0.047)\n                  1.807 (0.240)\n                \n                \n                  female\n                  -1.486 (0.070)\n                  -1.618 (0.094)\n                \n                \n                  klasse89II Nedre serviceklasse\n                  \n                  -0.927 (0.217)\n                \n                \n                  klasse89III Rutinefunksjonærer\n                  \n                  -2.752 (0.217)\n                \n                \n                  klasse89V-VI Faglærte arbeidere\n                  \n                  -2.625 (0.225)\n                \n                \n                  klasse89VIIa Ufaglærte arbeidere\n                  \n                  -2.991 (0.225)\n                \n                \n                  age\n                  \n                  0.025 (0.003)\n                \n                \n                  Num.Obs.\n                  3759\n                  3680\n                \n        \n      \n    \n\n\n\nVi kan også vise odds-ratioer ved å bruke exponentiate = TRUE:\n\nmodelsummary(list(\"OR\" = logit1, \"OR\" = logit2),\n             exponentiate = TRUE,\n             fmt = 2,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int',\n             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|F|RMSE')\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                OR\n                OR \n              \n        \n        \n        \n                \n                  (Intercept)\n                  1.94 (0.09)\n                  6.09 (1.46)\n                \n                \n                  \n                  [1.77, 2.13]\n                  [3.86, 9.89]\n                \n                \n                  female\n                  0.23 (0.02)\n                  0.20 (0.02)\n                \n                \n                  \n                  [0.20, 0.26]\n                  [0.16, 0.24]\n                \n                \n                  klasse89II Nedre serviceklasse\n                  \n                  0.40 (0.09)\n                \n                \n                  \n                  \n                  [0.25, 0.60]\n                \n                \n                  klasse89III Rutinefunksjonærer\n                  \n                  0.06 (0.01)\n                \n                \n                  \n                  \n                  [0.04, 0.10]\n                \n                \n                  klasse89V-VI Faglærte arbeidere\n                  \n                  0.07 (0.02)\n                \n                \n                  \n                  \n                  [0.05, 0.11]\n                \n                \n                  klasse89VIIa Ufaglærte arbeidere\n                  \n                  0.05 (0.01)\n                \n                \n                  \n                  \n                  [0.03, 0.08]\n                \n                \n                  age\n                  \n                  1.03 (0.00)\n                \n                \n                  \n                  \n                  [1.02, 1.03]\n                \n                \n                  Num.Obs.\n                  3759\n                  3680\n                \n        \n      \n    \n\n\n\nMerk exponentiate = TRUE som gjør at koeffisientene vises som odds-ratioer. Det er som regel lurt å rapportere odds-ratioer fordi de er lettere å tolke.\nFor å eksportere til Word gjøres det på nøyaktig samme måte som for lineær regresjon, ved å sette output = \"filnavn.docx\".",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#modelltilpasning",
    "href": "logistisk_regresjon.html#modelltilpasning",
    "title": "14  Logistisk regresjon",
    "section": "14.9 Modelltilpasning",
    "text": "14.9 Modelltilpasning\nI lineær regresjon har vi \\(R^2\\) som mål på hvor godt modellen passer til dataene. I logistisk regresjon finnes det ingen perfekt ekvivalent, men det finnes flere varianter av pseudo-\\(R^2\\). Disse kan tolkes omtrent på samme måte: et tall mellom 0 og 1 der høyere verdier betyr bedre tilpasning.\nEn annen tilnærming er å se på hvor godt modellen klassifiserer observasjonene. Vi kan sammenligne predikerte verdier med faktiske verdier:\n\nabu89_pred &lt;- abu89 %&gt;%\n  filter(!is.na(hoylonn), !is.na(klasse89), !is.na(age)) %&gt;%\n  mutate(pred_prob = predict(logit2, type = \"response\"),\n         pred_klasse = ifelse(pred_prob &gt; 0.5, 1, 0))\n\ntable(Faktisk = abu89_pred$hoylonn, Predikert = abu89_pred$pred_klasse)\n\n       Predikert\nFaktisk    0    1\n      0 1384  480\n      1  479 1337\n\n\nDenne tabellen kalles en forvirringsmatrise (confusion matrix). Diagonalen viser korrekte prediksjoner, mens de andre cellene viser feilklassifiseringer. Andelen korrekte prediksjoner kan regnes ut slik:\n\nmean(abu89_pred$hoylonn == abu89_pred$pred_klasse, na.rm = TRUE)\n\n[1] 0.7394022\n\n\nDette gir oss en enkel indikasjon på hvor godt modellen predikerer. Husk imidlertid at hovedpoenget med logistisk regresjon i samfunnsvitenskap som regel er å forstå sammenhenger mellom variable, ikke nødvendigvis å predikere best mulig.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "logistisk_regresjon.html#oppsummering",
    "href": "logistisk_regresjon.html#oppsummering",
    "title": "14  Logistisk regresjon",
    "section": "14.10 Oppsummering",
    "text": "14.10 Oppsummering\nLogistisk regresjon brukes når utfallsvariabelen er binær (0/1). De viktigste punktene er:\n\nBruk glm(y ~ x, family = binomial) for å estimere modellen\nKoeffisientene er på log-odds-skalaen, konverter til odds-ratio med exp()\nOdds-ratio over 1 betyr høyere odds, under 1 betyr lavere odds\nBruk predict(modell, type = \"response\") for å få predikerte sannsynligheter\nBruk modelsummary() med exponentiate = TRUE for å vise odds-ratioer i tabeller\nTolkningen av kontrollvariable er den samme som i lineær regresjon",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistisk regresjon</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html",
    "href": "marginaleffekter.html",
    "title": "15  Marginaleffekter",
    "section": "",
    "text": "15.1 Eksempelmodeller\nI de foregående kapitlene har vi sett på lineær regresjon og logistisk regresjon. I lineær regresjon er regresjonskoeffisientene greie å tolke direkte: de uttrykker endring i gjennomsnittlig verdi på utfallsvariabelen per enhets endring i forklaringsvariabelen. Men i logistisk regresjon er koeffisientene på log-odds-skalaen, og det er ikke spesielt intuitivt. Vi kan eksponentiere til oddsratioer, men det er heller ikke alltid lett å forklare hva en oddsratio betyr i praksis.\nHer kommer marginaleffekter inn i bildet. Marginaleffekter lar oss uttrykke effekten av en forklaringsvariabel som endring i sannsynlighet, noe som er langt mer intuitivt. Pakken {marginaleffects} gir oss et samlet rammeverk for å beregne marginaleffekter, predikerte verdier og sammenligninger mellom grupper. Hvis du ikke har installert pakken fra før:\nVi trenger noen modeller å jobbe med. La oss estimere en lineær modell for timelønn og en logistisk modell for sannsynligheten for å ha høy lønn. Først lager vi en dummy for høy lønn, definert som timelønn over medianen.\nabu89 &lt;- abu89 %&gt;%\n  filter(!is.na(time89)) %&gt;%\n  mutate(hoy_lonn = ifelse(time89 &gt; median(time89, na.rm = TRUE), 1, 0))\nSå estimerer vi to modeller:\nlm_mod &lt;- lm(time89 ~ age + female + ed, data = abu89)\nlogit_mod &lt;- glm(hoy_lonn ~ age + female + ed,\n                 data = abu89, family = binomial)\nI den lineære modellen kan vi lese koeffisientene direkte, men i den logistiske modellen er koeffisientene på log-odds-skalaen:\ncoef(logit_mod)\n\n(Intercept)         age      female          ed \n-1.84743222  0.03867057 -1.58421620  0.41064784\nDet er her marginaleffekter kommer inn.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#gjennomsnittlige-marginaleffekter-ame",
    "href": "marginaleffekter.html#gjennomsnittlige-marginaleffekter-ame",
    "title": "15  Marginaleffekter",
    "section": "15.2 Gjennomsnittlige marginaleffekter (AME)",
    "text": "15.2 Gjennomsnittlige marginaleffekter (AME)\nDen vanligste bruken er å beregne Average Marginal Effects (AME). Det betyr at vi beregner den marginale effekten for hver observasjon og tar gjennomsnittet. Funksjonen avg_slopes() gjør nettopp dette.\n\navg_slopes(logit_mod)\n\n\n   Term Contrast Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %   97.5 %\n age       dY/dX  0.00693   0.000538  12.9   &lt;0.001 123.7  0.00588  0.00799\n ed        dY/dX  0.07362   0.002552  28.8   &lt;0.001 605.6  0.06862  0.07862\n female    1 - 0 -0.30865   0.014233 -21.7   &lt;0.001 344.0 -0.33655 -0.28076\n\nType: response\n\n\nNå er effektene uttrykt som endring i sannsynlighet. For eksempel betyr en effekt av female på -0.10 at kvinner i gjennomsnitt har 10 prosentpoeng lavere sannsynlighet for høy lønn sammenlignet med menn, alt annet likt.\nFor den lineære modellen gir avg_slopes() de samme verdiene som de vanlige regresjonskoeffisientene, fordi marginaleffekten er lik overalt i en lineær modell:\n\navg_slopes(lm_mod)\n\n\n   Term Contrast Estimate Std. Error     z Pr(&gt;|z|)     S   2.5 %  97.5 %\n age       dY/dX    0.542     0.0332  16.3   &lt;0.001 196.6   0.477   0.607\n ed        dY/dX    4.874     0.1626  30.0   &lt;0.001 653.0   4.555   5.192\n female    1 - 0  -17.601     0.8255 -21.3   &lt;0.001 332.7 -19.219 -15.983\n\nType: response",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#marginaleffekter-ved-bestemte-verdier",
    "href": "marginaleffekter.html#marginaleffekter-ved-bestemte-verdier",
    "title": "15  Marginaleffekter",
    "section": "15.3 Marginaleffekter ved bestemte verdier",
    "text": "15.3 Marginaleffekter ved bestemte verdier\nNoen ganger vil man vite hva marginaleffekten er ved bestemte verdier av forklaringsvariablene. Funksjonen slopes() gjør dette. Med datagrid() kan vi lage et datasett med bestemte verdier, der variable som ikke spesifiseres holdes på gjennomsnittsverdier.\n\nslopes(logit_mod,\n       variables = \"ed\",\n       newdata = datagrid(age = c(25, 40, 55)))\n\n\n age Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 % 97.5 %\n  25   0.0996    0.00458 21.7   &lt;0.001 344.9 0.0906 0.1085\n  40   0.0833    0.00366 22.8   &lt;0.001 379.2 0.0761 0.0904\n  55   0.0608    0.00327 18.6   &lt;0.001 254.2 0.0544 0.0672\n\nTerm: ed\nType: response\nComparison: dY/dX\n\n\nHer ser vi at effekten av utdanning varierer med alder. Det er fordi logistisk regresjon er ikke-lineær: den marginale effekten avhenger av hvor på fordelingen man befinner seg.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#predikerte-verdier",
    "href": "marginaleffekter.html#predikerte-verdier",
    "title": "15  Marginaleffekter",
    "section": "15.4 Predikerte verdier",
    "text": "15.4 Predikerte verdier\nI kapittelet om lineær regresjon brukte vi predict() for å beregne predikerte verdier. Pakken {marginaleffects} har tilsvarende funksjoner som gir ryddigere output med konfidensintervaller. Funksjonen predictions() gir predikerte verdier, mens avg_predictions() gir gjennomsnitt per gruppe.\n\npredictions(logit_mod,\n            newdata = datagrid(age = c(25, 35, 45, 55),\n                               female = c(0, 1)))\n\n\n age female Estimate Pr(&gt;|z|)     S 2.5 % 97.5 %\n  25      0    0.587   &lt;0.001  22.6 0.555  0.618\n  25      1    0.226   &lt;0.001 192.5 0.201  0.253\n  35      0    0.677   &lt;0.001 134.7 0.653  0.700\n  35      1    0.300   &lt;0.001 144.4 0.276  0.326\n  45      0    0.755   &lt;0.001 258.0 0.732  0.776\n  45      1    0.387   &lt;0.001  45.5 0.360  0.415\n  55      0    0.819   &lt;0.001 267.6 0.795  0.841\n  55      1    0.482    0.331   1.6 0.445  0.518\n\nType: invlink(link)\n\n\nMed avg_predictions() kan vi beregne gjennomsnittlig predikert sannsynlighet fordelt på grupper:\n\navg_predictions(logit_mod, by = \"female\")\n\n\n female Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n      0    0.660    0.00968 68.2   &lt;0.001   Inf 0.641  0.679\n      1    0.305    0.00984 31.0   &lt;0.001 700.1 0.286  0.325\n\nType: response",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#sammenligninger-mellom-grupper",
    "href": "marginaleffekter.html#sammenligninger-mellom-grupper",
    "title": "15  Marginaleffekter",
    "section": "15.5 Sammenligninger mellom grupper",
    "text": "15.5 Sammenligninger mellom grupper\nFunksjonen avg_comparisons() beregner gjennomsnittlige forskjeller mellom grupper eller ved endring i en variabel. For eksempel forskjellen mellom menn og kvinner:\n\navg_comparisons(logit_mod, variables = \"female\")\n\n\n Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n   -0.309     0.0142 -21.7   &lt;0.001 344.0 -0.337 -0.281\n\nTerm: female\nType: response\nComparison: 1 - 0\n\n\nVi kan også se på effekten av en bestemt endring i en kontinuerlig variabel, for eksempel fra 10 til 15 års utdanning:\n\navg_comparisons(logit_mod,\n                variables = list(ed = c(10, 15)))\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n   0.0547    0.00619 8.83   &lt;0.001 59.8 0.0426 0.0668\n\nTerm: ed\nType: response\nComparison: 15 - 10",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#plotting-av-marginaleffekter",
    "href": "marginaleffekter.html#plotting-av-marginaleffekter",
    "title": "15  Marginaleffekter",
    "section": "15.6 Plotting av marginaleffekter",
    "text": "15.6 Plotting av marginaleffekter\nEn stor styrke med {marginaleffects} er enkle og fine plot. Funksjonen plot_predictions() viser predikerte verdier, mens plot_slopes() viser hvordan marginaleffekten varierer.\nHer plotter vi predikert sannsynlighet for høy lønn som funksjon av alder, separat for menn og kvinner:\n\nplot_predictions(logit_mod, condition = c(\"age\", \"female\"))\n\n\n\n\n\n\n\n\nDen grå sonen viser konfidensintervallet. Vi ser den karakteristiske S-formen fra logistisk regresjon. For den lineære modellen blir linjene rette:\n\nplot_predictions(lm_mod, condition = c(\"age\", \"female\"))\n\n\n\n\n\n\n\n\nMed plot_slopes() kan vi visualisere hvordan marginaleffekten av en variabel varierer med en annen:\n\nplot_slopes(logit_mod, variables = \"ed\", condition = \"age\")\n\n\n\n\n\n\n\n\nSiden disse funksjonene returnerer ggplot-objekter, kan de tilpasses med vanlig ggplot-syntaks:\n\nplot_predictions(logit_mod, condition = c(\"age\", \"female\")) +\n  labs(x = \"Alder\",\n       y = \"Predikert sannsynlighet for høy lønn\",\n       color = \"Kjønn\") +\n  theme_minimal()",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#sammenhengen-med-predict",
    "href": "marginaleffekter.html#sammenhengen-med-predict",
    "title": "15  Marginaleffekter",
    "section": "15.7 Sammenhengen med predict()",
    "text": "15.7 Sammenhengen med predict()\nI kapittelet om lineær regresjon brukte vi predict() for å beregne predikerte verdier. Her er en kort sammenligning:\n\nnyedata &lt;- data.frame(age = 40, female = 0, ed = 12)\n\n# Med predict():\npredict(logit_mod, newdata = nyedata, type = \"response\")\n\n        1 \n0.9903123 \n\n# Med predictions():\npredictions(logit_mod, newdata = nyedata)\n\n\n Estimate Pr(&gt;|z|)     S 2.5 % 97.5 %\n     0.99   &lt;0.001 408.6 0.986  0.993\n\nType: invlink(link)\n\n\nBegge gir samme predikerte verdi, men predictions() gir i tillegg konfidensintervaller og standardfeil. Funksjonen predict() er innebygd i R og fungerer alltid, men {marginaleffects} gir ryddigere output og er enklere for mer avanserte ting.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "marginaleffekter.html#oppsummering",
    "href": "marginaleffekter.html#oppsummering",
    "title": "15  Marginaleffekter",
    "section": "15.8 Oppsummering",
    "text": "15.8 Oppsummering\n\n\n\n\n\n\n\nFunksjon\nHva den gjør\n\n\n\n\navg_slopes()\nGjennomsnittlige marginaleffekter (AME)\n\n\nslopes()\nMarginaleffekter ved bestemte verdier\n\n\npredictions()\nPredikerte verdier for angitte observasjoner\n\n\navg_predictions()\nGjennomsnittlige predikerte verdier per gruppe\n\n\navg_comparisons()\nGjennomsnittlige sammenligninger mellom grupper\n\n\nplot_predictions()\nPlot av predikerte verdier\n\n\nplot_slopes()\nPlot av marginale effekter\n\n\n\nHovedpoenget er at marginaleffekter lar oss tolke resultater fra ikke-lineære modeller (som logistisk regresjon) på en intuitiv skala. I stedet for log-odds eller oddsratioer kan vi snakke om endring i sannsynlighet, noe som er langt lettere å forstå.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Marginaleffekter</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html",
    "href": "prediksjon_ml.html",
    "title": "16  Prediksjon og maskinlæring",
    "section": "",
    "text": "16.1 Forklaring vs. prediksjon\nI tidligere kapitler har vi brukt regresjonsmodeller til å beskrive sammenhenger mellom variable. Vi har tolket regresjonskoeffisienter som uttrykk for forskjeller mellom grupper. Men regresjonsmodeller kan også brukes til noe annet: prediksjon. Her gir vi en kort introduksjon til hvordan man tenker på prediksjon og hva som skiller det fra den vanlige tilnærmingen i samfunnsvitenskap.\nI samfunnsvitenskap er vi vanligvis opptatt av forklaring: vi vil forstå hvorfor ting henger sammen. Da er vi mest interessert i regresjonskoeffisientene. Hva er sammenhengen mellom utdanning og inntekt? Hva er kjønnsforskjellen i timelønn?\nMen noen ganger er vi mer opptatt av å predikere utfall. Da bryr vi oss ikke nødvendigvis om hvorfor modellen virker, men om den gir gode gjetninger. Eksempler kan være:\nI slike tilfeller er det utfallsvariabelen vi er mest opptatt av, ikke forklaringsvariablene. Vi vil ha en modell som gir gode prediksjoner for nye observasjoner vi ikke har sett ennå. Dette er kjernen i det som ofte kalles maskinlæring.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#forklaring-vs.-prediksjon",
    "href": "prediksjon_ml.html#forklaring-vs.-prediksjon",
    "title": "16  Prediksjon og maskinlæring",
    "section": "",
    "text": "Hvilke pasienter har høy risiko for tilbakefall?\nHvilke elever har høy risiko for å falle fra videregående?\nHva blir arbeidsledigheten neste kvartal?",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#overtilpasning",
    "href": "prediksjon_ml.html#overtilpasning",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.2 Overtilpasning",
    "text": "16.2 Overtilpasning\nEt sentralt problem i prediksjon er overtilpasning (engelsk: overfitting). En modell som er veldig kompleks kan tilpasse seg alle særegenhetene i dataene vi har, inkludert tilfeldig støy. Da får modellen veldig god “score” på treningsdataene, men dårlige prediksjoner for nye data.\nTenk deg at du pugger gamle eksamensoppgaver ord for ord. Du kan gjengi alle svarene perfekt – men bare for akkurat de oppgavene. Får du en ny oppgave som er litt annerledes, hjelper det lite. Det er det samme som skjer med en overtilpasset modell.\nEn enkel modell med få variable vil kanskje ikke fange opp alt i treningsdataene, men kan likevel gi bedre prediksjoner for nye data fordi den har lært det generelle mønsteret i stedet for støyen. Balansen mellom for enkel og for kompleks modell er det viktigste spørsmålet i prediksjon.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#trening-og-test-dele-opp-dataene",
    "href": "prediksjon_ml.html#trening-og-test-dele-opp-dataene",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.3 Trening og test: dele opp dataene",
    "text": "16.3 Trening og test: dele opp dataene\nHvordan vet vi om modellen vår gir gode prediksjoner for nye data? En enkel strategi er å dele opp dataene i to deler:\n\nTreningsdata: Brukes til å estimere modellen\nTestdata: Brukes til å evaluere hvor gode prediksjonene er\n\nVi estimerer modellen kun på treningsdataene, og deretter ser vi hvor godt modellen predikerer utfallsvariabelen i testdataene – data modellen aldri har “sett” under estimeringen.\nLa oss prøve dette med abu89-datasettet. Vi deler tilfeldig dataene i 80% trening og 20% test.\n\nset.seed(42)\nn &lt;- nrow(abu89)\ntrenings_indeks &lt;- sample(1:n, size = round(0.8 * n))\n\ntrening &lt;- abu89[trenings_indeks, ]\ntest     &lt;- abu89[-trenings_indeks, ]\n\nFunksjonen set.seed() sørger for at den tilfeldige oppdelingen blir den samme hver gang koden kjøres. Det er god praksis for reproduserbarhet.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#en-enkel-prediksjonsmodell",
    "href": "prediksjon_ml.html#en-enkel-prediksjonsmodell",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.4 En enkel prediksjonsmodell",
    "text": "16.4 En enkel prediksjonsmodell\nVi bruker helt vanlig lineær regresjon som prediksjonsmodell. La oss predikere timelønn (time89) basert på alder, kjønn, utdanning og yrkeserfaring.\n\nmod &lt;- lm(time89 ~ age + female + ed + fexp, data = trening)\n\nNå bruker vi predict() til å lage prediksjoner for testdataene:\n\ntest &lt;- test %&gt;%\n  mutate(predikert = predict(mod, newdata = test))\n\nVi kan visualisere hvor godt modellen treffer ved å plotte predikert mot faktisk timelønn:\n\nggplot(test, aes(x = predikert, y = time89)) +\n  geom_point(alpha = 0.3) +\n  geom_abline(intercept = 0, slope = 1, col = \"red\", linewidth = 1) +\n  labs(x = \"Predikert timelønn\", y = \"Faktisk timelønn\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDen røde linjen viser hvor punktene ville ligget hvis modellen predikerte perfekt. Vi ser at modellen fanger opp den generelle trenden, men det er mye variasjon den ikke klarer å forklare. Det er helt normalt for denne typen data.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#mål-på-prediksjonsevne",
    "href": "prediksjon_ml.html#mål-på-prediksjonsevne",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.5 Mål på prediksjonsevne",
    "text": "16.5 Mål på prediksjonsevne\nFor å tallfeste hvor gode prediksjonene er bruker vi gjerne to mål:\nRMSE (Root Mean Squared Error) måler gjennomsnittlig avvik mellom predikert og faktisk verdi, i samme enhet som utfallsvariabelen. Lavere er bedre.\nR-kvadrat (\\(R^2\\)) måler hvor stor andel av variasjonen i utfallsvariabelen modellen forklarer. Verdien ligger mellom 0 og 1, der 1 betyr perfekt prediksjon.\n\nresidualer &lt;- test$time89 - test$predikert\n\nrmse &lt;- sqrt(mean(residualer^2))\nr2   &lt;- 1 - sum(residualer^2) / sum((test$time89 - mean(test$time89))^2)\n\ndata.frame(RMSE = round(rmse, 1),\n           R2   = round(r2, 3))\n\n  RMSE    R2\n1 23.6 0.366\n\n\nHer er RMSE uttrykt i kroner, altså det gjennomsnittlige avviket i predikert timelønn. R-kvadrat forteller oss hvor mye av variasjonen i timelønn modellen fanger opp.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#kryssvalidering",
    "href": "prediksjon_ml.html#kryssvalidering",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.6 Kryssvalidering",
    "text": "16.6 Kryssvalidering\nOppdelingen i trening og test er litt tilfeldig. Kanskje fikk vi et uheldig utvalg? En mer robust tilnærming er kryssvalidering (engelsk: cross-validation). Prinsippet er at man deler dataene i \\(k\\) deler (f.eks. 10), og så bruker man 9 deler til trening og 1 del til testing. Dette gjentas slik at hver del brukes som testdata nøyaktig en gang. Til slutt regner man ut gjennomsnittet av prediksjonsfeilen over alle rundene.\nVi går ikke nærmere inn på implementeringen her, men det er viktig å vite at dette er standardmetoden for å evaluere prediksjonsmodeller. Pakker som caret og tidymodels i R gjør dette enkelt i praksis.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#regularisering-lasso",
    "href": "prediksjon_ml.html#regularisering-lasso",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.7 Regularisering: LASSO",
    "text": "16.7 Regularisering: LASSO\nNår man har mange mulige forklaringsvariable, kan det være fristende å inkludere alle sammen. Men det kan føre til overtilpasning. En teknikk som hjelper med dette er regularisering. Den mest brukte varianten kalles LASSO (Least Absolute Shrinkage and Selection Operator).\nLASSO fungerer som vanlig regresjon, men legger til en “straff” for store koeffisienter. Resultatet er at noen koeffisienter krympes mot null, og noen settes til nøyaktig null. Det betyr at LASSO automatisk velger bort variable som ikke bidrar nok til prediksjon. Dette er veldig nyttig når man har mange potensielle forklaringsvariable.\nVi viser ikke koden for LASSO her, men pakken glmnet er standardverktøyet i R. Poenget er at dette er et naturlig neste steg etter at man har forstått prediksjon med vanlig regresjon.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#klassifisering",
    "href": "prediksjon_ml.html#klassifisering",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.8 Klassifisering",
    "text": "16.8 Klassifisering\nSå langt har vi predikert en kontinuerlig variabel (timelønn). Men ofte vil vi predikere en kategorisk variabel. For eksempel: vil en person bli arbeidsledig eller ikke? Er en e-post spam eller ikke? Dette kalles klassifisering.\nFor klassifisering bruker vi gjerne logistisk regresjon (som vi har sett i et annet kapittel) i stedet for lineær regresjon. Evalueringsmålene er da litt annerledes: i stedet for RMSE ser vi på andelen riktig klassifiserte (accuracy) og andre mål som presisjon og recall.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#når-er-prediksjon-nyttig-i-samfunnsvitenskap",
    "href": "prediksjon_ml.html#når-er-prediksjon-nyttig-i-samfunnsvitenskap",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.9 Når er prediksjon nyttig i samfunnsvitenskap?",
    "text": "16.9 Når er prediksjon nyttig i samfunnsvitenskap?\nSelv om samfunnsvitenskap tradisjonelt er mest opptatt av forklaring, er det flere områder der prediksjon er sentralt:\n\nRisikoscoring: Identifisere individer med høy risiko for f.eks. tilbakefall til kriminalitet, frafall fra skolen, eller helseproblemer\nKlassifisering av tekst: Automatisk kategorisering av store mengder tekst, f.eks. avisartikler eller stortingsdebatter\nPrognoser: Forutsi utvikling i arbeidsledighet, kriminalitet eller demografiske trender\nVariabelseleksjon: Bruke maskinlæring til å identifisere hvilke variable som er viktigst, som utgangspunkt for videre analyse\n\nDet er verdt å merke seg at mange av maskinlæringsmetodene (tilfeldige skoger, nevrale nettverk osv.) bygger på de samme grunnprinsippene vi har gjennomgått her: dele opp data, evaluere prediksjonsevne, og balansere modellkompleksitet mot overtilpasning.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "prediksjon_ml.html#videre-lesning",
    "href": "prediksjon_ml.html#videre-lesning",
    "title": "16  Prediksjon og maskinlæring",
    "section": "16.10 Videre lesning",
    "text": "16.10 Videre lesning\nDette kapittelet har gitt en helt grunnleggende smakebit på prediksjon og maskinlæring. Temaet er svært omfattende, og vi har bare skrapt i overflaten. For de som vil lære mer er SOS2901 et introduksjonskurs i maskinlæring for samfunnsvitere ved UiO som tar utgangspunkt i nettopp disse konseptene. En god bok for videre lesning er An Introduction to Statistical Learning av James, Witten, Hastie og Tibshirani, som også er tilgjengelig gratis på nett.",
    "crumbs": [
      "Del III: Statistisk modellering",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Prediksjon og maskinlæring</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html",
    "href": "statistisk_inferens.html",
    "title": "17  Statistisk tolkning",
    "section": "",
    "text": "17.1 Stokastiske variabler og sannsynlighetsfordelinger\nDet vi omtaler som statistisk tolkning eller statistisk inferens handler om å skille systematikk fra støy. Altså: håndtering av usikkerhet ved estimeringen.\nPå nivå 2 handler det om å generalisere til en veldefinert populasjon, mens det på nivå 3 handler om å si om en kausal effekten kan skilles fra tilfeldig støy. De statistiske teknikken er imidlertid de samme. I praksis handler dette om følgende:\nDisse tre henger nøye sammen og er forskjellige uttrykk for feilmarginen ved et estimat. Her skal vi ikke gjennomgå begrunnelsene og det teoretiske grunnlaget for hvordan dette fungerer, men hoppe rett til det praktiske. En skikkelig forklaring følger fra sentralgrenseteoremet1.\nLitt enkelt kan vi si at det hvis man gjør en studie på en ordenlig måte, så er ganske sannsynlig at man får en estimat som er lik den sanne verdien. Men det er også ganske lite sannsynlig at man får et estimat som er nøyaktig lik den sanne verdien. Vi må regne med at estimatet avviker noe på grunn av tilfeldigheter! Det er veldig nyttig å vite noe om hvor mye feil man kan forvente å få av tilfeldige grunner. Altså: hva er feilmarginen til den metoden vi bruker til å estimere?\nDenne feilmarginen avhenger først og fremst av hvordan undersøkelsen er gjennomført. Utvalgsprosedyren er det viktigste: tilfeldig trukket utvalg er det mest grunnleggende momentet. Hvis det er systematiske skjevheter i dataene, så vil estimatet bli systematisk skjevt på måter vi ikke så lett kan håndtere med statistiske teknikker.\nDernest avhenger feilmarginen av utvalgsstørrelsen. Det er rett og slett slik at større data gir sikrere estimatet. Hvis utvalget består av 10 personer, så vil estimatet være langt mer usikkert enn hvis det hadde bestått av 5000 personer. Selv om det finnes en statistisk forklaring på dette, så er det relativt intuitivt å forstå. I utregninger vil standardfeilen bli mindre hvis antall observasjoner er større.\nTil sist avhenger feilmarginen av en grense vi selv setter, som gjerne kalles konfidensgrad. Denne setter vi selv, men det er vanlig å sette denne til 95%. Det gjør at man noen ganger sier “95% sikker”, hvilket er en nokså sleivete måte å si det på, men ikke helt galt under visse forutsetninger som vi kommer tilbake til.\nEn stokastisk variabel er en funksjon som tilordner en numerisk verdi til utfallet av et eksperiment. For eksempel, et terningkast er et eksperiment med et utfallsrom som omfatter tallene 1 til 6. Det er usikkerhet knyttet til utfallet av eksperimentet (vi vet ikke på forhånd hva utfallet er, altså om vi kaster 2 eller 5 eller noe annet). La oss si at jeg kaster terningen 100 ganger og teller antall ganger jeg får 6. Vi kan se på denne prosessen som en stokastisk variabel som måler antall 6’ere (den gir utfallet en numerisk verdi).\nHvis vi kaster en vanlig terning, har alle mulige utfall den samme sannsynligheten (1/6). I andre tilfeller, dvs. for andre stokastiske variabler, kan det hende at noen utfall er mer sannsynlige enn andre. Alle stokastiske variabler er derfor forbundet med en tilsvarende sannsynlighetsfordeling. En sannsynlighetsfordeling er en funksjon som tilordner en sannsynlighetsverdi (et tall mellom 0 og 1) til alle mulige verdier av den stokastiske variabelen. Et terningkast følger en binomisk fordeling. Andre fordelinger du kanskje har hørt om er Bernoulli-fordelingen, uniformfordelingen, Poisson-fordelingen og selsvsagt normalfordelingen.\nMini-oppgave: Kan du tenke på og forklare hvordan en survey er et stokastisk utfall (en realisering) av et eksperiment?",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html#stokastiske-variabler-og-sannsynlighetsfordelinger",
    "href": "statistisk_inferens.html#stokastiske-variabler-og-sannsynlighetsfordelinger",
    "title": "17  Statistisk tolkning",
    "section": "",
    "text": "17.1.1 Estimater som stokastiske variabler\nNår vi produserer statistiske estimater, er vi som oftest avhengige av et (tilfeldig) utvalg fra en større populasjon (vi måler som regel utdanningsnivået til et utvalg mennesker, ikke for hele befolkningen). Dette betyr at et estimat kan variere fra ett utvalg til et annet: det er usikkerhet knyttet til det. Med andre ord, kan selve estimatet anses som en stokastisk variabel. Med nok observasjoner, forteller sentralgrenseteoremet at denne stokastiske variabelen følger en normalfordeling med to viktige parametere: en gjennomsnittlig (forventet) verdi og en varians. Denne variansen kvantifiserer hvor mye estimatene våre kan variere dersom vi trekker et nytt (hypotetisk) utvalg fra populasjonen. I praksis, forholder vi oss som regel til standardavviket og ikke variansen til denne utvalgsfordelingen. Standardavviket til denne fordelingen kalles standardfeilen (se under).\nStandardfeilen forbundet med et estimat kan brukes til å bygge et konfidensintervall (se under). Dette er et intervall som med en gitt sannsynlighet inneholder den sanne verdien av det vi prøver å estimere (gitt antakelsene som vår statistiske modell legger til grunn). Et 95 prosent konfidensintervall er definert som et intervall som gjennom hypotetisk repeterte datasamlinger, “fanger” denne sanne verdien med 95 prosent sannsynlighet. Som en røff tommelfingerregel, tilsvarer et slikt intervall estimatet ± 2 ganger standardfeilen.\nMini-oppgave: Gitt det du vet om normalfordelingen, forklar hvorfor vi er 95 prosent sikre på at den sanne verdien til det vi estimerer faller innenfor ca. 2 ganger standardfeilen.",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html#estimater-og-feilmarginer",
    "href": "statistisk_inferens.html#estimater-og-feilmarginer",
    "title": "17  Statistisk tolkning",
    "section": "17.2 Estimater og feilmarginer",
    "text": "17.2 Estimater og feilmarginer\n\n17.2.1 Estimat\nLa oss si at du ønsker å si noe om gjennomsnittet i populasjonen, men har bare data om et tilfeldig utvalg fra denne populasjonen. Når du da regner ut gjennomsnittet i utvalget er det din beste gjetning på hva gjennomsnittet er i populasjonen. En slik gjetning kaller vi et estimat.\n\n\n17.2.2 Standardfeil\nStandardfeilen uttrykker usikkerheten ved estimatet. Standardfeilen til estimatet er et mål på usikkerheten ved målemetoden. Usikker målemetode gjør at feilen kan være større.\nOrdet standardfeil er lett å blande sammen med standardavvik i mer generell forstand, så la oss ta det med det samme. Standardavviket beskriver som regel variasjon i observerte data, f.eks. hvis man vil beskrive hvordan personers inntekt varierer rundt gjennomsnittet. Standardavviket beskriver altå variasjon i data.\nStandardfeilen beskriver derimot ikke data, men sannsynlighetsfordelingen for hvordan vi forventer at estimatet vil kunne avvike fra den sanne verdien på grunn av tilfeldigheter.\nSentralgrenseteoremet sier at estimatet på et gjennomsnitt vil ha tilfeldige feil som er normalfordelt, og dermed kan vi bruke normalfordelingen til å si noe om usikkerheten ved estimatet. Dette er forsøkt illustrert nedenfor der x-aksen viser hvor mye estimatet kan avvike fra den sanne verdien, mens kurven viser hvor sannsynligsfordelingen til avviket. Den stiplede linjen viser den sanne verdien. Når x-aksen er avvik fra sanne verdien, så vil altså \\(x = 0\\) bety null avvik fra sanne verdien: helt riktig estimat.\nAltså: det er aller mest sannsynlig å få et estimat som ligger nærme den sanne verdien, men litt avvik (større eller lavere estimat) er nesten like sannsynlig. Jo lengre til hver av sidene man går (større feil), jo mindre sannsynlig er det å få et slikt estimat.\n\n\n\n\n\n\n\n\n\nSkalaen på x-aksen er \\(z\\), som i denne sammenheng kan tolkes som antall standardfeil. Den følger en standard normalfordeling som har kjente og faste egenskaper. Vi vet f.eks. at andelen nedenfor -1.96 er 0.025, og det samme gjelder ovenfor 1.96. Dette er illustrert i figuren nedenfor. Det er altså 0.05 (dvs 5%) sannsynlighet for å få et estimat som ligger 1.96 standardfeil unna den sanne verdien. Motsatt er sannsynligheten for å få et estimatet innenfor intervallet mellom -1.96 og 1.96 tilsvarende 95%. Dette er grunnlaget for det vi kaller konfidensintervall.\n\n\n\n\n\n\n\n\n\n\n\n17.2.3 Konfidensintervall\nHvis man ønsker å være “95% sikker”, så bruker man altså et 95% konfidensintervall. Det er ikke noe magisk ved akkurat 95% og er primært blitt en norm. Grunnen er bare at det skal være en ganske lav sannsynlighet for at estimatet skyldes tilfeldig variasjon.\nTil ethvert estimat er knyttet en feilmargin som uttrykkes ved \\(z \\times se\\), der \\(se\\) er forkortelse for standardfeil (engelsk: “standard error”). \\(z\\) er et tall som er knyttet til grad av usikkerhet ved feilmarginen. En feilmargin basert på 95% konfidensgrad er dermed \\(1.96 \\times se\\). Hvis man så tar denne feilmarginen til hver side, så gir det samme som illustrert i figuren ovenfor.\nEt konfidensintervall er altså bare å ta hensyn til feilmarginen til hver side av estimatet. Når vi bruker dette i praksis baserer vi oss på denne normalfordelingen og trenger bare å få regnet ut standardfeilen i tillegg.\n\n\n[1] 91.0712\n\n\nHvis man f.eks. har estimert gjennomsnittlig timelønn til å være 90.2 og standardfeilen er 0.5. Da blir 95% konfidensintervallet som følger:\n\\[ 90.1 \\pm 1.96 \\times 0.47 = [89.2, 91.1]\\] Dette betyr at vi har brukt en målemetode som har en feilmargin som gjør at vi kan være 95% sikker på at den sanne verdien ligger innenfor dette intervallet.\n\n17.2.3.1 Er man egentlig “95% sikker”?\nDet sies ofte at feilmarginen uttrykker hvor sikker man er. Det er jo ikke helt riktig - eller det er riktig under noen spesielle forutsetninger om hva man mener med “sikker”. La oss derfor ta dette med en gang.\nEt 95% konfidensintervall er vårt anslag på hvor god vår målemetode er. Vi har jo regnet ut f.eks. et gjennomsnitt og det er jo greit nok. Usikkerheten kommer fra utvalgsprosedyren og variasjonen i data.\nVi vet ikke hvorvidt vårt estimat ligger nærme eller langt unna den sanne verdien. Det vi derimot vet noe om er påliteligheten i den metoden vi har brukt. Det viktigste her er altså tilfeldig utvalg, og hvis utvalget ikke er tilnærmet tilfeldig trukket, så bryter det hele sammen.\nNår man sier at konfidensintervallet uttrykker at man er “95% sikker” på at den sanne verdien ligger i det intervallet mener man da følgende: Man har brukt en metode (dvs utvalg og utregninger og det hele) som har en feilmargin. Denne feilmarginen er slik at hvis man gjorde estimeringen (altså nytt utvalg hver gang) på samme måte svært mange ganger (f.eks. uendelig mange ganger), så ville 95% av resultatene ligget innenfor et slikt intervall.\nMan gjør selvsagt ikke samme undersøkelse tusenvis av ganger, så dette er en hypotetisk tanke. Man man kan også tenke seg at mange ulike forskere gjør en tilsvarende studie og får litt forskjellige resultat. Disse resultatene vil (i teorien) fordele seg som en normalfordeling rundt den sanne verdien. Noen ganske få vil ligge langt unna sannheten.\n\n\n\n17.2.4 T-testen\nHvis man skal sammenligne to grupper, så vet vi i utgangspunktet at dataene fra et utvalg antakeligvis vil vise at de ikke er helt like på grunn av tilfeldig variasjon. Det kan altså være at gruppene er like i virkeligheten, bare at dataene våre tilfeldigvis ble litt forskjellige. Det må vi jo regne med, men det er begrenset hvor forskjellig vi kan forvente at gruppene er på grunn av rene tilfeldigheter.\nSe igjen på figuren over av normalfordelingen i omtalen av konfidensintervall. Gitt at det ikke er noen sann forskjell mellom gruppene, så vil vi forvente at estimatet ligger innenfor en viss feilmargin. Det betyr at en observert forskjell i dataene som ligger innenfor denne feilmarginen vil være konsistent med at forskjellene bare skyldes tilfeldig variasjon. Motsatt: hvis estimatet ligger utenfor denne feilmarginen, ja da kan vi si at det ikke er konsistent med dette utgangspunktet om at forskjellene bare skyldes tilfeldig variasjon.\nEn av de meste brukte statistiske testene i praksis er “t-testen”. Du kan tenke på det som en beslutningsregel: hva skal til for at du skal bestemme deg for å tro at forskjellen ikke skyldes tilfeldigheter? Standardfeil og feilmarginer er det samme som før, så du må bare bestemme deg for hvor stor feilmargin du er villig til å operere med. Hvis estimatet på en differanse er større enn feilmarginen, da forkastes hypotesen om at forskjeller skyles tilfeldigher. Altså: forskjellene i data må da skyldes noe mer systematisk.\nSå i utgangspunktet så må du altså ta stilling til om du mener det er en forskjell - eller ikke. Du kan ikke konkludere med at det “kanskje er en forskjell”, men må ta et valg. Derfor kaller vi gjerne dette for hypotesetesting i en litt snever forstand. Det er bare to mulige hypoteser:\n\\(H_0\\): Det er egentlig ingen forskjell mellom gruppene, og forskjell i dataene skyldes bare tilfeldig variasjon. (Nullhypotesen). \\(H_A\\): Det er faktisk en forskjell mellom gruppene, og forskjellen i dataene er for stor til av det er sannsynlig at det skyldes tilfeldig variasjon. (Alternativ hypotese).\n\n17.2.4.1 Formler og slikt\nT-testen i prinsippet en sammenligning mellom estimatets størrelse og standardfeilen til estimatet. Vi kan skrive det som følger:\n\\[\n\\frac{\\mu}{SE(\\mu)} = t\n\\]\nEller sagt på en annen måte: \\[\n\\frac{estimat}{standardfeil} = t\n\\]\nDet betyr at \\(t\\)-verdien egentlig bare er forholdstallet mellom estimatet og standardfeilen. Intuitivt kan man vel forstå at hvis usikkerheten bør være mindre enn estimatet. Altså: hvis du har estimert en forskjell i timelønn mellom to grupper, og feilmarginen til dette estimatet er større enn forskjellen, ja, da er det vanskelig å lære noe særlig fra det estimatet.\nVerdien \\(t\\) tilsvarer verdien \\(z\\) som vi nevnte i forbindelse med konfidensintervall. Så hvis \\(t\\) er større enn \\(z\\), så ligger estimatet utenfor konfidensintervallet.\nTolkningen av \\(t\\)-verdien brukes gjerne som en en beslutningsregel: Ja/Nei. Litt firkantet, med andre ord. Men \\(t\\)-verdien er også knyttet til normalfordelingen på samme måte som nevnt ovenfor i forbindelse med konfidensintervaller. Ethvert mulig resultat er knyttet til en viss sannsynlighet for at det skal skje ved en tilfeldighet.\n\n\n17.2.4.2 P-verdi\nTolkningen av p-verdien er i hvilken grad det er sannsynlig å få det observerte resultatet ved en tilfeldighet hvis NULL-hypotesen er riktig. Dette høres ganske pussig ut. Tanken er at man nesten alltid vil observere noe forskjell fra null, og det kan skje ved en tilfeldighet. Hvis null-hypotesen er riktig er det mindre sannsynlig at vi observerer en veldig stor forskjell. Men hvor stor forskjell er det, egentlig? Løsningen er å se avstanden fra null i lys av standardfeilen. Hvis man bruker en usikker målemetode, så er det mer sannsynlig å observere en stor forskjell ved tilfeldigheter enn om man bruker en veldig nøyaktig målemetode.\nI praksis: Tenk at du observerer en stor forskjell mellom to grupper. Med “stor” mener vi f.eks. at forskjellen er over dobbelt så stor som standardfeilen. Da får vi en p-verdi som er \\(p &lt; 0.05\\). Da kan vi si at hvis nullhypotesen er sann, så er det lite sannsynlig at vi ville fått et slikt resultat på grunn av tilfeldigheter.^(Hvis vi ønsker være pinlig korrekte kan vi også si noe slikt som at hvis man gjorde målingen tusenvis av ganger, så ville 5% av resultatene ligge så langt unna null (eller lengre).)\nSå er logikken videre at vi som hovedregel ikke tror på resultater som er usannsynlige. Så i stedet for å holde fast på nullhypotesen velger vi i stedet å tro på den alternative hypotesen.",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html#kan-man-velge-fritt-konfidensgrad",
    "href": "statistisk_inferens.html#kan-man-velge-fritt-konfidensgrad",
    "title": "17  Statistisk tolkning",
    "section": "17.3 Kan man velge fritt konfidensgrad?",
    "text": "17.3 Kan man velge fritt konfidensgrad?\nDet er ingenting magisk med tallet 1.96 eller \\(p &lt; 0.05\\). Det er en konvensjon. Konfidensgrad er nemlig noe du velger. All tolkning av “statistisk signifikans” er basert på en gitt konfidensgrad.\nProblemet oppstår hvis du først ser på resultatene og så velger en konfidensgrad som passer til det du har mest lyst til å konkludere med. Det er rett og slett juks. For at du skal velge en annen konfidensgrad må du si det høyt og tydelig før du gjennomfører undersøkelsen - og da må du faktisk etterleve det når resultatene foreligger. Du bør også kunne argumentere selvstendig for en annen konfidensgrad, altså før resultatene foreligger. Dette innebærer at det ikke er godt nok å si det høyt ut i luften der du sitter alene for deg selv. Det må pre-registeres på et offentlig sted, f.eks. osf.io eller tilsvarende websider.\nDette er egentlig en mye større diskusjon, men verd å være obs på. Du kan velge konfidensgrad, men i så fall må du gjøre det på en ordenlig måte hvis du vil bli tatt seriøst av andre. Vi skal ikke drive med cherry-picking av resultater og konklusjoner!",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html#statistiske-tester-generelt",
    "href": "statistisk_inferens.html#statistiske-tester-generelt",
    "title": "17  Statistisk tolkning",
    "section": "17.4 Statistiske tester generelt",
    "text": "17.4 Statistiske tester generelt\nDet finnes en hel haug av statistiske tester. Prinsippet er gjerne variasjoner av t-testen og har disse komponentene:\n\nen nullhypotese og et alternativ\nen statistikk, altså et måltall som er et avstandsmål mellom observert resultat og hva man forventer under nullhypotesen\nen statistisk modell for samplingfordelingen som sier noe om fordelingen av tilfeldige feil\nen uttalt beslutningsregel for konklusjonen. Et vanlig mål er at hvis \\(p &lt; 0.05\\), så forkastes nullhypotesen.\n\nDu har sikker lært om \\(\\chi^2\\) testen for krysstabeller. Den er forskjellig på mange måter fra \\(t\\)-testen, men logikken er tilsvarende: \\(\\chi^2\\) er et avstandsmål for hva vi forventer gitt hypotesen om ingen forskjell. Hvis resultatet fra dataanalysen er for langt unna dette, så beslutter vi å tro at forskjellen skyldes systematikk.\n\n\n\n\nMoore, David S., Notz William I, and Michael Fligner. 2021. The Basic Practice of Statistics. W.H.Freeman & Co Ltd.",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistisk_inferens.html#footnotes",
    "href": "statistisk_inferens.html#footnotes",
    "title": "17  Statistisk tolkning",
    "section": "",
    "text": "Hvis dette er ukjent stoff for deg kan du se f.eks. Moore, Notz, and Fligner (2021), kapittel 15, etterfulgt av forlengelsen til konfidensintervall og statistiske tester i kapittel 16 og 17.↩︎",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Statistisk tolkning</span>"
    ]
  },
  {
    "objectID": "statistikk_i_praksis.html",
    "href": "statistikk_i_praksis.html",
    "title": "18  Statistikk i praksis",
    "section": "",
    "text": "18.1 Deskriptiv statistikk\nStatistiske analyser innebærer å analysere data og vurdere usikkerhet. En kjerneoppgave er å sammenligne. Enten mellom grupper eller på ulike steder langs en kontinuerlig skala. Når vi sammenligner Usikkerheten i sammenligningen uttrykkes ved p-verdier og konfidensintervaller.\nNår man har en tabell med deskriptiv statistikk fordelt på grupper, så gjør man jo en sammenligning av disse gruppene på de aktuelle variablene. Da kan man bare legge til en statistisk test for denne sammenligningen. I følgende eksempel brukes tbl_summary med tilhørende add_difference. I første omgang tar vi bare med kontinuerlige variable. Resultatet blir tilsvarende som i det tidligere kapittelet for deskriptiv statistikk, men her legges det til tre kolonner: forskjellen i gjennomsnitt, konfidensintervallet og p-verdi fra en \\(t\\)-test.^(Legg merke til fotnoten som spesifiserer “Welch two sample t-test”. Dette er den vanlig t-testen. Den opprinnelige “Student’s t-test” forutsetter lik varians i begge grupper, noe som Welch t-test ikke gjør. Vi kaller det bare for \\(t\\)-test. Dette bare til oppklaring.)\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  #select(-io_nr) %&gt;%\n  select(female, time89, ed,  fexp, age) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_difference() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nKvinner\nN = 1,9341\nMenn\nN = 2,1931\nDifference2\n95% CI2\np-value2\n\n\n\n\nGjennomsnittlig timelønn 1989\n79 (24)\n100 (32)\n-21\n-23, -19\n&lt;0.001\n\n\nÅr utdanning\n2.38 (2.40)\n2.96 (2.66)\n-0.58\n-0.74, -0.43\n&lt;0.001\n\n\nBedriftserfaring\n0.83 (0.81)\n1.05 (0.97)\n-0.22\n-0.27, -0.16\n&lt;0.001\n\n\nAlder\n40 (13)\n40 (12)\n-0.17\n-0.93, 0.58\n0.7\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\nAbbreviation: CI = Confidence Interval\nLegg merke til at kollonnen “Difference” er forskjellen i gjennomsnitt i de to gruppene, og konfidensintervallet gjelder for denne differansen. Den gjennomsnittlige forskjellen i timelønn for menn er altså 21 kroner høyere enn for kvinner, men når vi tar feilmarginen med i beregningen er det rimelig å si at den ligger mellom 19 og 23 kroner høyere for menn enn for kvinner, siden et 95% konfidensintervall tilsier det.\nabu89 %&gt;% \n  select(female, time89, ed,  fexp, age) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_p() \n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nKvinner\nN = 1,9341\nMenn\nN = 2,1931\np-value2\n\n\n\n\nGjennomsnittlig timelønn 1989\n79 (24)\n100 (32)\n&lt;0.001\n\n\nÅr utdanning\n2.38 (2.40)\n2.96 (2.66)\n&lt;0.001\n\n\nBedriftserfaring\n0.83 (0.81)\n1.05 (0.97)\n&lt;0.001\n\n\nAlder\n40 (13)\n40 (12)\n0.7\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\nFor kategoriske variable bruker man ikke en t-test, men en test som omtales som \\(\\chi^2\\) test (uttales som “kji-kvadrat test”).1\nabu89 %&gt;% \n  select(female, klasse89, promot, private) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              missing = \"no\") %&gt;% \n  add_p() \n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nKvinner\nN = 1,9341\nMenn\nN = 2,1931\np-value2\n\n\n\n\nKlasse\n\n\n\n\n&lt;0.001\n\n\n    I Øvre serviceklasse\n74 (3.9%)\n254 (12%)\n\n\n\n\n    II Nedre serviceklasse\n555 (29%)\n626 (29%)\n\n\n\n\n    III Rutinefunksjonærer\n986 (52%)\n262 (12%)\n\n\n\n\n    V-VI Faglærte arbeidere\n46 (2.4%)\n602 (28%)\n\n\n\n\n    VIIa Ufaglærte arbeidere\n244 (13%)\n393 (18%)\n\n\n\n\nNoen gang forfremmet\n\n\n\n\n&lt;0.001\n\n\n    NEI\n1,308 (68%)\n1,260 (57%)\n\n\n\n\n    JA\n626 (32%)\n933 (43%)\n\n\n\n\nPrivat sektor\n\n\n\n\n&lt;0.001\n\n\n    Public\n1,016 (53%)\n586 (27%)\n\n\n\n\n    Private\n918 (47%)\n1,607 (73%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\nDet kan også settes sammen i en felles tabell.\nabu89 %&gt;% \n  select(-io_nr) %&gt;%\n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_overall() %&gt;% \n  add_p() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall\nN = 4,1271\nKvinner\nN = 1,9341\nMenn\nN = 2,1931\np-value2\n\n\n\n\nGjennomsnittlig timelønn 1989\n90 (30)\n79 (24)\n100 (32)\n&lt;0.001\n\n\nÅr utdanning\n2.69 (2.56)\n2.38 (2.40)\n2.96 (2.66)\n&lt;0.001\n\n\nAlder\n40 (12)\n40 (13)\n40 (12)\n0.7\n\n\nKlasse\n\n\n\n\n\n\n&lt;0.001\n\n\n    I Øvre serviceklasse\n328 (8.1%)\n74 (3.9%)\n254 (12%)\n\n\n\n\n    II Nedre serviceklasse\n1,181 (29%)\n555 (29%)\n626 (29%)\n\n\n\n\n    III Rutinefunksjonærer\n1,248 (31%)\n986 (52%)\n262 (12%)\n\n\n\n\n    V-VI Faglærte arbeidere\n648 (16%)\n46 (2.4%)\n602 (28%)\n\n\n\n\n    VIIa Ufaglærte arbeidere\n637 (16%)\n244 (13%)\n393 (18%)\n\n\n\n\nNoen gang forfremmet\n\n\n\n\n\n\n&lt;0.001\n\n\n    NEI\n2,568 (62%)\n1,308 (68%)\n1,260 (57%)\n\n\n\n\n    JA\n1,559 (38%)\n626 (32%)\n933 (43%)\n\n\n\n\nBedriftserfaring\n0.95 (0.91)\n0.83 (0.81)\n1.05 (0.97)\n&lt;0.001\n\n\nPrivat sektor\n\n\n\n\n\n\n&lt;0.001\n\n\n    Public\n1,602 (39%)\n1,016 (53%)\n586 (27%)\n\n\n\n\n    Private\n2,525 (61%)\n918 (47%)\n1,607 (73%)\n\n\n\n\n\n1 Mean (SD); n (%)\n\n\n2 Welch Two Sample t-test; Pearson’s Chi-squared test",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistikk i praksis</span>"
    ]
  },
  {
    "objectID": "statistikk_i_praksis.html#regresjon",
    "href": "statistikk_i_praksis.html#regresjon",
    "title": "18  Statistikk i praksis",
    "section": "18.2 Regresjon",
    "text": "18.2 Regresjon\nFor regresjon er det i prinsippet det samme: regresjonskoeffisientene er estimater med usikkerhet som uttrykkes med standardfeil og tilhørende konfidenstintervaller og p-verdier. Merk at p-verdiene er resultat av en helt ordinær t-test:\n\\[\nt = \\frac{\\beta}{se_\\beta}\n\\]\nHusk at \\(\\beta\\) er et estimat på en forskjell mellom grupper eller nivåer på en kontinuerlig variabel. Tolkningen er derfor lik som for t-test: kan denne forskjellen skyldes tilfeldig variasjon? Eller er forskjellen såpass stor i forhold til feilmarginen at vi velger å tolke det som en systematisk forskjell? Hvis p-verdien er høy (typisk: større enn 0.05), så er vi ikke tilstrekkelig sikker på at det ikke bare er tilfeldig støy.\n\nlm_est1 &lt;- lm(time89 ~ female , data = abu89)\nmodelsummary(lm_est1)\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  99.844\n                \n                \n                  \n                  (0.637)\n                \n                \n                  female\n                  -20.752\n                \n                \n                  \n                  (0.932)\n                \n                \n                  Num.Obs.\n                  3759\n                \n                \n                  R2\n                  0.117\n                \n                \n                  R2 Adj.\n                  0.116\n                \n                \n                  AIC\n                  35854.9\n                \n                \n                  BIC\n                  35873.6\n                \n                \n                  Log.Lik.\n                  -17924.434\n                \n                \n                  F\n                  496.278\n                \n                \n                  RMSE\n                  28.49\n                \n        \n      \n    \n\n\n\n\n18.2.1 Multippel regresjon\n\nlm_est2 &lt;- lm(time89 ~ female + age , data = abu89)\nmodelsummary(lm_est2)\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  81.101\n                \n                \n                  \n                  (1.585)\n                \n                \n                  female\n                  -20.625\n                \n                \n                  \n                  (0.912)\n                \n                \n                  age\n                  0.474\n                \n                \n                  \n                  (0.037)\n                \n                \n                  Num.Obs.\n                  3759\n                \n                \n                  R2\n                  0.154\n                \n                \n                  R2 Adj.\n                  0.153\n                \n                \n                  AIC\n                  35694.9\n                \n                \n                  BIC\n                  35719.8\n                \n                \n                  Log.Lik.\n                  -17843.437\n                \n                \n                  F\n                  341.699\n                \n                \n                  RMSE\n                  27.88\n                \n        \n      \n    \n\n\n\n\n\n18.2.2 Interaksjonsledd\n\nlm_est3 &lt;- lm(time89 ~ female + age + female * age , data = abu89)\nmodelsummary(lm_est3)\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  75.854\n                \n                \n                  \n                  (2.126)\n                \n                \n                  female\n                  -9.905\n                \n                \n                  \n                  (3.040)\n                \n                \n                  age\n                  0.606\n                \n                \n                  \n                  (0.051)\n                \n                \n                  female × age\n                  -0.272\n                \n                \n                  \n                  (0.074)\n                \n                \n                  Num.Obs.\n                  3759\n                \n                \n                  R2\n                  0.157\n                \n                \n                  R2 Adj.\n                  0.156\n                \n                \n                  AIC\n                  35683.2\n                \n                \n                  BIC\n                  35714.4\n                \n                \n                  Log.Lik.\n                  -17836.611\n                \n                \n                  F\n                  233.121\n                \n                \n                  RMSE\n                  27.83\n                \n        \n      \n    \n\n\n\n\nmodelsummary(list(lm_est1, lm_est2, lm_est3))\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  99.844\n                  81.101\n                  75.854\n                \n                \n                  \n                  (0.637)\n                  (1.585)\n                  (2.126)\n                \n                \n                  female\n                  -20.752\n                  -20.625\n                  -9.905\n                \n                \n                  \n                  (0.932)\n                  (0.912)\n                  (3.040)\n                \n                \n                  age\n                  \n                  0.474\n                  0.606\n                \n                \n                  \n                  \n                  (0.037)\n                  (0.051)\n                \n                \n                  female × age\n                  \n                  \n                  -0.272\n                \n                \n                  \n                  \n                  \n                  (0.074)\n                \n                \n                  Num.Obs.\n                  3759\n                  3759\n                  3759\n                \n                \n                  R2\n                  0.117\n                  0.154\n                  0.157\n                \n                \n                  R2 Adj.\n                  0.116\n                  0.153\n                  0.156\n                \n                \n                  AIC\n                  35854.9\n                  35694.9\n                  35683.2\n                \n                \n                  BIC\n                  35873.6\n                  35719.8\n                  35714.4\n                \n                \n                  Log.Lik.\n                  -17924.434\n                  -17843.437\n                  -17836.611\n                \n                \n                  F\n                  496.278\n                  341.699\n                  233.121\n                \n                \n                  RMSE\n                  28.49\n                  27.88\n                  27.83",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistikk i praksis</span>"
    ]
  },
  {
    "objectID": "statistikk_i_praksis.html#footnotes",
    "href": "statistikk_i_praksis.html#footnotes",
    "title": "18  Statistikk i praksis",
    "section": "",
    "text": "Denne gir identisk resultat som z-test for andeler.↩︎",
    "crumbs": [
      "Del IV: Statistisk tolkning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Statistikk i praksis</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html",
    "href": "design_tolkning_teori.html",
    "title": "19  Forskningsdesign og tolkning",
    "section": "",
    "text": "19.1 Observasjonsdata vs. eksperimentelle data\nDenne boken handler primært om hvordan du gjør ting i R. Men det er like viktig å forstå hva du faktisk gjør og hvorfor. Statistiske analyser gir bare mening i lys av forskningsdesignet og den substansielle teorien du jobber med. I dette kapittelet diskuterer vi noen viktige prinsippelle poenger som bør ligge i bakhodet når du gjør dataanalyse.\nI samfunnsvitenskap jobber vi nesten alltid med observasjonsdata. Det vil si at vi observerer verden slik den er, uten å ha manipulert noe. I et eksperiment kan forskeren derimot kontrollere hvem som får en “behandling” og hvem som ikke får det.\nDenne forskjellen har store konsekvenser for hva vi kan konkludere. I et eksperiment med tilfeldig fordeling av behandling kan vi si at forskjeller mellom gruppene skyldes behandlingen. Med observasjonsdata kan vi som regel ikke trekke slike slutninger like enkelt, fordi gruppene kan være forskjellige på mange andre måter enn det vi er interessert i.\nDet betyr ikke at observasjonsdata er ubrukelige - det er tvert imot svært mye nyttig kunnskap vi kan trekke ut. Men vi må være bevisste på begrensningene og tolke resultatene deretter.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#korrelasjon-er-ikke-kausalitet",
    "href": "design_tolkning_teori.html#korrelasjon-er-ikke-kausalitet",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.2 Korrelasjon er ikke kausalitet",
    "text": "19.2 Korrelasjon er ikke kausalitet\nDu har garantert hørt dette utsagnet før. Men hva betyr det egentlig i praksis?\nNår vi finner en statistisk sammenheng mellom to variable, betyr det at de samvarierer. Men det betyr ikke nødvendigvis at den ene forårsaker den andre. Det finnes flere grunner til at to variable kan samvariere:\n\nKausalitet: X forårsaker faktisk Y. For eksempel: røyking forårsaker lungekreft.\nOmvendt kausalitet: Y forårsaker X. For eksempel: dårlig helse (Y) kan føre til lavere inntekt (X), ikke bare omvendt.\nFelles bakenforliggende årsak (confounding): En tredje variabel Z påvirker både X og Y. For eksempel: fysisk aktivitet (X) og god helse (Y) kan begge påvirkes av sosioøkonomisk bakgrunn (Z).\nTilfeldig samvariasjon: Med nok variable vil noen alltid korrelere tilfeldig.\n\nI observasjonsstudier er det spesielt confounding som er den store utfordringen. Det er dette vi prøver å håndtere med kontrollvariable i regresjonsanalyser (se kapittelet om kontrollvariable), men det er begrenset hva vi kan oppnå med statistiske metoder alene.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#seleksjonsskjevhet",
    "href": "design_tolkning_teori.html#seleksjonsskjevhet",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.3 Seleksjonsskjevhet",
    "text": "19.3 Seleksjonsskjevhet\nSeleksjonsskjevhet oppstår når utvalget vi studerer ikke er representativt for populasjonen vi er interessert i. Det kan skje på mange måter:\n\nUtvalgsskjevhet: De som svarer på en spørreundersøkelse er kanskje systematisk forskjellige fra de som ikke svarer.\nSelvseleksjon: Folk velger selv om de deltar i et program eller en aktivitet. De som velger å delta kan være systematisk forskjellige fra de som ikke deltar.\nFrafall: Deltakere faller ut av en studie, og frafallet er kanskje ikke tilfeldig.\n\nI praksis betyr dette at vi alltid bør tenke over: hvem er det egentlig vi studerer? Og kan resultatene generaliseres til en bredere befolkning?",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#teoriens-rolle",
    "href": "design_tolkning_teori.html#teoriens-rolle",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.4 Teoriens rolle",
    "text": "19.4 Teoriens rolle\nStatistiske analyser kan fortelle oss om det finnes en sammenheng mellom variable, og hvor sterk sammenhengen er. Men statistikken kan ikke fortelle oss hvorfor sammenhengen finnes. Det er teoriens jobb.\nTeori er viktig for dataanalyse på flere måter:\n\nVelge variable: Teori hjelper oss å bestemme hvilke variable som bør inkluderes i analysen og hvilke som bør holdes utenfor.\nBestemme modellstruktur: Bør vi inkludere interaksjonsledd? Ikke-lineære termer? Det avhenger av hva teorien sier om sammenhengen.\nTolke resultater: Et regresjonsestimat er bare et tall inntil vi legger en substansiell tolkning på det.\nIdentifisere confounders: Teori forteller oss hvilke bakenforliggende variable som kan forstyrre analysen.\n\nPoenget er at god dataanalyse krever faglig forståelse av det du studerer. R er et verktøy, men det er du som må bruke det klokt.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#dager-rettet-asyklisk-graf",
    "href": "design_tolkning_teori.html#dager-rettet-asyklisk-graf",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.5 DAGer: Rettet asyklisk graf",
    "text": "19.5 DAGer: Rettet asyklisk graf\nEt nyttig verktøy for å tenke om kausale sammenhenger er DAGer (Directed Acyclic Graphs, eller rettede asykliske grafer). En DAG er et diagram som viser antatte kausale sammenhenger mellom variable.\n\nlibrary(ggdag)\n\ndag &lt;- dagify(\n  Y ~ X + Z,\n  X ~ Z,\n  labels = c(\"Y\" = \"Lønn\",\n             \"X\" = \"Utdanning\",\n             \"Z\" = \"Familiebakgrunn\")\n)\n\nggdag(dag, text = FALSE, use_labels = \"label\") +\n  theme_dag()\n\nI denne DAGen ser vi at:\n\nFamiliebakgrunn påvirker både utdanning og lønn\nUtdanning påvirker lønn\nFamiliebakgrunn er en confounding-variabel som vi bør kontrollere for\n\nDAGer tvinger oss til å være eksplisitte om hvilke kausale antakelser vi gjør. Det kan avsløre problemer vi ikke hadde tenkt på. Det kan også hjelpe oss å unngå å kontrollere for variable vi ikke bør kontrollere for (se kapittelet om kontrollvariable, avsnittet om “dårlige kontrollvariable”).\nFor mer om DAGer anbefales å utforske pakken dagitty og nettressursen daggity.net. Der kan du tegne DAGer interaktivt og få hjelp til å identifisere hvilke variable du bør kontrollere for.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#trusler-mot-validitet",
    "href": "design_tolkning_teori.html#trusler-mot-validitet",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.6 Trusler mot validitet",
    "text": "19.6 Trusler mot validitet\nValiditet handler om hvorvidt vi faktisk måler og konkluderer det vi tror vi gjør. Det er vanlig å skille mellom:\n\n19.6.1 Intern validitet\nIntern validitet handler om hvorvidt den observerte sammenhengen mellom X og Y faktisk reflekterer en kausal effekt. Trusler mot intern validitet inkluderer:\n\nConfounding: Uobserverte variable som påvirker både X og Y\nOmvendt kausalitet: Y påvirker X, ikke bare omvendt\nSeleksjonsskjevhet: Systematiske forskjeller mellom grupper\nMålefeil: Variablene måler ikke det vi tror de måler\n\n\n\n19.6.2 Ekstern validitet\nEkstern validitet handler om hvorvidt resultatene kan generaliseres til andre kontekster. Selv om en effekt er godt identifisert i én studie, er det ikke sikkert den gjelder i en annen kontekst, tidsperiode eller populasjon.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#kvasi-eksperimentelle-design",
    "href": "design_tolkning_teori.html#kvasi-eksperimentelle-design",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.7 Kvasi-eksperimentelle design",
    "text": "19.7 Kvasi-eksperimentelle design\nI mange tilfeller kan vi komme nærmere kausale konklusjoner selv med observasjonsdata ved å bruke smarte forskningsdesign. Dette er et stort felt, men her nevnes bare kort noen av de viktigste tilnærmingene:\n\nDifference-in-differences (DiD): Sammenligner endringer over tid mellom en behandlingsgruppe og en kontrollgruppe. Krever antakelse om parallelle trender.\nRegression discontinuity (RDD): Utnytter at en behandling tildeles basert på en terskelverdi (f.eks. aldersgrenser, poenggrenser).\nInstrumentvariabler (IV): Bruker en ekstern variabel som påvirker X, men ikke Y direkte, for å estimere kausal effekt.\nMatching: Sammenligner individer som er like på observerbare kjennetegn, men forskjellige på behandlingsvariabelen.\n\nDisse metodene går langt utover denne boken, men det er nyttig å vite at de finnes. Hvis du skal gjøre kausale analyser med observasjonsdata, bør du sette deg inn i minst én av disse.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#praktiske-råd",
    "href": "design_tolkning_teori.html#praktiske-råd",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.8 Praktiske råd",
    "text": "19.8 Praktiske råd\nHer er noen konkrete råd for å tenke godt om forskningsdesign i din egen analyse:\n\nVær eksplisitt om antakelser: Skriv ned hva du antar om kausale sammenhenger. Tegn gjerne en DAG.\nTenk over confounders: Hva kan påvirke både X og Y? Har du kontrollert for det?\nIkke overfortolke: En statistisk signifikant sammenheng er ikke det samme som en kausal effekt.\nDiskuter begrensninger: Enhver analyse har begrensninger. Det er bedre å diskutere dem åpent enn å ignorere dem.\nLes andres forskning: Se hvordan andre har håndtert lignende problemstillinger. Hvilke metoder har de brukt? Hvilke kontrollvariable?\nBruk teori aktivt: La faglig teori veilede valgene dine, ikke bare statistiske kriterier.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "design_tolkning_teori.html#oppsummering",
    "href": "design_tolkning_teori.html#oppsummering",
    "title": "19  Forskningsdesign og tolkning",
    "section": "19.9 Oppsummering",
    "text": "19.9 Oppsummering\n\nObservasjonsdata gir sjelden grunnlag for å trekke kausale konklusjoner direkte\nKorrelasjon skyldes ikke nødvendigvis kausalitet - confounding er en hovedutfordring\nTeori er nødvendig for å velge variable, spesifisere modeller og tolke resultater\nDAGer er et nyttig verktøy for å tenke eksplisitt om kausale sammenhenger\nDet finnes kvasi-eksperimentelle metoder som kan styrke kausale slutninger\nGod dataanalyse krever faglig forståelse - R er verktøyet, men du må bruke det klokt",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Forskningsdesign og tolkning</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html",
    "href": "reproduserbarhet.html",
    "title": "20  Reproduserbarhet",
    "section": "",
    "text": "20.1 Replikasjonskrisen\nForskning handler om å finne ut noe om verden, og det er viktig at andre kan etterprøve det vi har gjort. Reproduserbarhet betyr ganske enkelt at noen andre skal kunne ta dine data og din kode, kjøre analysen på nytt, og få nøyaktig samme resultat. Det høres kanskje selvfølgelig ut, men det er overraskende vanskelig i praksis.\nEn del av grunnen til at vi bruker R og skriver kode er nettopp dette: alt vi gjør er dokumentert i et script. Det er ingen skjulte klikk i menyer som ingen husker etterpå. Men det kreves litt disiplin for å gjøre det ordentlig. Dette kapittelet handler om praktiske grep du kan ta for å gjøre analysene dine reproduserbare.\nI løpet av de siste årene har det blitt avdekket at overraskende mange forskningsresultater ikke lar seg reprodusere. Dette omtales ofte som “replikasjonskrisen” og har særlig rammet psykologi og andre samfunnsvitenskapelige fag. Studier som forsøkte å gjenta klassiske eksperimenter fant at bare omtrent halvparten ga tilsvarende resultater som det opprinnelige studiet. Årsakene er sammensatte og handler om mye mer enn kode og data, men en viktig del av løsningen er åpenhet om hvordan analyser er gjennomført. Det starter med at analysekoden er tilgjengelig og at andre faktisk kan kjøre den.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#bruk-script-ikke-pek-og-klikk",
    "href": "reproduserbarhet.html#bruk-script-ikke-pek-og-klikk",
    "title": "20  Reproduserbarhet",
    "section": "20.2 Bruk script – ikke pek-og-klikk",
    "text": "20.2 Bruk script – ikke pek-og-klikk\nDet mest grunnleggende grepet for reproduserbarhet er å gjøre alt i et script. Alt du gjør i analysen skal stå i koden. Du skal ikke gjøre noe manuelt som ikke er dokumentert. Det betyr for eksempel at du ikke skal sortere data i Excel, ikke redigere datafiler for hånd, og ikke kopiere tall fra R-output og lime inn i et Word-dokument manuelt.\nGrunnen er enkel: hvis du gjør noe manuelt, så er det ingen garanti for at du (eller noen andre) kan gjøre nøyaktig det samme om igjen. Og du vil garantert glemme hva du gjorde etter noen måneder.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#r-prosjekter-og-filstier",
    "href": "reproduserbarhet.html#r-prosjekter-og-filstier",
    "title": "20  Reproduserbarhet",
    "section": "20.3 R-prosjekter og filstier",
    "text": "20.3 R-prosjekter og filstier\nEn av de vanligste kildene til problemer med reproduserbarhet er filstier. Hvis koden din inneholder noe slikt:\n\ndata &lt;- read.csv(\"C:/Users/torbjorn/Mine dokumenter/masteroppgave/data/survey.csv\")\n\n…så vil denne koden bare fungere på akkurat din datamaskin. Ingen andre har den samme mappestien. Løsningen er å bruke R-prosjekter (.Rproj-filer) og relative filstier.\nNår du åpner et R-prosjekt i RStudio, settes arbeidskatalogen automatisk til mappen der .Rproj-filen ligger. Da kan du skrive:\n\ndata &lt;- read.csv(\"data/survey.csv\")\n\nDette fungerer for alle som har prosjektmappen, uansett hvor på datamaskinen den ligger. Opprett et nytt prosjekt via File &gt; New Project i RStudio.\n\n20.3.1 Aldri bruk setwd()\nDu har kanskje sett at noen bruker setwd() for å sette arbeidskatalogen. Ikke gjør det. Problemet er det samme som med absolutte filstier: setwd(\"C:/Users/torbjorn/prosjekt\") fungerer bare på din maskin. I tillegg gjør det at koden blir avhengig av rekkefølgen ting kjøres i, noe som gjør det vanskeligere å feilsøke. Bruk R-prosjekter i stedet, så slipper du setwd() helt.\n\n\n20.3.2 here-pakken for filstier\nSelv med R-prosjekter kan det noen ganger være litt klønete med filstier, særlig i Quarto-dokumenter der arbeidskatalogen er mappen der .qmd-filen ligger, ikke prosjektets rotmappe. Pakken here løser dette elegant:\n\nlibrary(here)\ndata &lt;- read.csv(here(\"data\", \"survey.csv\"))\n\nFunksjonen here() finner alltid prosjektets rotmappe (der .Rproj-filen ligger) og bygger filstien derfra. Det fungerer uansett hvor i prosjektmappen scriptet ditt befinner seg.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#kommenter-koden-din",
    "href": "reproduserbarhet.html#kommenter-koden-din",
    "title": "20  Reproduserbarhet",
    "section": "20.4 Kommenter koden din",
    "text": "20.4 Kommenter koden din\nGod kode er kode som andre kan lese og forstå. Og med “andre” mener vi også deg selv om seks måneder. Bruk kommentarer (#) for å forklare hvorfor du gjør noe, ikke bare hva du gjør. R ignorerer alt som står etter # på en linje.\n\n# Fjerner observasjoner med manglende inntektsdata\n# fordi disse er kodet som -1 i rådataene\ndata &lt;- data %&gt;%\n  filter(inntekt &gt;= 0)\n\nDu trenger ikke kommentere hver eneste linje, men de stegene der det ikke er opplagt hva som skjer eller hvorfor du gjør det, bør ha en kommentar.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#quarto-og-r-markdown-for-rapporter",
    "href": "reproduserbarhet.html#quarto-og-r-markdown-for-rapporter",
    "title": "20  Reproduserbarhet",
    "section": "20.5 Quarto og R Markdown for rapporter",
    "text": "20.5 Quarto og R Markdown for rapporter\nDenne boken er skrevet i Quarto, og det er et godt eksempel på hvordan man kan kombinere tekst og kode i ett dokument. Når du skriver en oppgave eller rapport i Quarto, ligger all kode og alle resultater i samme fil. Det betyr at du aldri trenger å kopiere tall fra R-output og lime inn i Word. Resultatene genereres direkte fra koden, og hvis data endres, oppdateres alt automatisk.\nFor semesteroppgaver og masteroppgaver er det veldig lurt å skrive i Quarto. Du slipper mye rot med å holde styr på hvilke tall som hører til hvilken analyse, og du unngår feil som oppstår ved manuell kopiering av resultater.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#versjonskontroll-med-git",
    "href": "reproduserbarhet.html#versjonskontroll-med-git",
    "title": "20  Reproduserbarhet",
    "section": "20.6 Versjonskontroll med Git",
    "text": "20.6 Versjonskontroll med Git\nHar du noen gang hatt filer som heter analyse_v2.R, analyse_v3_endelig.R, analyse_v3_endelig_VIRKELIG.R? Da trenger du versjonskontroll.\nGit er et system for å holde styr på endringer i filer over tid. Hver gang du gjør en meningsfull endring, lager du et “commit” – et slags øyeblikksbilde av filene dine. Du kan alltid gå tilbake til en tidligere versjon, og du kan se nøyaktig hva som ble endret og når.\nGit brukes mest via kommandolinjen, men RStudio har innebygd støtte for Git slik at du kan gjøre de vanligste operasjonene direkte i RStudio. For å komme i gang med Git trenger du å installere det og koble det til RStudio. Det er litt oppsett første gangen, men når det er på plass er det veldig nyttig. For de fleste studentprosjekter er det nok å lære seg de grunnleggende operasjonene: commit, push og pull.\nVi går ikke i detalj om Git her, men det er verdt å vite at det finnes og at det er standard verktøy for versjonskontroll i de fleste fagmiljøer.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#pakkeversjoner-med-renv",
    "href": "reproduserbarhet.html#pakkeversjoner-med-renv",
    "title": "20  Reproduserbarhet",
    "section": "20.7 Pakkeversjoner med renv",
    "text": "20.7 Pakkeversjoner med renv\nR-pakker oppdateres hele tiden, og noen ganger kan en ny versjon av en pakke gi andre resultater enn den gamle. For å sikre at analysen din gir samme resultat om et år, kan du bruke pakken renv til å “fryse” pakkene i prosjektet ditt.\n\n# Initialiser renv i prosjektet\nrenv::init()\n\n# Etter at du har installert alle pakkene du trenger:\nrenv::snapshot()\n\nKommandoen renv::snapshot() lager en fil (renv.lock) som inneholder en oversikt over alle pakkene du bruker og nøyaktig hvilke versjoner som er installert. Hvis noen andre skal kjøre koden din, kan de bruke renv::restore() for å installere nøyaktig de samme versjonene.\nFor en masteroppgave eller et forskningsprosjekt er dette et veldig godt grep. For vanlige semesteroppgaver er det kanskje ikke strengt nødvendig, men det er greit å vite at muligheten finnes.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#dele-data-og-kode",
    "href": "reproduserbarhet.html#dele-data-og-kode",
    "title": "20  Reproduserbarhet",
    "section": "20.8 Dele data og kode",
    "text": "20.8 Dele data og kode\nReproduserbarhet handler også om at andre faktisk har tilgang til data og kode. To vanlige plattformer for dette er:\n\nGitHub: Et nettsted for å dele kode og samarbeide om prosjekter. GitHub er tett integrert med Git og er standard plattform i mange fagmiljøer. Du kan opprette en konto gratis på github.com.\nOpen Science Framework (OSF): En plattform laget spesifikt for forskning, der du kan dele data, kode, og annen dokumentasjon. OSF er mye brukt i samfunnsvitenskap og er tilgjengelig på osf.io.\n\nFor en masteroppgave kan det være veldig nyttig å legge kode og data (hvis dataene kan deles) på en av disse plattformene. Det viser at du tar reproduserbarhet på alvor, og det gjør det lett for veileder å se på koden din.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#dokumenter-r-miljøet-ditt",
    "href": "reproduserbarhet.html#dokumenter-r-miljøet-ditt",
    "title": "20  Reproduserbarhet",
    "section": "20.9 Dokumenter R-miljøet ditt",
    "text": "20.9 Dokumenter R-miljøet ditt\nEn enkel ting du kan gjøre helt til slutt i ethvert prosjekt er å dokumentere hvilken versjon av R og hvilke pakker du har brukt. Funksjonen sessionInfo() gir deg alt du trenger:\n\nsessionInfo()\n\nDette skriver ut R-versjon, operativsystem, og alle pakkene som er lastet inn med versjonsnumre. Hvis noen har problemer med å reprodusere resultatene dine, er dette det første stedet å se etter forskjeller. Legg gjerne til sessionInfo() helt sist i Quarto-dokumentet ditt.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "reproduserbarhet.html#sjekkliste-for-reproduserbare-prosjekter",
    "href": "reproduserbarhet.html#sjekkliste-for-reproduserbare-prosjekter",
    "title": "20  Reproduserbarhet",
    "section": "20.10 Sjekkliste for reproduserbare prosjekter",
    "text": "20.10 Sjekkliste for reproduserbare prosjekter\nHer er en praktisk sjekkliste du kan bruke for å sjekke at prosjektet ditt er rimelig reproduserbart:\n\nAll analyse er gjort i script (ingen manuelle steg)\nProsjektet bruker en .Rproj-fil\nAlle filstier er relative (ingen setwd(), ingen absolutte stier)\nKoden er kommentert der det trengs\nRapporten er skrevet i Quarto eller R Markdown\nsessionInfo() er inkludert i dokumentet\nData og kode er organisert i en logisk mappestruktur\nProsjektet kan kjøres fra start til slutt uten feil på en annen maskin\n\nDu trenger ikke krysse av alt for en vanlig semesteroppgave, men jo flere punkter du får med, desto bedre. For en masteroppgave bør du sikte på å få med alt.",
    "crumbs": [
      "Del V: Tolkning og vitenskapelig praksis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reproduserbarhet</span>"
    ]
  },
  {
    "objectID": "innlesning_data.html",
    "href": "innlesning_data.html",
    "title": "21  Innlesning av data",
    "section": "",
    "text": "21.1 Generelt om ulike dataformat\nVi skal bruke følgende pakker i dette kapittelet\nData kan være lagret i mange ulike formater, men det er også problemstillinger knyttet til hvordan dataene er lagret i et gitt format. Dette handler delvis om hvordan noen har valgt å lagre og distribuere data, ikke bare om dataformatet i seg selv.\nDet kan være vanskelig å skille mellom hvorvidt utfordringene du møter skyldes dataformatet, softwaren man bruker eller valg andre har tatt. Det kan være flere av disse, men som hovedregel er problemet at data ofte ikke er distribuert i et universelt format. Permanent lagring og distribusjon av data er krevende, men ikke temaet her.\nUansett: du vil ofte få data i et format som ikke er tilrettelagt verken i eller for R. Å gjøre om data fra et format til et annet kan være en avgjørende oppgave for å få gjort noe som helst.\nDette kan være krøkete og du har virkelig muligheten til å kløne det til skikkelig. For at du skal slippe det gir dette kapittelet en oppskrift for å håndtere slike data slik at du kan jobbe videre med dem i R på en hensiktsmessig måte.\nR kan imidlertid håndtere det aller meste av dataformater på en eller annen måte, men vi ser bare på de aller mest vanlige her.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Innlesning av data</span>"
    ]
  },
  {
    "objectID": "innlesning_data.html#generelt-om-ulike-dataformat",
    "href": "innlesning_data.html#generelt-om-ulike-dataformat",
    "title": "21  Innlesning av data",
    "section": "",
    "text": "21.1.1 rds\nRds-formatet er et format særlig egnet for R. Her er et eksempel med et utdrag fra datasettet wagepan (paneldata om lønn fra pakken wooldridge)\n\nwagepan_rds &lt;- readRDS(\"data/wagepan_eksempel.rds\")\nglimpse(wagepan_rds)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;int&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;int&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;int&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\n\n\n21.1.2 Laste workspace med load()\nFiler av typen .Rdat eller .Rdata er egentlig ikke et dataformat, men brukes tidvis for å lagre datafiler. Man kan lagre en eller flere datafiler i samme .Rdat fil på disk.\nDu kan også lagre et “speilbilde” av hele ditt workspace på denne måten slik at du kan lukke R og så åpne R senere akkurat på det stedet du var i arbeidet. Det kan være kjekt, men forutsetter at du husker hva du drev med forrige gang. Den klare anbefalingen er derfor å ikke bruke dette rutinemessig.\nHer bruker man load som laster dette speilbildet og objektet med dataene i beholder det navnet de hadde da de ble laget. Se i fanen “Environment” i Rstudio om det har dukket opp noe nytt der, for å finne navnet hvis du ikke vet det fra før. I dette eksempelet er dataene lagret i et objekt som “wagepan_eksempel_rdata” som altså er lagret i en fil som heter “wagepan_eksempel.Rdata”. Ved lasting av filen dukker objektet opp under “Enviroment”-fanen, men du får ikke noen melding av noe slag. Men er altså tilgjengelig i minnet i R. Her er koden:\n\nload(\"data/wagepan_eksempel.Rdata\")\nglimpse(wagepan_eksempel_rdata)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;int&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;int&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;int&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\n\n\n21.1.3 csv-filer\nSåkalte csv-format er ren tekstformat der verdiene i kollonnene har skilletegn. Skilletegnet er nesten alltid komma eller semikolon, men kan i prinsippet være hva som helst. Hvis du får feilmeldinger og det ser skikkelig rart ut, så åpen filen i Notepad (eller annet ren-tekst program) og sjekk. I koden nedenfor er det spesifisert komma som skilletegn, men hvis det er semikolon endrer du det til sep =\",\". I utgangspunket forventer read.csv at det er kommaseparert, så koden vil funkere her uten den delen.\n\nwagepan_eksempel_csv &lt;- read.csv(\"data/wagepan_eksempel.csv\", sep =\",\")\nglimpse(wagepan_eksempel_csv)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;int&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;int&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;int&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\n\n\n21.1.4 Excel\nForbløffende mye data foreligger i Excel-format. Det finnes egne funksjoner for å jobbe direkte med excel-filer. Blant annet pakken readxl gir funksjoner til å lese inn denne typen filer. Det finnes også andre pakker for å håndtere Excel-filer, men hvis formålet bare er å lese inn data, så gjør denne pakken jobben. Husk å laste pakken først. Her er et eksempel:\n\nlibrary(readxl)\nwagepan_xlsx &lt;- read_excel(\"data/wagepan_eksempel.xlsx\")\nglimpse(wagepan_xlsx)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\nMen Excel-filer kan ha en litt mer komplisert struktur enn dette eksempelet. Data kan ligge i ulike faner i Excel-filen, men det kan da håndteres med å legge til argumentet sheet = .... Hvis excel-arket inneholder mye tekst eller andre ting som gjør at de faktiske dataene kommer litt lengre ned, så kan det spesifiseres hvilket celleområde som det skal leses inn fra ved range = ... eller bare hoppe over noen rader med skip = ....\nPå dette kurset skal vi ikke bruke Excel-filer, men det er stor sannsynlighet for at du vil få bruk for dette senere en gang.\n\n\n21.1.5 Proprietære format: Stata, SPSS og SAS\n\n21.1.5.1 Stata\n\nwagepan_dta &lt;- read_stata(\"data/wagepan_eksempel.dta\")\nglimpse(wagepan_dta)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\nLegg merke til at den andre kolonnen her viser hva slags variabeltype det er. &lt;dbl&gt; betyr at det er numerisk variabel^(Det finnes flere typer numeriske variable som vi for praktiske analyser sjelden behøver å forholde oss til. &lt;dbl&gt; står for Double som er et lagringsformat som kan ta svært mange desimaler. Det kan også stå &lt;num&gt; som håndterer færre desimaler. Det er også vanlig med &lt;int&gt; som står for Integer, altså heltall uten desimaler.) På noen variable står det også &lt;dbl+lbl&gt; der lbl står for labelled som betyr at det finnes såkalte labler tilhørende variabelen. Labler er vanlig å bruke i programmene Stata og SPSS, men er ikke noe som vanligvis brukes i R. Men R leser det inn og kan håndtere dette helt fint. Men som hovedregel er det bedre å rydde opp slik at dataene blir slik vi vanligvis bruker det i R.\nNeste kapittel går nærmere inn på å håndtere data fra Stata og SPSS, inkludert hvordan man effektivt gjør om labler. Hvordan dette gjøres i praksis er dekket i et appendiks. De av dere som senere skal jobbe med data levert ut fra Sikt kan ha behov for dette, og da kan dere ta en nærmere titt på appendikset.\n\n\n21.1.5.2 SPSS og SAS\nAndre vanlige dataformater er formater fra statistikkpakkene SPSS og SAS, med filhalene henholdsvis .sav og .sas7bdat. De leses inn på tilsvarende funksjoner tilpasset disse dataformatene. Her er eksempel for innlesning av SPSS-fil:\n\nwagepan_sav &lt;- read_spss(\"data/wagepan_eksempel.sav\")\nglimpse(wagepan_sav)\n\nHer er eksempel for innlesning av SAS-fil:\n\nwagepan_sas &lt;- read_sas(\"data/wagepan_eksempel.sas7bdat\")\nglimpse(wagepan_sas)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\n\n\n\n21.1.6 Dataformater for store data\nDet finnes en hel rekke andre formater for spesielle formål, derav formater for store data. Med store data mener vi her enten at de er så store at det upraktisk lang tid å lese det inn - eller så store at det ikke er plass i minnet på datamaskinen. Formatene feather og parquet er varianter av det samme og håndteres med pakken Arrow. Det finnes også andre pakker for store data, men Arrow er nå den anbefalte. En annen grunn til det er at disse datasettene tillater sømløs bytte mellom programmeringsspråkene R og Python. Men det går laaaagt utenfor formålet med dette forkurset.\nFor mer spesielle behov går det også an å koble mot databaser som MySQL, Spark, Oracle eller noe helt annet, og en oversikt finnes her.\nEneste du trenger være klar over akkurat nå er at R kan håndtere svært mange forskjellige dataformater og koble mot andre løsninger. Kanskje vil du trenge det en gang - kanskje ikke.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Innlesning av data</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html",
    "href": "innlesning_stata_spss.html",
    "title": "22  Import fra Stata og SPSS",
    "section": "",
    "text": "22.1 Hva er labelled data?\nI forrige kapittel så vi kort hvordan man leser inn data fra Stata og SPSS. Det fungerer greit nok for de fleste formål, men det er noen utfordringer knyttet til labelled data som krever litt mer arbeid. Dette kapittelet går dypere inn i dette.\nHvis du jobber med data som opprinnelig er laget i Stata eller SPSS, vil du nesten garantert støte på det som kalles labler. Det er en spesiell måte å lagre informasjon om variablene på. R kan håndtere dette, men det er viktig å forstå hva som skjer og hvordan du bør rydde opp.\nI Stata og SPSS er det vanlig å bruke to typer labler:\nNår du leser inn en Stata- eller SPSS-fil med haven, beholdes denne informasjonen. Men R behandler den annerledes enn det Stata og SPSS gjør. I R er disse verdiene fortsatt tall, men med labler vedlagt som metadata.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#hva-er-labelled-data",
    "href": "innlesning_stata_spss.html#hva-er-labelled-data",
    "title": "22  Import fra Stata og SPSS",
    "section": "",
    "text": "Value labels (verdilabel): Knytter en tekst til en tallverdi. For eksempel kan verdien 0 ha labelen “Not married” og 1 ha labelen “Married”.\nVariable labels (variabellabel): En kort beskrivelse av hva variabelen inneholder. For eksempel kan variabelen married ha variabellabelen “Sivilstatus”.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#lese-inn-data",
    "href": "innlesning_stata_spss.html#lese-inn-data",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.2 Lese inn data",
    "text": "22.2 Lese inn data\nLa oss starte med å lese inn en Stata-fil:\n\nwagepan &lt;- read_stata(\"data/wagepan_eksempel.dta\")\nglimpse(wagepan)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\nLegg merke til variabeltypene. Der det står &lt;dbl+lbl&gt; betyr det at variabelen er numerisk (dbl = double), men at det finnes labler knyttet til verdiene. Dette er altså labelled variable.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#inspisere-labler",
    "href": "innlesning_stata_spss.html#inspisere-labler",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.3 Inspisere labler",
    "text": "22.3 Inspisere labler\nVi kan se på lablene til en enkelt variabel med val_labels():\n\nval_labels(wagepan$married)\n\nNULL\n\n\nVi kan også se variabellabelen (beskrivelsen av variabelen) med var_label():\n\nvar_label(wagepan$married)\n\n[1] \"Married\"\n\n\nFor å få oversikt over alle variable med labler kan vi bruke look_for() fra labelled-pakken:\n\nlook_for(wagepan)\n\n pos variable label               col_type missing values\n 1   nr       Person identifier   dbl      0             \n 2   year     Year                dbl      0             \n 3   hours    Annual hours worked dbl      0             \n 4   lwage    Log hourly wage     dbl      0             \n 5   educ     Years of education  dbl      0             \n 6   black    Black               dbl      0             \n 7   hisp     Hispanic            dbl      0             \n 8   married  Married             dbl      0             \n 9   union    Union member        dbl      0             \n 10  exper    Years of experience dbl      0             \n\n\nDenne funksjonen gir en ryddig oversikt over variabelnavn, variabellabler, verdier og verdilabel. Det er veldig nyttig for å utforske datasett fra Stata og SPSS.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#problemet-med-labelled-data-i-r",
    "href": "innlesning_stata_spss.html#problemet-med-labelled-data-i-r",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.4 Problemet med labelled data i R",
    "text": "22.4 Problemet med labelled data i R\nLabelled data fungerer fint for å inspisere dataene, men de kan skape problemer når du skal gjøre analyser. Mange R-funksjoner forventer enten numeriske variable eller factor-variable, ikke labelled-variable. Du kan for eksempel oppleve at:\n\nggplot viser tallverdier i stedet for meningsfulle kategorinavn\nTabeller viser koder i stedet for tekst\nNoen funksjoner gir uventede resultater eller feilmeldinger\n\nDerfor er det lurt å konvertere labelled variable til factor-variable tidlig i arbeidsprosessen.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#konvertere-til-factor",
    "href": "innlesning_stata_spss.html#konvertere-til-factor",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.5 Konvertere til factor",
    "text": "22.5 Konvertere til factor\nDen enkleste måten å konvertere en labelled variabel til factor er med as_factor() fra haven:\n\nwagepan &lt;- wagepan %&gt;%\n  mutate(married_factor = as_factor(married))\n\ntable(wagepan$married_factor)\n\n\n   0    1 \n2446 1914 \n\n\nMen hvis du har mange labelled variable, er det mye mer effektivt å konvertere alle på en gang med across():\n\nwagepan_clean &lt;- wagepan %&gt;%\n  mutate(across(where(is.labelled), ~as_factor(.)))\n\nglimpse(wagepan_clean)\n\nRows: 4,360\nColumns: 11\n$ nr             &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17,…\n$ year           &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1…\n$ hours          &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2…\n$ lwage          &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, …\n$ educ           &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13,…\n$ black          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ hisp           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ married        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1…\n$ union          &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ exper          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5,…\n$ married_factor &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1…\n\n\nDenne ene linjen konverterer alle labelled variable i datasettet til factor-variable. Det er den anbefalte metoden.\nNoen ganger vil du også fjerne ubrukte factor-nivåer som kan oppstå etter filtrering:\n\nwagepan_clean &lt;- wagepan %&gt;%\n  mutate(across(where(is.labelled), ~as_factor(.)),\n         across(where(is.factor), ~fct_drop(.)))",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#brukerdefinertemissing-verdier",
    "href": "innlesning_stata_spss.html#brukerdefinertemissing-verdier",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.6 Brukerdefinertemissing-verdier",
    "text": "22.6 Brukerdefinertemissing-verdier\nI Stata og SPSS er det vanlig å bruke spesielle verdier for å markere ulike typer missing. For eksempel kan -9 bety “ikke besvart” og -8 bety “ikke relevant”. Disse verdiene er ofte dokumentert med labler.\nPakken haven håndterer dette med tagged NA-verdier. Du kan sjekke om det finnes slike verdier:\n\n# Se brukerefinerte missing-verdier\nna_values(wagepan$hours)\n\nI praksis er det ofte enklest å bare konvertere til factor (som gjort ovenfor) og deretter filtrere ut de kategoriene du ikke trenger. Alternativt kan du bruke zap_labels() for å fjerne alle labler og beholde bare tallverdiene:\n\nwagepan_tall &lt;- wagepan %&gt;%\n  mutate(across(where(is.labelled), ~zap_labels(.)))\n\nMen vær forsiktig med dette - da mister du all informasjon om hva verdiene betyr!",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#lese-inn-spss-filer",
    "href": "innlesning_stata_spss.html#lese-inn-spss-filer",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.7 Lese inn SPSS-filer",
    "text": "22.7 Lese inn SPSS-filer\nInnlesning av SPSS-filer fungerer på tilsvarende måte:\n\nwagepan_spss &lt;- read_spss(\"data/wagepan_eksempel.sav\")\nglimpse(wagepan_spss)\n\nKonvertering til factor gjøres på nøyaktig samme måte:\n\nwagepan_spss_clean &lt;- wagepan_spss %&gt;%\n  mutate(across(where(is.labelled), ~as_factor(.)),\n         across(where(is.factor), ~fct_drop(.)))",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#tegnsett-og-encoding",
    "href": "innlesning_stata_spss.html#tegnsett-og-encoding",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.8 Tegnsett og encoding",
    "text": "22.8 Tegnsett og encoding\nEt vanlig problem med nordiske data er tegnsettproblemer. Norske bokstaver (æ, ø, å) kan vises feil hvis filen er lagret med et annet tegnsett enn det R forventer. Hvis du ser rare tegn i stedet for æøå, kan du prøve å spesifisere tegnsett ved innlesning:\n\n# Prøv med ulike tegnsett\nwagepan &lt;- read_stata(\"data/wagepan_eksempel.dta\", encoding = \"latin1\")\n\nDe vanligste tegnsettene er \"UTF-8\" og \"latin1\" (også kalt ISO-8859-1). Prøv begge hvis du har problemer.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#anbefalt-arbeidsflyt",
    "href": "innlesning_stata_spss.html#anbefalt-arbeidsflyt",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.9 Anbefalt arbeidsflyt",
    "text": "22.9 Anbefalt arbeidsflyt\nHer er en anbefalt arbeidsflyt for å jobbe med data fra Stata eller SPSS:\n\nLes inn datafilen med read_stata() eller read_spss()\nInspiser dataene med glimpse() og look_for()\nKonverter labelled variable til factor med across(where(is.labelled), ~as_factor(.))\nVelg de variablene du trenger med select()\nLagre den ryddede versjonen som .rds for videre bruk\n\n\n# Komplett arbeidsflyt\nwagepan_ferdig &lt;- read_stata(\"data/wagepan_eksempel.dta\") %&gt;%\n  mutate(across(where(is.labelled), ~as_factor(.)),\n         across(where(is.factor), ~fct_drop(.))) %&gt;%\n  select(nr, year, hours, lwage, educ, married, union)\n\n# Lagre til .rds for videre bruk\nsaveRDS(wagepan_ferdig, \"data/wagepan_ferdig.rds\")\n\nFordelen med å lagre som .rds er at du slipper å gjøre denne konverteringen hver gang. Neste gang du trenger dataene kan du bare laste inn .rds-filen direkte.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_stata_spss.html#oppsummering",
    "href": "innlesning_stata_spss.html#oppsummering",
    "title": "22  Import fra Stata og SPSS",
    "section": "22.10 Oppsummering",
    "text": "22.10 Oppsummering\n\nData fra Stata og SPSS har labler som R behandler som labelled data\nKonverter til factor med mutate(across(where(is.labelled), ~as_factor(.)))\nBruk look_for() for å utforske variabelnavn og labler\nLagre ryddede data som .rds for effektiv videre bruk\nPass på tegnsettproblemer med nordiske bokstaver",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Import fra Stata og SPSS</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html",
    "href": "innlesning_excel.html",
    "title": "23  Import av Excel-filer",
    "section": "",
    "text": "23.1 Lese inn Excel-filer med readxl\nForbløffende mye data finnes i Excel-format. Selv om Excel ikke er designet for statistisk analyse, er det slik at svært mange organisasjoner, kommuner og offentlige etater lagrer og distribuerer data i Excel. Du vil nesten garantert støte på Excel-filer i løpet av studiene eller i arbeidslivet, så det er greit å vite hvordan du håndterer dem i R.\nExcel-filer kan være litt mer kronglete enn csv-filer fordi de kan inneholde flere ark, sammenslåtte celler, formatering og formler. Men R har gode verktøy for å håndtere dette.\nPakken readxl er den anbefalte pakken for å lese inn Excel-filer i R. Den er en del av tidyverse-familien og håndterer både .xls (gammelt format) og .xlsx (nytt format). Den enkleste bruken er helt rett frem:\nwagepan_xlsx &lt;- read_excel(\"data/wagepan_eksempel.xlsx\")\nglimpse(wagepan_xlsx)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\nFunksjonen read_excel() gjetter selv om det er .xls eller .xlsx basert på filendelsen. Du kan også bruke read_xlsx() eller read_xls() direkte hvis du vil være eksplisitt.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#velge-ark-med-sheet",
    "href": "innlesning_excel.html#velge-ark-med-sheet",
    "title": "23  Import av Excel-filer",
    "section": "23.2 Velge ark med sheet",
    "text": "23.2 Velge ark med sheet\nEn Excel-fil kan inneholde flere ark (sheets). Som standard leser read_excel() inn det første arket. For å se hvilke ark som finnes i en fil kan du bruke excel_sheets():\n\nexcel_sheets(\"data/wagepan_eksempel.xlsx\")\n\n[1] \"Sheet 1\"\n\n\nDu kan velge ark enten med navn eller nummer:\n\n# Med navn\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", sheet = \"Sheet1\")\n\n# Med nummer (første ark)\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", sheet = 1)\n\nHvis du trenger data fra flere ark kan du lese dem inn hver for seg og eventuelt koble dem sammen etterpå.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#håndtere-overskriftsrader-og-hoppe-over-rader",
    "href": "innlesning_excel.html#håndtere-overskriftsrader-og-hoppe-over-rader",
    "title": "23  Import av Excel-filer",
    "section": "23.3 Håndtere overskriftsrader og hoppe over rader",
    "text": "23.3 Håndtere overskriftsrader og hoppe over rader\nI praksis ser Excel-filer sjelden så ryddige ut som man skulle ønske. Det er vanlig at de første radene inneholder titler eller merknader som ikke er en del av dataene. Med skip hopper du over et gitt antall rader fra toppen:\n\n# Hopp over de 3 første radene\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", skip = 3)\n\nNoen ganger har ikke filen variabelnavn i det hele tatt. Da kan du bruke col_names:\n\n# Ingen overskriftsrad - R lager egne navn (X1, X2, ...)\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", col_names = FALSE)\n\n# Sett egne variabelnavn\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\",\n                 col_names = c(\"id\", \"alder\", \"kjonn\", \"inntekt\"))",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#spesifisere-celleområde-med-range",
    "href": "innlesning_excel.html#spesifisere-celleområde-med-range",
    "title": "23  Import av Excel-filer",
    "section": "23.4 Spesifisere celleområde med range",
    "text": "23.4 Spesifisere celleområde med range\nHvis dataene bare ligger i en del av regnearket, kan du spesifisere nøyaktig hvilke celler som skal leses inn.\n\n# Les bare cellene B2 til F100\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", range = \"B2:F100\")\n\n# Du kan også spesifisere ark og celleområde samtidig\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", range = \"Sheet1!B2:F100\")\n\nDu kan også bruke cell_rows() og cell_cols() for å spesifisere bare rader eller kolonner:\n\n# Bare radene 5 til 50\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", range = cell_rows(5:50))\n\n# Bare kolonnene A til D\ndf &lt;- read_excel(\"data/wagepan_eksempel.xlsx\", range = cell_cols(\"A:D\"))",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#vanlige-problemer-med-excel-filer",
    "href": "innlesning_excel.html#vanlige-problemer-med-excel-filer",
    "title": "23  Import av Excel-filer",
    "section": "23.5 Vanlige problemer med Excel-filer",
    "text": "23.5 Vanlige problemer med Excel-filer\n\n23.5.1 Datoer\nExcel lagrer datoer som tall internt, og det kan noen ganger bli krøll ved innlesning. Hvis datoene ser rare ut (f.eks. som femsifrede tall), kan du konvertere dem:\n\n# Excel bruker 1899-12-30 som nullpunkt\nexcel_tall &lt;- 44927\nas.Date(excel_tall, origin = \"1899-12-30\")\n\n[1] \"2023-01-01\"\n\n\nSom regel håndterer readxl datoer automatisk, men det er greit å vite om dette.\n\n\n23.5.2 Sammenslåtte celler\nSammenslåtte celler er en gjenganger. Ved innlesning får bare den første cellen verdien, resten blir NA. Løsningen er å fylle nedover med tidyr::fill():\n\n# Eksempel: Fyll NA-verdier nedover (typisk etter sammenslåtte celler)\ndemo &lt;- tibble(\n  kategori = c(\"Menn\", NA, NA, \"Kvinner\", NA, NA),\n  alder = c(\"18-29\", \"30-49\", \"50+\", \"18-29\", \"30-49\", \"50+\"),\n  antall = c(120, 340, 280, 135, 360, 295)\n)\n\ndemo %&gt;%\n  fill(kategori, .direction = \"down\")\n\n# A tibble: 6 × 3\n  kategori alder antall\n  &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;\n1 Menn     18-29    120\n2 Menn     30-49    340\n3 Menn     50+      280\n4 Kvinner  18-29    135\n5 Kvinner  30-49    360\n6 Kvinner  50+      295\n\n\n\n\n23.5.3 Flere tabeller i samme ark\nNoen bruker ett Excel-ark til å plassere flere tabeller ved siden av hverandre eller under hverandre. Da er range-argumentet din beste venn. Les inn hver tabell for seg med hvert sitt celleområde.\n\n\n23.5.4 Tekst i tallkolonner\nHvis noen har skrevet en kommentar eller merknad i en celle som ellers inneholder tall, vil hele kolonnen kunne bli lest inn som tekst. Sjekk variabeltypene med glimpse() og konverter om nødvendig med as.numeric().",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#skrive-excel-filer",
    "href": "innlesning_excel.html#skrive-excel-filer",
    "title": "23  Import av Excel-filer",
    "section": "23.6 Skrive Excel-filer",
    "text": "23.6 Skrive Excel-filer\nNoen ganger trenger du å lagre data som Excel-fil, f.eks. fordi noen du samarbeider med foretrekker det. Pakken openxlsx er et godt alternativ:\n\nlibrary(openxlsx)\n\n# Enkel eksport\nwrite.xlsx(wagepan_xlsx, file = \"data/eksempel_ut.xlsx\")\n\n# Med flere ark i samme fil\nwrite.xlsx(list(\"Datasett1\" = wagepan_xlsx,\n                \"Oppsummering\" = summary(wagepan_xlsx) %&gt;% as.data.frame()),\n           file = \"data/eksempel_flere_ark.xlsx\")\n\nEt enklere alternativ er pakken writexl som ikke har noen avhengigheter til Java eller andre systemer:\n\nlibrary(writexl)\nwrite_xlsx(wagepan_xlsx, path = \"data/eksempel_ut.xlsx\")\n\nBegge fungerer fint for enkel eksport. openxlsx gir deg mer kontroll over formatering, mens writexl er mer lettvektig og enklere å installere.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_excel.html#tips-for-rotete-excel-filer",
    "href": "innlesning_excel.html#tips-for-rotete-excel-filer",
    "title": "23  Import av Excel-filer",
    "section": "23.7 Tips for rotete Excel-filer",
    "text": "23.7 Tips for rotete Excel-filer\nI virkeligheten er Excel-filer ofte rotete. Her er noen praktiske tips:\n\nÅpne filen i Excel først og se på strukturen. Legg merke til hvilke rader og kolonner dataene faktisk ligger i.\nBruk excel_sheets() for å se hvilke ark som finnes.\nStart med range hvis dataene ikke begynner i celle A1.\nSjekk variabeltypene med glimpse() rett etter innlesning. Hvis en tallkolonne er blitt tekst, er det gjerne en kommentar eller et spesialtegn som lurer seg inn.\nBruk fill() etter innlesning dersom det har vært sammenslåtte celler.\nUnngå å redigere Excel-filen manuelt for å “rydde” den. Skriv heller R-kode som håndterer rotet. Da er arbeidet reproduserbart og du slipper å gjøre det om igjen neste gang du får oppdaterte data.\n\nDet siste punktet er kanskje det viktigste. Det er fristende å fikse ting manuelt i Excel, men da mister du sporbarhet. Gjør du alt i R-kode, kan du og andre kjøre koden på nytt og få nøyaktig samme resultat.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Import av Excel-filer</span>"
    ]
  },
  {
    "objectID": "innlesning_ssb.html",
    "href": "innlesning_ssb.html",
    "title": "24  Data fra SSBs statistikkbank",
    "section": "",
    "text": "All statistikk fra SSB publiseres (også) i en statistikkbank der man kan hente ut f.eks. tidsserier over flere årganger. Du kan ta en titt på Statistikkbanken på SSB sine sider.\nSSB har laget et r-pakke for å hente data direkte fra SSBs statistikkbank. Denne kan du installere direkte fra CRAN via R slik:\n\ninstall.packages(\"PxWebApiData\")\n\nVi skal altså bruke følgende pakker i dette kapittelet:\n\nlibrary(PxWebApiData)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.2.0     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.2     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n# Befolkning\nmeta&lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/07459\",  returnMetaFrames = TRUE)\nnames(meta)\n\n[1] \"Region\"       \"Kjonn\"        \"Alder\"        \"ContentsCode\" \"Tid\"         \n\nmeta$Kjonn\n\n  values valueTexts\n1      2    Females\n2      1      Males\n\n\n\n## Anmeldte lovbrudd\nmeta&lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/08487\",  returnMetaFrames = TRUE)\n\nkommuner &lt;- meta$Gjerningssted %&gt;% \n  filter(nchar(values) == 4 & !(values %in% c(\"Ialt\", \"0000\"))) %&gt;% \n  pull(values)\n\ngrupper &lt;- meta$LovbruddKrim %&gt;% \n  filter(nchar(values) &gt; 5 & valueTexts != \"All groups of offences\" ) %&gt;% \n  pull(values)\n\n## Pull data from API\nanm_list &lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/08487\", \n                    ContentsCode = \"AnmLovbrPer1000\", \n                    Gjerningssted = kommuner, \n                    LovbruddKrim = grupper, \n                    Tid = TRUE,\n                    makeNAstatus = FALSE)\n\n\n# rename\nnames(anm_list[[1]]) &lt;- c(\"kommune\", \"lovbruddsgruppe\", \"content\", \"year\", \"lovbrudd_per1000\", \"NAstatus\")\n\n\n# Combine and tidy up\nanm &lt;- cbind(anm_list[[2]][1], anm_list[[1]]) %&gt;%\n  select(-content, -NAstatus) %&gt;%\n  mutate(lovbruddsgruppe = str_sub(lovbruddsgruppe, 3, nchar(lovbruddsgruppe))) %&gt;% \n  mutate(year = as.numeric(str_sub(year,1,4))) %&gt;% \n  filter(!is.na(lovbrudd_per1000)) %&gt;% \n  mutate(lovbruddsgruppe = case_when(str_sub(lovbruddsgruppe, 1,4) == \"Prop\" ~ \"vinningskriminalitet\", \n                                     str_sub(lovbruddsgruppe, 1,4) == \"Viol\" ~ \"voldskriminalitet\",\n                                     str_sub(lovbruddsgruppe, 1,4) == \"Drug\" ~ \"nark_alko_kriminalitet\",\n                                     str_sub(lovbruddsgruppe, 1,4) == \"Publ\" ~ \"ordenslovbrudd\",\n                                     str_sub(lovbruddsgruppe, 1,4) == \"Traf\" ~ \"trafikklovbrudd\",\n                                     str_sub(lovbruddsgruppe, 1,4) == \"Othe\" ~ \"andre_lovbrudd\")) %&gt;% \n  # pivot_wider(values_from = lovbrudd_per1000, names_from = lovbruddsgruppe) %&gt;% \n  rename(kommune_nr = Gjerningssted) %&gt;% \n  select(-kommune)\n\nglimpse(anm)\n\nRows: 36,866\nColumns: 4\n$ kommune_nr       &lt;chr&gt; \"3101\", \"3101\", \"3101\", \"3101\", \"3101\", \"3101\", \"3103…\n$ lovbruddsgruppe  &lt;chr&gt; \"vinningskriminalitet\", \"voldskriminalitet\", \"nark_al…\n$ year             &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023,…\n$ lovbrudd_per1000 &lt;dbl&gt; 12.6, 11.6, 16.8, 13.2, 13.8, 18.0, 21.8, 7.4, 6.3, 5…\n\n#Check\nggplot( filter(anm, kommune_nr == \"0301\"), \n        aes(x = year, y = lovbrudd_per1000, group = lovbruddsgruppe, linetype = lovbruddsgruppe))+\n  geom_line()+\n  theme(legend.position = \"bottom\", legend.title = element_blank())+\n  guides(linetype = guide_legend(ncol = 2))+\n  xlab(\"\")\n\n\n\n\n\n\n\n\n\n# meta$Alder\n# meta$Kjonn\n# meta$ContentsCode\n# meta$Region %&gt;% head()\n\nkommuner_bef &lt;- meta$Region %&gt;% \n  filter(nchar(values) == 4 ) %&gt;% \n  pull(values)\nhead(kommuner_bef)\n\n\nbefolk &lt;- list(length(meta$Tid$values))\nfor(i in 1:length(meta$Tid$values)){ \n  #print(i)\n  bef_list &lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/07459\", \n                      ContentsCode = TRUE, \n                      Region = kommuner_bef, \n                      Kjonn = TRUE,  \n                      Alder = TRUE,\n                      Tid = i)\n  befolk[[i]] &lt;- cbind(bef_list[[2]][1], bef_list[[1]])\n  \n  #rm(bef_list)\n  }\n\n\nbefolkning &lt;- bind_rows(befolk)\n\n# rename\nnames(befolkning) &lt;- c(\"kommune_nr\", \"kommune\", \"kjonn\", \"alder\", \"contents\", \"year\", \"bef_antall\")\n\n# Combine and tidy up\nbefolkning2 &lt;- befolkning %&gt;% \n  select(-contents) %&gt;% \n  mutate(year = as.numeric(year)) %&gt;% \n  mutate(age = str_extract(alder, \"(\\\\d)+\")) %&gt;% \n  mutate(age_gr = case_when(age &lt; 18 ~ \"under 18\", \n                            age &lt;= 25 ~ \"18-25\",\n                            age &lt;= 35 ~ \"26-35\", \n                            age &lt;= 67 ~ \"36-67\", \n                            age &gt; 67 ~ \"over 67\")) \n\nbef_gruppe &lt;- befolkning2 %&gt;% \n  group_by(kommune_nr, kommune, year, age_gr, kjonn) %&gt;% \n  summarise(n = sum(bef_antall)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(values_from = n, names_from = age_gr) %&gt;% \n  rename(bef_18_25 = `18-25`, bef_26_35 = `26-35`, bef_36_67 = `36-67`, \n         bef_67plus = `over 67`, bef_18min = `under 18`) %&gt;% \n  filter(year &gt;= 2010) \n  \nbef_menn &lt;- filter(bef_gruppe, kjonn == \"Males\") %&gt;% \n  rename_all(str_replace_all, \"bef_\", \"menn_\") %&gt;% \n  select(-kjonn, -kommune)\n\nbef_kvinner &lt;- filter(bef_gruppe, kjonn == \"Females\") %&gt;% \n  rename_all(str_replace_all, \"bef_\", \"kvinner_\") %&gt;% \n  select(-kjonn, -kommune)\n\nhead(bef_kvinner)\n\n\nbef_tot &lt;- befolkning2 %&gt;% \n  group_by(kommune_nr, kommune, year, age_gr) %&gt;% \n  summarise(n = sum(bef_antall)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(values_from = n, names_from = age_gr) %&gt;% \n  rename(bef_18_25 = `18-25`, bef_26_35 = `26-35`, bef_36_67 = `36-67`, \n         bef_67plus = `over 67`, bef_18min = `under 18`) %&gt;% \n  filter(year &gt;= 2010) %&gt;% \n  rowwise() %&gt;% \n  mutate(bef_totalt = sum( across(bef_18_25:bef_18min))) %&gt;% \n  select(1:3, 8, 4, 5, 9)\n\nglimpse(bef_tot)\n\n\nggplot(bef, aes(x = year, y = value, group = region, col = region)) +\n  geom_line()\n\n\nApiData(\"http://data.ssb.no/api/v0/no/table/07459\",  returnMetaFrames = TRUE)\n\n\n\n\n\n\n\n# bef_agg &lt;- befolkning2 %&gt;% \n#   group_by( year, age_gr) %&gt;% \n#   summarise(n = sum(bef_antall)) %&gt;% \n#   ungroup()\n# \n# glimpse(bef_agg)\n# \n# ggplot(bef_agg, aes(x = year, y = n, linetype = age_gr, group = age_gr))+\n#   geom_line()+\n#   ylim(0,NA)\n# \n  \n\n## Inntekt\n\nmeta&lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/06944\",  returnMetaFrames = TRUE)\nnames(meta)\nmeta$Tid\nmeta$HusholdType\nmeta$ContentsCode\n\nkommuner_innt &lt;- meta$Region %&gt;% \n  filter(nchar(values) == 4 ) %&gt;% \n  pull(values)\nhead(kommuner_innt)\n\n\ninnt_list &lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/06944\", \n                    ContentsCode = TRUE, \n                    Region = kommuner_innt, \n                    HusholdType = TRUE,  \n                    Tid = TRUE)\n\nglimpse(innt_list[[1]])\n\ninntekt &lt;- cbind(innt_list[[2]][1], innt_list[[1]]) %&gt;% \n  mutate(year = as.numeric(year)) %&gt;% \n  select(-NAstatus) %&gt;% \n  filter(!is.na(value)) %&gt;% \n  rename(kommune = region, kommune_nr = Region,\n         hushold = `type of household`) %&gt;% \n  mutate(contents = case_when(str_sub(contents,1,5) == \"Total\" ~ \"inntekt_totalt_median\",\n                             str_sub(contents,1,6) == \"Income\" ~ \"inntekt_eskatt_median\",\n                             str_sub(contents,1,6) == \"Number\" ~ \"ant_husholdninger\")) %&gt;%\n  pivot_wider(values_from = value, names_from = contents)\n  \nglimpse(inntekt)\n\nhh_inntekt &lt;- filter(inntekt, hushold == \"All households\") %&gt;% \n  select(-hushold, -kommune)\nhead(hh_inntekt)\n\n\n\n\n\n\n\n\n## SOSIALHJLEP\n\nmeta&lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/12210\",  returnMetaFrames = TRUE)\nnames(meta)\nmeta$ContentsCode\nkokk &lt;- meta$KOKkommuneregion0000 %&gt;% \n  filter(!(values %in% c(\"EAK\", \"EAKUO\")) ) %&gt;% \n  pull(values)\n\nglimpse(kokk)  \n\n\nshj_list &lt;- ApiData(\"http://data.ssb.no/api/v0/en/table/12210\", \n                     ContentsCode = TRUE, \n                     KOKkommuneregion0000 = kokk, \n                     Tid = TRUE)\n\nshj &lt;- cbind(shj_list[[2]], shj_list[[1]][1]) %&gt;% \n  filter(!is.na(value)) %&gt;% \n  pivot_wider(values_from = value, names_from = ContentsCode) %&gt;% \n  rename(kommune_nr = KOKkommuneregion0000, \n          year = Tid,\n          shj_klienter = KOSsosantkliente0000 ,\n          shj_unge = KOSant18240000) %&gt;% \n  select(kommune_nr, year, shj_klienter, shj_unge) %&gt;% \n  mutate(year = as.numeric(year))\n  \n\nglimpse(shj)\n\n\n\n## Samle \n\n\nsamlet &lt;- left_join(bef_tot, bef_menn, by = c(\"kommune_nr\", \"year\")) %&gt;% \n  left_join(bef_kvinner, by = c(\"kommune_nr\", \"year\")) %&gt;% \n  left_join(hh_inntekt, by = c(\"kommune_nr\", \"year\")) %&gt;% \n  left_join( shj, by = c(\"kommune_nr\", \"year\")) %&gt;% \n  left_join( anm, by = c(\"kommune_nr\", \"year\")) %&gt;% \n  filter(year &gt;= 2015) %&gt;% \n  data.frame() %&gt;% \n  filter(complete.cases(.)) \n\nglimpse(samlet)\n  \n\nsaveRDS(samlet , \"data/kommunedata.rds\")",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Data fra SSBs statistikkbank</span>"
    ]
  },
  {
    "objectID": "oversikt_datasett.html",
    "href": "oversikt_datasett.html",
    "title": "25  Få oversikt over datasettet",
    "section": "",
    "text": "25.1 Sjekk om innlesning ble riktig\nNår man jobber med datasett kan det være mange variable, og det er viktig å ha en oversikt over datasettet. Bare det å finne riktig variabel kan være en utfordring i større datasett. Det vil normalt følge med et dokumentasjonsnotat eller -rapport med oversikt over alle variable. Ofte vil det være mest hensiktsmessig å slå opp i denne, men vi kan også ha behov for å se nærmere på dataene i R. En første ting man bør sjekke er om dataene er lest inn riktig og at det rett og slett ser greit ut.\nI det følgende bruker vi datasettet wagepan som er paneldata om lønn fra pakken wooldridge. Datasettet inneholder informasjon om arbeidstakere over flere år.\nDet første man bør sjekke er jo om innlesning av datasettet ble riktig. Skjer det noe feil her, så blir selvsagt alt annet feil. Men det er lite som kan gå galt når man leser inn fra datasett. Et unntak er csv-filer som ikke har metadata inkludert.\nFunksjonen class() gir informasjon om hva slags objekt man har. Altså: etter at man har lest inn dataene og lagt det i et objekt. Her sjekkes objektet wagepan:\nclass(wagepan)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nI dette tilfellet får vi tre beskjeder. Det er en kombinert objekttype av tibble og data.frame. Mens data.frame er standard datasett tilsvarende som et regneark, så er tibble en utvidelse med noen ekstra funksjoner som er nyttige for avanserte brukere, men er å regne som en utvidelse av data.frame. For vårt formål vil det i praksis være det samme. Et datasett som leses inn i R bør altså være av typen tbl eller data.frame. Data kan også ha andre typer strukturer og da vil class() rapportere noe annet.\nNår man bruker funksjoner i R, så vil noen ganger resultatet avhenge av hva slags type objekt det er.\nFor å vite hvor mange rader og kolonner det er i datasettet kan man bruke funksjonen dim() slik:\ndim(wagepan)\n\n[1] 4360   10\nHer får vi vite at det er 4360 rader (dvs. observasjoner) og 10 kollonner (dvs. variable).",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Få oversikt over datasettet</span>"
    ]
  },
  {
    "objectID": "oversikt_datasett.html#sjekk-om-innlesning-ble-riktig",
    "href": "oversikt_datasett.html#sjekk-om-innlesning-ble-riktig",
    "title": "25  Få oversikt over datasettet",
    "section": "",
    "text": "25.1.1 Bruke View()\nSærlig når man er uvant med å jobbe i R vil man kunne ha behov for å se på dataene slik man er vant til fra regneark eller software som SPSS eller Stata. En mulighet er å bruke funksjonen View() så vil hele datafilen åpnes i eget vindu. Dette er kun egnet for å se på dataene og du kan lukke vinduet uten at det påvirker dataene. Dataene ligger fremdeles i det samme objektet på samme måte som før.\n\nView(wagepan)\n\nHvis variablene ser ut til å ha forventede variabelnavn og verdier, så er det antakeligvis ok.\nEt slikt datasett tar imidlertid stor plass og det er vanligvis mer hensiktsmessige måter å se på dataene på som også gir mer informasjon. I R er det ikke meningen at du skal “sitte og se på dataene” på den måten mens man jobber. Men ta gjerne en titt for å få et bedre inntrykk av hvordan dataene ser ut.\nDu kan lukke det vinduet med dataene uten at det har noe å si for dataene, som fremdeles er tilgjengelig i minnet på datamaskinen på samme måte som før.\n\n\n25.1.2 Bruke head()\nFunksjonen head() skriver de første 6 observasjonenen til konsollen i Rstudio. Det gir et første inntrykk av datasettet med variabelnavn og de første verdiene uten å åpne hele datasettet. Hva som faktisk vises vil avhenge av hvor stor skjerm du har, men R vil bare vise de første variablene etter hva som er plass til på skjermen din. For datasett med mange variable er ikke dette veldig nyttig, men for datasett med noen få variable fungerer det greit.\n\nhead(wagepan)\n\nLegg merke til at under hvert variabelnavn er det en indikasjon på hva slags variabeltype det er. For eksempel betyr &lt;dbl&gt; at det er en numerisk variabel mens &lt;dbl+lbl&gt; indikerer at variabelen inneholder labels.\nDet er lite hensiktsmessig å vise alt i konsollen fordi det rett og slett ikke er plass. Nerst står det derfor angitt at det er flere variable som ikke vises og navnet på de første av disse.\n\n\n25.1.3 Subset med klammeparenteser\nEn enkel løsning er å bare se på noen få variable om gangen. Med klammeparentes kan vi angi hvilke radnummer og kolonnenummer vi ønsker se på med følgende syntax: datasett[rader, kolonner] der altså komma skiller mellom rader og kolonner. Følgende eksempel viser hvordan man kan bruke head() for å vise de første observasjonene i datasettet med bare de første 5 variablene (altså: kollonne nr 1-5).\n\nhead(wagepan[, 1:5])\n\n# A tibble: 6 × 5\n     nr  year hours lwage  educ\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    13  1980  2672  1.20    14\n2    13  1981  2320  1.85    14\n3    13  1982  2940  1.34    14\n4    13  1983  2960  1.43    14\n5    13  1984  3071  1.57    14\n6    13  1985  2864  1.70    14\n\n\nVi kan altså også angi både rader og kollonner på denne måten. Her er eksempel som viser første 3 rader og variabelnummer 5 til 8.\n\nhead(wagepan[1:3, 5:8])\n\n# A tibble: 3 × 4\n   educ black  hisp married\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1    14     0     0       0\n2    14     0     0       0\n3    14     0     0       0\n\n\nLegg merke til at under hvert variabelnavn står det en liten tekst, f.eks.  eller &lt;S3: haven_labelled&gt;. Det kan også stå andre ting. dbl betyr at det er en kontinuerlig variabel, mens haven_labelled betyr at det er labler til alle eller noe verdier i variabelen.\nVi skal primært jobbe med data som ikke er “labelled”, men du vil noen ganger komme borti dette, spesielt hvis du importerer data fra andre statistikksoftware.\n\n\n25.1.4 Bruke ‘glimpse()’\nI tidligere kurs skal dere ha lært å bruke funksjonen glimpse(). Her er et eksempel:\n\nglimpse(wagepan)\n\nRows: 4,360\nColumns: 10\n$ nr      &lt;dbl&gt; 13, 13, 13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17…\n$ year    &lt;dbl&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1980, 1981, 19…\n$ hours   &lt;dbl&gt; 2672, 2320, 2940, 2960, 3071, 2864, 2994, 2640, 2484, 2804, 25…\n$ lwage   &lt;dbl&gt; 1.1975402, 1.8530600, 1.3444617, 1.4332134, 1.5681251, 1.69989…\n$ educ    &lt;dbl&gt; 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13…\n$ black   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ hisp    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ married &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,…\n$ union   &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exper   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, …\n\n\nI denne output’en er den første kollonnen altså variabelnavnene, deretter er det en kollonne som viser hva slags type variabel det er, og deretter de første observasjonene på hver variabel slik at man får et inntrykk av hvordan det ser ut. glimpse() gir altså omtrent samme informasjon som head(), men er nok mer hensiktsmessig hvis mange variable.\n\n\n25.1.5 Undersøke enkeltvariable med codebook() fra pakken {memisc}\nNoen ganger vil man ha litt mer informasjon om enkeltvariablene. Noen datasett vil komme med labler (omtalt annet sted) eller faktorvariable, som gjør at variablene inneholder både tallverdier og tekst.\nÅ få ut noe deskriptiv statistikk og se på fordelinger er da gjerne neste steg som vil bli behandlet i de etterfølgende kapitlene.\nMan vil klare seg greit med det vi har vist ovenfor. Men det finnes flere måter å gjøre det på. Pakken {memisc} inneholder en rekke funksjoner for å håndtere surveydata, som vi ikke skal gå nærmere inn på her. Men akkurat funksjonen codebook() gir litt mer informativt output enn look_for().\nFor å bruke denne må du installere pakken først. I eksempelet nedenfor er pakken ikke lastet med library(), men angitt pakken direkte med memisc:: først. Dette kan være nyttig hvis man ikke skal bruke noen andre funksjoner fra denne pakken.\n\nmemisc::codebook(wagepan$married)\n\n================================================================================\n\n   wagepan$married 'Married'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n\n        Min: 0.0000000\n        Max: 1.0000000\n       Mean: 0.4389908\n   Std.Dev.: 0.4962639\n\n\nPoenget her er altså bare å få en penere output og litt deskriptiv statistikk samtidig.",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Få oversikt over datasettet</span>"
    ]
  },
  {
    "objectID": "oversikt_datasett.html#søke-i-datasettet-etter-variable",
    "href": "oversikt_datasett.html#søke-i-datasettet-etter-variable",
    "title": "25  Få oversikt over datasettet",
    "section": "25.2 Søke i datasettet etter variable",
    "text": "25.2 Søke i datasettet etter variable\nFor å se nærmere på en variabel går an å bruke funksjonen look_for(), som primært er en søke-funksjon, men det gir også informasjon om variabelen.\n\nlook_for(wagepan, \"married\")\n\n pos variable label   col_type missing values\n 8   married  Married dbl      0             \n\n\nI output fremgår det at variabelen married finnes i datasettet, hva slags type den er, og eventuelle labler.\nDet går også an å bare få ut variabel-label med funksjonen var_label() slik:\n\nvar_label(wagepan$married)\n\n[1] \"Married\"\n\n\nFor å se labels på verdiene bruk val_labels().\n\nval_labels(wagepan$married)\n\nNULL\n\n\nAlle datasett skal komme med en dokumentasjon som sier hva hver variabel inneholder og hvilke verdier som finnes i hver variable, og hva de betyr. For datasett fra R-pakker finnes dokumentasjonen i hjelpesiden, som du finner med ?wagepan eller help(wagepan).\nDu kan søke i dokumentasjonen på samme måte som i andre filer, men det kan være litt knotete. Et godt alternativ er å søke direkte i datasettet. Funksjonen look_for() søker både i variabelnavn, verdier og labler. Her er et eksempel for hvordan finne variabler som inneholder ordet “wage”. Du kan også søke på kortere eller lengre tekststrenger.\n\nlook_for(wagepan, \"wage\")\n\n pos variable label           col_type missing values\n 4   lwage    Log hourly wage dbl      0             \n\n\nHer finner vi variabelen lwage som inneholder logaritmen av timelønn. Vi kan se nærmere på variabellabelen slik:\n\nvar_label(wagepan$lwage)\n\n[1] \"Log hourly wage\"",
    "crumbs": [
      "Del VI: Importere og utforske data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Få oversikt over datasettet</span>"
    ]
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "26  Datahåndtering med tidyverse",
    "section": "",
    "text": "26.1 Pipe-operatoren: %&gt;%\nI et tidligere kapittel ble det nevnt at R har ulike “dialekter”. I denne boken bruker vi tidyverse konsekvent, og dette kapittelet går grundigere inn i hvordan man bruker tidyverse til datahåndtering. Datahåndtering er alt man gjør med dataene før man analyserer dem: lage nye variable, velge ut variable, filtrere observasjoner, sortere, gruppere og oppsummere.\nTidyverse er en samling pakker som deler en felles filosofi og syntaks. Kjernepakken for datahåndtering er dplyr, som lastes automatisk når du laster tidyverse. Poenget med tidyverse er at koden skal være lesbar og logisk, nesten som å lese setninger.\nVi bruker datasettet abu89 i eksemplene som følger. Dette datasettet inneholder informasjon om lønn, alder, utdanning, kjønn, klasse og sektor for et utvalg arbeidstakere. La oss først se på dataene:\nDet viktigste konseptet i tidyverse er “pipen” %&gt;%. Den betyr rett og slett “ta dette, og gjør deretter…”. Pipen sender resultatet fra venstre side videre som input til funksjonen på høyre side.\nHurtigtasten er Ctrl + Shift + M (du kommer til å bruke denne mye!).\nUten pipe ville vi skrevet noe slikt:\nhead(abu89)\nMed pipe kan vi skrive det slik:\nabu89 %&gt;% head()\nI dette enkle eksempelet er det ingen stor forskjell. Men pipen blir veldig nyttig når man skal gjøre flere ting etter hverandre. Uten pipe ender man opp med enten svært uleselig nøsting av funksjoner eller mange mellomliggende objekter. Med pipe kan man kjede sammen operasjoner slik:\nabu89 %&gt;%\n  filtrer noe %&gt;%\n  lag ny variabel %&gt;%\n  oppsummer\nDette er pseudokode, men illustrerer poenget: man leser koden fra topp til bunn, steg for steg. Merk at det finnes en nyere pipe i base R: |&gt;. Den fungerer omtrent likt for de aller fleste formål, og du vil se begge brukt i kodeeksempler på nettet. I denne boken bruker vi %&gt;% konsekvent.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#mutate-lage-nye-variable",
    "href": "tidyverse.html#mutate-lage-nye-variable",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.2 mutate() – lage nye variable",
    "text": "26.2 mutate() – lage nye variable\nFunksjonen mutate() brukes til å lage nye variable eller endre eksisterende. Nye variable legges til som en ny kolonne i datasettet.\n\n26.2.1 Enkel beregning\nLa oss si vi ønsker å lage en variabel som inneholder alderen i måneder:\n\nabu89 %&gt;%\n  mutate(alder_mnd = age * 12) %&gt;%\n  select(io_nr, age, alder_mnd) %&gt;%\n  head()\n\n# A tibble: 6 × 3\n  io_nr   age alder_mnd\n  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1     3    58       696\n2     4    24       288\n3     5    44       528\n4     8    46       552\n5    11    40       480\n6    12    36       432\n\n\nMerk at vi ikke har endret det opprinnelige datasettet. For å lagre endringen må vi legge resultatet tilbake i et objekt:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(alder_mnd = age * 12)\n\n\n\n26.2.2 Lage aldersgrupper med case_when()\nEt svært vanlig behov er å lage kategorier basert på en kontinuerlig variabel. Det gjøres med case_when() inni mutate():\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(aldersgruppe = case_when(\n    age &lt; 30              ~ \"Under 30\",\n    age &gt;= 30 & age &lt; 40  ~ \"30-39\",\n    age &gt;= 40 & age &lt; 50  ~ \"40-49\",\n    age &gt;= 50             ~ \"50+\"\n  ))\n\nabu89 %&gt;%\n  select(age, aldersgruppe) %&gt;%\n  head(10)\n\n# A tibble: 10 × 2\n     age aldersgruppe\n   &lt;dbl&gt; &lt;chr&gt;       \n 1    58 50+         \n 2    24 Under 30    \n 3    44 40-49       \n 4    46 40-49       \n 5    40 40-49       \n 6    36 30-39       \n 7    31 30-39       \n 8    31 30-39       \n 9    26 Under 30    \n10    29 Under 30    \n\n\ncase_when() går gjennom betingelsene fra topp til bunn og tildeler verdien på høyre side av ~ for den første betingelsen som er oppfylt. Rekkefølgen har altså betydning.\n\n\n26.2.3 Lage en binær variabel med ifelse()\nFor enklere tilfeller med bare to kategorier kan man bruke ifelse():\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(hoy_lonn = ifelse(time89 &gt; 150, \"Høy lønn\", \"Lav/middels lønn\"))\n\nabu89 %&gt;%\n  select(time89, hoy_lonn) %&gt;%\n  head()\n\n# A tibble: 6 × 2\n  time89 hoy_lonn        \n   &lt;dbl&gt; &lt;chr&gt;           \n1   62   Lav/middels lønn\n2   NA   &lt;NA&gt;            \n3   91.3 Lav/middels lønn\n4   84.2 Lav/middels lønn\n5   90.4 Lav/middels lønn\n6  103.  Lav/middels lønn",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#select-velge-variable",
    "href": "tidyverse.html#select-velge-variable",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.3 select() – velge variable",
    "text": "26.3 select() – velge variable\nFunksjonen select() brukes til å velge ut variable (kolonner) du ønsker å beholde – eller fjerne de du ikke trenger.\n\n26.3.1 Velge variable\n\nabu89 %&gt;%\n  select(io_nr, age, time89, female) %&gt;%\n  head()\n\n# A tibble: 6 × 4\n  io_nr   age time89 female\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     3    58   62        1\n2     4    24   NA        0\n3     5    44   91.3      1\n4     8    46   84.2      1\n5    11    40   90.4      0\n6    12    36  103.       0\n\n\n\n\n26.3.2 Fjerne variable\nBruker man minus-tegn foran variabelnavnet fjernes den:\n\nabu89 %&gt;%\n  select(-io_nr, -alder_mnd, -aldersgruppe, -hoy_lonn) %&gt;%\n  head()\n\n# A tibble: 6 × 8\n  time89    ed   age female klasse89                 promot  fexp private\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;                    &lt;fct&gt;  &lt;dbl&gt; &lt;fct&gt;  \n1   62       0    58      1 III Rutinefunksjonærer   NEI      1   Public \n2   NA       1    24      0 VIIa Ufaglærte arbeidere JA       0.3 Private\n3   91.3     3    44      1 II Nedre serviceklasse   JA       1.9 Private\n4   84.2     5    46      1 II Nedre serviceklasse   NEI      0.3 Public \n5   90.4     3    40      0 II Nedre serviceklasse   NEI      1   Private\n6  103.      1    36      0 II Nedre serviceklasse   NEI      1.2 Public \n\n\n\n\n26.3.3 Hjelpefunksjoner i select()\nDet finnes nyttige hjelpefunksjoner for å velge variable basert på navnemønster:\n\n# Velg alle variable som starter med en bestemt tekst\nabu89 %&gt;% select(starts_with(\"time\"))\n\n# Velg alle variable som inneholder en bestemt tekst\nabu89 %&gt;% select(contains(\"89\"))\n\n# Velg alle numeriske variable\nabu89 %&gt;% select(where(is.numeric))\n\nDisse er spesielt nyttige når man jobber med datasett som har mange variable.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#filter-filtrere-rader",
    "href": "tidyverse.html#filter-filtrere-rader",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.4 filter() – filtrere rader",
    "text": "26.4 filter() – filtrere rader\nMens select() velger kolonner, velger filter() rader basert på betingelser. Her brukes logiske operatorer som ==, !=, &gt;, &lt;, &gt;=, &lt;=, & (og), | (eller).\n\n26.4.1 Filtrere på én betingelse\n\nabu89 %&gt;%\n  filter(age &gt; 50) %&gt;%\n  head()\n\n# A tibble: 6 × 12\n  io_nr time89    ed   age female klasse89        promot  fexp private alder_mnd\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;           &lt;fct&gt;  &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;\n1     3   62       0    58      1 III Rutinefunk… NEI      1   Public        696\n2    18   89.9     0    54      1 III Rutinefunk… JA       3.5 Public        648\n3    19   NA       9    58      0 I Øvre service… JA       3.1 Public        696\n4    22   NA       9    56      0 I Øvre service… NEI      0.3 Public        672\n5    23  112.      3    54      0 III Rutinefunk… JA       2   Public        648\n6    38   70       0    65      1 V-VI Faglærte … NEI      0.2 Private       780\n# ℹ 2 more variables: aldersgruppe &lt;chr&gt;, hoy_lonn &lt;chr&gt;\n\n\n\n\n26.4.2 Filtrere på flere betingelser\n\nabu89 %&gt;%\n  filter(age &gt; 40, female == 1) %&gt;%\n  select(io_nr, age, female, time89) %&gt;%\n  head()\n\n# A tibble: 6 × 4\n  io_nr   age female time89\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     3    58      1   62  \n2     5    44      1   91.3\n3     8    46      1   84.2\n4    18    54      1   89.9\n5    38    65      1   70  \n6    39    65      1   73.9\n\n\nNår man skriver flere betingelser adskilt med komma inni filter() tolkes det som “og” (&). Alternativt kan man bruke | for “eller”:\n\nabu89 %&gt;%\n  filter(age &lt; 25 | age &gt; 60) %&gt;%\n  select(io_nr, age, time89) %&gt;%\n  head()\n\n# A tibble: 6 × 3\n  io_nr   age time89\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     4    24   NA  \n2    25    17   41  \n3    36    21   NA  \n4    38    65   70  \n5    39    65   73.9\n6    42    61  118. \n\n\n\n\n26.4.3 Fjerne manglende verdier\nEn vanlig bruk av filter() er å fjerne rader med manglende verdier (NA) på en bestemt variabel:\n\nabu89_komplett &lt;- abu89 %&gt;%\n  filter(!is.na(time89))\n\nHer betyr !is.na() “er ikke NA”.\n\n\n\n\n\n\nNote\n\n\n\nMerk forskjellen: select() velger kolonner (variable), mens filter() velger rader (observasjoner). Denne distinksjonen er viktig!",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#summarise-oppsummere-data",
    "href": "tidyverse.html#summarise-oppsummere-data",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.5 summarise() – oppsummere data",
    "text": "26.5 summarise() – oppsummere data\nFunksjonen summarise() (eller summarize(), begge stavemåter fungerer) beregner oppsummerende statistikk og returnerer en ny, liten tabell.\n\nabu89 %&gt;%\n  summarise(\n    snitt_lonn = mean(time89, na.rm = TRUE),\n    sd_lonn    = sd(time89, na.rm = TRUE),\n    snitt_alder = mean(age, na.rm = TRUE),\n    antall     = n()\n  )\n\n# A tibble: 1 × 4\n  snitt_lonn sd_lonn snitt_alder antall\n       &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;  &lt;int&gt;\n1       90.1    30.3        39.7   4127\n\n\nMerk at n() gir antall observasjoner. Argumentet na.rm = TRUE sier at manglende verdier skal ignoreres i beregningen. Uten dette argumentet vil resultatet bli NA hvis det finnes noen manglende verdier.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#group_by-grupperte-operasjoner",
    "href": "tidyverse.html#group_by-grupperte-operasjoner",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.6 group_by() – grupperte operasjoner",
    "text": "26.6 group_by() – grupperte operasjoner\ngroup_by() gjør egentlig ingenting synlig i seg selv, men endrer hvordan etterfølgende funksjoner oppfører seg. Når man bruker group_by() etterfulgt av summarise() beregnes statistikken per gruppe.\n\nabu89 %&gt;%\n  group_by(klasse89) %&gt;%\n  summarise(\n    snitt_lonn = mean(time89, na.rm = TRUE),\n    antall     = n()\n  )\n\n# A tibble: 6 × 3\n  klasse89                 snitt_lonn antall\n  &lt;fct&gt;                         &lt;dbl&gt;  &lt;int&gt;\n1 I Øvre serviceklasse          118.     328\n2 II Nedre serviceklasse        104.    1181\n3 III Rutinefunksjonærer         75.5   1248\n4 V-VI Faglærte arbeidere        88.7    648\n5 VIIa Ufaglærte arbeidere       81.4    637\n6 &lt;NA&gt;                           92.1     85\n\n\nMan kan også gruppere etter flere variable:\n\nabu89 %&gt;%\n  group_by(klasse89, female) %&gt;%\n  summarise(\n    snitt_lonn = mean(time89, na.rm = TRUE),\n    antall     = n()\n  )\n\n# A tibble: 12 × 4\n# Groups:   klasse89 [6]\n   klasse89                 female snitt_lonn antall\n   &lt;fct&gt;                     &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;\n 1 I Øvre serviceklasse          0      123.     254\n 2 I Øvre serviceklasse          1      102.      74\n 3 II Nedre serviceklasse        0      113.     626\n 4 II Nedre serviceklasse        1       93.6    555\n 5 III Rutinefunksjonærer        0       90.5    262\n 6 III Rutinefunksjonærer        1       71.6    986\n 7 V-VI Faglærte arbeidere       0       89.4    602\n 8 V-VI Faglærte arbeidere       1       79.3     46\n 9 VIIa Ufaglærte arbeidere      0       88.1    393\n10 VIIa Ufaglærte arbeidere      1       71.1    244\n11 &lt;NA&gt;                          0       96.4     56\n12 &lt;NA&gt;                          1       84.1     29\n\n\n\n\n\n\n\n\nTip\n\n\n\nHusk å bruke ungroup() etter at du er ferdig med grupperingen, spesielt hvis du skal gjøre flere operasjoner etterpå. Ellers kan grupperingen påvirke senere beregninger på uventede måter.\n\n\ngroup_by() kan også brukes sammen med mutate(). Da legges den nye variabelen til i datasettet, men beregningen gjøres per gruppe. Et typisk eksempel er å beregne gruppegjennomsnittet og legge det til som en variabel:\n\nabu89 %&gt;%\n  group_by(klasse89) %&gt;%\n  mutate(snitt_lonn_klasse = mean(time89, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  select(io_nr, klasse89, time89, snitt_lonn_klasse) %&gt;%\n  head(10)\n\n# A tibble: 10 × 4\n   io_nr klasse89                 time89 snitt_lonn_klasse\n   &lt;dbl&gt; &lt;fct&gt;                     &lt;dbl&gt;             &lt;dbl&gt;\n 1     3 III Rutinefunksjonærer     62                75.5\n 2     4 VIIa Ufaglærte arbeidere   NA                81.4\n 3     5 II Nedre serviceklasse     91.3             104. \n 4     8 II Nedre serviceklasse     84.2             104. \n 5    11 II Nedre serviceklasse     90.4             104. \n 6    12 II Nedre serviceklasse    103.              104. \n 7    13 VIIa Ufaglærte arbeidere   75                81.4\n 8    14 I Øvre serviceklasse      110.              118. \n 9    16 V-VI Faglærte arbeidere    79                88.7\n10    17 I Øvre serviceklasse      112.              118.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#arrange-sortere-data",
    "href": "tidyverse.html#arrange-sortere-data",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.7 arrange() – sortere data",
    "text": "26.7 arrange() – sortere data\nFunksjonen arrange() sorterer datasettet etter en eller flere variable. Som standard sorteres det i stigende rekkefølge.\n\nabu89 %&gt;%\n  select(io_nr, age, time89) %&gt;%\n  arrange(time89) %&gt;%\n  head()\n\n# A tibble: 6 × 3\n  io_nr   age time89\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1   148    48   25  \n2  4107    17   25  \n3  3316    41   25.9\n4  1685    37   26.3\n5  2126    21   26.8\n6   272    18   27.5\n\n\nFor synkende rekkefølge brukes desc():\n\nabu89 %&gt;%\n  select(io_nr, age, time89) %&gt;%\n  arrange(desc(time89)) %&gt;%\n  head()\n\n# A tibble: 6 × 3\n  io_nr   age time89\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2557    36   344.\n2  3276    35   325 \n3  1188    63   300 \n4  1997    44   300 \n5  3757    42   300 \n6  3751    52   278.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#kombinere-funksjoner-med-pipe",
    "href": "tidyverse.html#kombinere-funksjoner-med-pipe",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.8 Kombinere funksjoner med pipe",
    "text": "26.8 Kombinere funksjoner med pipe\nDen virkelige styrken med tidyverse er at man kan kombinere alle disse funksjonene i én sammenhengende arbeidsflyt. Her er et eksempel som gjør flere ting:\n\nabu89 %&gt;%\n  filter(!is.na(time89)) %&gt;%                         # Fjern manglende verdier\n  mutate(ed_aar = as.numeric(as.character(ed))) %&gt;%   # Gjør utdanning numerisk\n  group_by(klasse89) %&gt;%                              # Grupper etter klasse\n  summarise(\n    snitt_lonn = mean(time89, na.rm = TRUE),          # Gjennomsnittslønn\n    snitt_alder = mean(age, na.rm = TRUE),             # Gjennomsnittsalder\n    antall = n()                                       # Antall per gruppe\n  ) %&gt;%\n  arrange(desc(snitt_lonn))                            # Sorter etter lønn\n\n# A tibble: 6 × 4\n  klasse89                 snitt_lonn snitt_alder antall\n  &lt;fct&gt;                         &lt;dbl&gt;       &lt;dbl&gt;  &lt;int&gt;\n1 I Øvre serviceklasse          118.         40.8    292\n2 II Nedre serviceklasse        104.         40.7   1044\n3 &lt;NA&gt;                           92.1        36.5     79\n4 V-VI Faglærte arbeidere        88.7        38.5    607\n5 VIIa Ufaglærte arbeidere       81.4        40.1    598\n6 III Rutinefunksjonærer         75.5        38.2   1139\n\n\nDenne koden leses som: “Ta datasettet abu89, fjern deretter rader med manglende lønn, lag deretter en numerisk utdanningsvariabel, grupper deretter etter klasse, beregn deretter gjennomsnitt per klasse, og sorter til slutt etter lønn.”\nDet er god praksis å legge til kommentarer i koden med # slik at du husker hva hvert steg gjør.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#across-samme-operasjon-på-flere-variable",
    "href": "tidyverse.html#across-samme-operasjon-på-flere-variable",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.9 across() – samme operasjon på flere variable",
    "text": "26.9 across() – samme operasjon på flere variable\nNoen ganger ønsker man å gjøre det samme med flere variable samtidig. Funksjonen across() brukes inni mutate() eller summarise() for å anvende en funksjon på flere kolonner.\nHer er et eksempel der vi beregner gjennomsnittet av alle numeriske variable per klasse:\n\nabu89 %&gt;%\n  group_by(klasse89) %&gt;%\n  summarise(across(where(is.numeric), ~mean(.x, na.rm = TRUE))) %&gt;%\n  head()\n\n# A tibble: 6 × 8\n  klasse89                 io_nr time89    ed   age female  fexp alder_mnd\n  &lt;fct&gt;                    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 I Øvre serviceklasse     3112.  118.  6.23   41.1 0.226  0.990      494.\n2 II Nedre serviceklasse   3095.  104.  4.27   40.9 0.470  1.03       491.\n3 III Rutinefunksjonærer   3139.   75.5 1.67   38.5 0.790  0.798      462.\n4 V-VI Faglærte arbeidere  3205.   88.7 1.73   38.9 0.0710 1.03       467.\n5 VIIa Ufaglærte arbeidere 3044.   81.4 0.948  40.1 0.383  0.977      481.\n6 &lt;NA&gt;                     2388.   92.1 2.42   36.6 0.341  0.826      439.\n\n\nSyntaksen ~mean(.x, na.rm = TRUE) er en forkortet måte å skrive en funksjon på der .x er et plassholdernavn for variabelen. where(is.numeric) velger alle numeriske variable. Man kan også angi variabelnavn direkte:\n\nabu89 %&gt;%\n  summarise(across(c(age, time89),\n                   list(snitt = ~mean(.x, na.rm = TRUE),\n                        sd = ~sd(.x, na.rm = TRUE))))\n\n# A tibble: 1 × 4\n  age_snitt age_sd time89_snitt time89_sd\n      &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1      39.7   12.4         90.1      30.3\n\n\nHer beregnes både gjennomsnitt og standardavvik for variablene age og time89. Resultatnavnene settes automatisk sammen av variabelnavn og funksjonsnavnet angitt i list().\nacross() er svært nyttig for å unngå repetitiv kode, men kan virke litt kryptisk i starten. Det er helt greit å skrive ut variabel for variabel til man er komfortabel med across().",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#oppsummering",
    "href": "tidyverse.html#oppsummering",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.10 Oppsummering",
    "text": "26.10 Oppsummering\nHer er en oversikt over de viktigste funksjonene i dplyr:\n\n\n\nFunksjon\nHva den gjør\n\n\n\n\nmutate()\nLager nye variable / endrer eksisterende\n\n\nselect()\nVelger (eller fjerner) kolonner\n\n\nfilter()\nFiltrerer rader basert på betingelser\n\n\nsummarise()\nBeregner oppsummerende statistikk\n\n\ngroup_by()\nGrupperer data for etterfølgende operasjoner\n\n\narrange()\nSorterer rader\n\n\nacross()\nAnvender funksjoner på flere kolonner\n\n\n\nAlle disse kan kombineres med %&gt;% for å lage ryddige, lesbare arbeidsflyter.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse.html#oppgaver",
    "href": "tidyverse.html#oppgaver",
    "title": "26  Datahåndtering med tidyverse",
    "section": "26.11 Oppgaver",
    "text": "26.11 Oppgaver\n\nExercise 26.1 Bruk datasettet abu89 og lag en ny variabel som angir om en person er over eller under 40 år. Bruk mutate() og ifelse().\n\n\nExercise 26.2 Filtrer datasettet slik at du bare har personer som jobber i privat sektor, og beregn gjennomsnittslønn og gjennomsnittsalder for dette utvalget med summarise().\n\n\nExercise 26.3 Bruk group_by() og summarise() til å beregne gjennomsnittlig timelønn for hver klasse, fordelt på kjønn. Sorter resultatet etter synkende lønn med arrange().\n\n\nExercise 26.4 Skriv en sammenhengende pipe som filtrerer bort manglende verdier på timelønn, grupperer etter aldersgruppe (som du lager med case_when()), og beregner gjennomsnitt, standardavvik og antall per gruppe.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Datahåndtering med tidyverse</span>"
    ]
  },
  {
    "objectID": "omkoding.html",
    "href": "omkoding.html",
    "title": "27  Omkoding av variable",
    "section": "",
    "text": "27.1 Factor-variable\nÅ omkode variable er noe du vil gjøre veldig ofte. Noen ganger trenger du å slå sammen kategorier, andre ganger trenger du å lage helt nye variable basert på eksisterende. Det kan handle om å lage aldersgrupper fra en kontinuerlig aldersvariabel, slå sammen utdanningskategorier, eller gjøre om en variabel til en annen type. I dette kapittelet går vi gjennom de viktigste teknikkene.\nFactor-variable er Rs måte å håndtere kategoriske data på. En factor har definerte nivåer (levels) som angir de mulige verdiene. La oss se på et eksempel:\nclass(abu89$klasse89)\n\n[1] \"factor\"\n\nlevels(abu89$klasse89)\n\n[1] \"I Øvre serviceklasse\"     \"II Nedre serviceklasse\"  \n[3] \"III Rutinefunksjonærer\"   \"V-VI Faglærte arbeidere\" \n[5] \"VIIa Ufaglærte arbeidere\"\nVi kan se at variabelen klasse89 er en factor med fem nivåer. Rekkefølgen på nivåene har betydning, blant annet for hvilken kategori som blir referansekategori i regresjonsanalyser.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#factor-variable",
    "href": "omkoding.html#factor-variable",
    "title": "27  Omkoding av variable",
    "section": "",
    "text": "27.1.1 Lage factor fra tall\nHvis du har en numerisk variabel som egentlig er kategorisk, kan du gjøre den om til factor:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(kjonn = factor(ifelse(female == 1, \"Kvinne\", \"Mann\"),\n                        levels = c(\"Mann\", \"Kvinne\")))\n\ntable(abu89$kjonn)\n\n\n  Mann Kvinne \n  2193   1934 \n\n\nMed levels = bestemmer du rekkefølgen. Den første kategorien blir referansekategori i regresjon.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#omkoding-med-ifelse",
    "href": "omkoding.html#omkoding-med-ifelse",
    "title": "27  Omkoding av variable",
    "section": "27.2 Omkoding med ifelse()",
    "text": "27.2 Omkoding med ifelse()\nDen enkleste formen for omkoding er ifelse(). Den tester en betingelse og gir én verdi hvis betingelsen er sann og en annen hvis den er usann:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(hoylonn = ifelse(time89 &gt; 100, \"Høy lønn\", \"Lav lønn\"))\n\ntable(abu89$hoylonn)\n\n\nHøy lønn Lav lønn \n    1007     2752 \n\n\nHer er time89 &gt; 100 betingelsen. Alle som har timelønn over 100 får verdien “Høy lønn”, resten får “Lav lønn”.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#omkoding-med-case_when",
    "href": "omkoding.html#omkoding-med-case_when",
    "title": "27  Omkoding av variable",
    "section": "27.3 Omkoding med case_when()",
    "text": "27.3 Omkoding med case_when()\nNår du har mer enn to kategorier, er case_when() mye mer oversiktlig enn nestede ifelse()-kall:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(aldersgruppe = case_when(\n    age &lt; 25 ~ \"Under 25\",\n    age &lt; 35 ~ \"25-34\",\n    age &lt; 45 ~ \"35-44\",\n    age &lt; 55 ~ \"45-54\",\n    age &gt;= 55 ~ \"55 og over\"\n  ))\n\ntable(abu89$aldersgruppe)\n\n\n     25-34      35-44      45-54 55 og over   Under 25 \n      1061       1179        790        595        502 \n\n\nMerk at case_when() evaluerer betingelsene ovenfra og ned. Den stopper ved den første betingelsen som er sann. Derfor trenger vi ikke skrive age &gt;= 25 & age &lt; 35 for den andre linjen - alle under 25 er allerede fanget opp av første linje.\n\n\n\n\n\n\nTip\n\n\n\nHvis ingen av betingelsene er sanne, får verdien NA. Du kan legge til .default = \"Annet\" som siste argument for å fange opp alt som ikke matcher.\n\n\nResultatet av case_when() er en tekstvariabel. Hvis du vil ha den som factor med bestemt rekkefølge, kan du pakke det inn i factor():\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(aldersgruppe = factor(\n    case_when(\n      age &lt; 25 ~ \"Under 25\",\n      age &lt; 35 ~ \"25-34\",\n      age &lt; 45 ~ \"35-44\",\n      age &lt; 55 ~ \"45-54\",\n      age &gt;= 55 ~ \"55 og over\"\n    ),\n    levels = c(\"Under 25\", \"25-34\", \"35-44\", \"45-54\", \"55 og over\")\n  ))\n\nlevels(abu89$aldersgruppe)\n\n[1] \"Under 25\"   \"25-34\"      \"35-44\"      \"45-54\"      \"55 og over\"",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#lage-grupper-med-cut",
    "href": "omkoding.html#lage-grupper-med-cut",
    "title": "27  Omkoding av variable",
    "section": "27.4 Lage grupper med cut()",
    "text": "27.4 Lage grupper med cut()\nFor å dele en kontinuerlig variabel inn i grupper er cut() et hendig alternativ:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(aldersgruppe2 = cut(age,\n                             breaks = c(0, 25, 35, 45, 55, 100),\n                             labels = c(\"Under 25\", \"25-34\", \"35-44\",\n                                       \"45-54\", \"55+\")))\n\ntable(abu89$aldersgruppe2)\n\n\nUnder 25    25-34    35-44    45-54      55+ \n     587     1092     1171      745      532 \n\n\nbreaks angir grensene og labels angir navnene på gruppene. Merk at det alltid er én label mindre enn antall grenseverdier.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#endre-factor-nivåer-med-forcats",
    "href": "omkoding.html#endre-factor-nivåer-med-forcats",
    "title": "27  Omkoding av variable",
    "section": "27.5 Endre factor-nivåer med forcats",
    "text": "27.5 Endre factor-nivåer med forcats\nPakken forcats (en del av tidyverse) har en rekke nyttige funksjoner for å jobbe med factor-variable.\n\n27.5.1 Slå sammen kategorier med fct_collapse()\nHvis du har for mange kategorier og vil slå noen sammen:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(klasse_enkel = fct_collapse(klasse89,\n    \"Service\" = c(\"I: Øvre serviceklasse\", \"II: Nedre serviceklasse\"),\n    \"Rutine\" = c(\"III: Rutinefunksjonærer\"),\n    \"Arbeider\" = c(\"V-VI: Faglærte arbeidere\", \"VII: Ufaglærte arbeidere\")\n  ))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `klasse_enkel = fct_collapse(...)`.\nCaused by warning:\n! Unknown levels in `f`: I: Øvre serviceklasse, II: Nedre serviceklasse, III: Rutinefunksjonærer, V-VI: Faglærte arbeidere, VII: Ufaglærte arbeidere\n\ntable(abu89$klasse_enkel)\n\n\n    I Øvre serviceklasse   II Nedre serviceklasse   III Rutinefunksjonærer \n                     328                     1181                     1248 \n V-VI Faglærte arbeidere VIIa Ufaglærte arbeidere \n                     648                      637 \n\n\n\n\n27.5.2 Gi nye navn med fct_recode()\nNoen ganger vil du bare endre navnene uten å slå sammen:\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(klasse_kort = fct_recode(klasse89,\n    \"I\" = \"I: Øvre serviceklasse\",\n    \"II\" = \"II: Nedre serviceklasse\",\n    \"III\" = \"III: Rutinefunksjonærer\",\n    \"V-VI\" = \"V-VI: Faglærte arbeidere\",\n    \"VII\" = \"VII: Ufaglærte arbeidere\"\n  ))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `klasse_kort = fct_recode(...)`.\nCaused by warning:\n! Unknown levels in `f`: I: Øvre serviceklasse, II: Nedre serviceklasse, III: Rutinefunksjonærer, V-VI: Faglærte arbeidere, VII: Ufaglærte arbeidere\n\ntable(abu89$klasse_kort)\n\n\n    I Øvre serviceklasse   II Nedre serviceklasse   III Rutinefunksjonærer \n                     328                     1181                     1248 \n V-VI Faglærte arbeidere VIIa Ufaglærte arbeidere \n                     648                      637 \n\n\nMerk syntaksen: \"nytt navn\" = \"gammelt navn\".\n\n\n27.5.3 Endre rekkefølge med fct_relevel()\nFor å endre hvilken kategori som er først (og dermed referansekategori i regresjon):\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(klasse_omvendt = fct_relevel(klasse89, \"VII: Ufaglærte arbeidere\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `klasse_omvendt = fct_relevel(klasse89, \"VII: Ufaglærte\n  arbeidere\")`.\nCaused by warning:\n! 1 unknown level in `f`: VII: Ufaglærte arbeidere\n\nlevels(abu89$klasse_omvendt)\n\n[1] \"I Øvre serviceklasse\"     \"II Nedre serviceklasse\"  \n[3] \"III Rutinefunksjonærer\"   \"V-VI Faglærte arbeidere\" \n[5] \"VIIa Ufaglærte arbeidere\"\n\n\nNå er “VII: Ufaglærte arbeidere” flyttet til første posisjon og vil bli referansekategori.\n\n\n27.5.4 Sortere etter en annen variabel med fct_reorder()\nNoen ganger vil du sortere kategoriene etter en annen variabel, for eksempel for å lage pene grafer:\n\nabu89 %&gt;%\n  filter(!is.na(klasse89), !is.na(time89)) %&gt;%\n  mutate(klasse89 = fct_reorder(klasse89, time89, .fun = mean)) %&gt;%\n  ggplot(aes(x = klasse89, y = time89)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\n\nHer sorteres klassekategoriene etter gjennomsnittlig timelønn, slik at den klassen med lavest lønn kommer først.\n\n\n27.5.5 Fjerne ubrukte nivåer med fct_drop()\nEtter filtrering kan du sitte igjen med factor-nivåer som ikke lenger har observasjoner:\n\nabu89_lite &lt;- abu89 %&gt;%\n  filter(klasse89 %in% c(\"I: Øvre serviceklasse\", \"II: Nedre serviceklasse\"))\n\n# Ubrukte nivåer er fortsatt der\nlevels(abu89_lite$klasse89)\n\n[1] \"I Øvre serviceklasse\"     \"II Nedre serviceklasse\"  \n[3] \"III Rutinefunksjonærer\"   \"V-VI Faglærte arbeidere\" \n[5] \"VIIa Ufaglærte arbeidere\"\n\n# Fjern dem\nabu89_lite &lt;- abu89_lite %&gt;%\n  mutate(klasse89 = fct_drop(klasse89))\n\nlevels(abu89_lite$klasse89)\n\ncharacter(0)",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#jobbe-med-tekst",
    "href": "omkoding.html#jobbe-med-tekst",
    "title": "27  Omkoding av variable",
    "section": "27.6 Jobbe med tekst",
    "text": "27.6 Jobbe med tekst\nNoen ganger trenger du å jobbe med tekstverdier. Pakken stringr (en del av tidyverse) har nyttige funksjoner:\n\n# Finne tekst i en variabel\nabu89 %&gt;%\n  filter(str_detect(as.character(klasse89), \"service\")) %&gt;%\n  head(3) %&gt;%\n  select(klasse89, time89)\n\n# A tibble: 3 × 2\n  klasse89               time89\n  &lt;fct&gt;                   &lt;dbl&gt;\n1 II Nedre serviceklasse   91.3\n2 II Nedre serviceklasse   84.2\n3 II Nedre serviceklasse   90.4\n\n\n\n# Erstatte tekst\nabu89 %&gt;%\n  mutate(klasse_ny = str_replace(as.character(klasse89), \"klasse\", \"kl.\"))",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#praktisk-eksempel-komplett-omkoding",
    "href": "omkoding.html#praktisk-eksempel-komplett-omkoding",
    "title": "27  Omkoding av variable",
    "section": "27.7 Praktisk eksempel: komplett omkoding",
    "text": "27.7 Praktisk eksempel: komplett omkoding\nHer er et eksempel som viser en typisk omkodingsprosess der vi forbereder data til analyse:\n\nabu89_analyse &lt;- abu89 %&gt;%\n  mutate(\n    # Lage kjønnsvariabel som factor\n    kjonn = factor(ifelse(female == 1, \"Kvinne\", \"Mann\"),\n                   levels = c(\"Mann\", \"Kvinne\")),\n    # Lage aldersgrupper\n    alder_gr = cut(age, breaks = c(0, 30, 40, 50, 100),\n                   labels = c(\"Under 30\", \"30-39\", \"40-49\", \"50+\")),\n    # Forenkle klassevariabel\n    klasse = fct_collapse(klasse89,\n      \"Serviceklasse\" = c(\"I: Øvre serviceklasse\", \"II: Nedre serviceklasse\"),\n      \"Rutine\" = \"III: Rutinefunksjonærer\",\n      \"Arbeiderklasse\" = c(\"V-VI: Faglærte arbeidere\", \"VII: Ufaglærte arbeidere\")\n    ),\n    # Lage dummy for høy lønn\n    hoylonn = ifelse(time89 &gt; median(time89, na.rm = TRUE), 1, 0)\n  ) %&gt;%\n  select(time89, hoylonn, kjonn, age, alder_gr, klasse)\n\nglimpse(abu89_analyse)\n\nRows: 4,127\nColumns: 6\n$ time89   &lt;dbl&gt; 62.00000, NA, 91.32895, 84.23913, 90.42553, 103.28947, 75.000…\n$ hoylonn  &lt;dbl&gt; 0, NA, 1, 1, 1, 1, 0, 1, 0, 1, 1, NA, 0, 1, NA, 1, 0, 1, 1, 0…\n$ kjonn    &lt;fct&gt; Kvinne, Mann, Kvinne, Kvinne, Mann, Mann, Kvinne, Mann, Mann,…\n$ age      &lt;dbl&gt; 58, 24, 44, 46, 40, 36, 31, 31, 26, 29, 54, 58, 25, 25, 56, 5…\n$ alder_gr &lt;fct&gt; 50+, Under 30, 40-49, 40-49, 30-39, 30-39, 30-39, 30-39, Unde…\n$ klasse   &lt;fct&gt; III Rutinefunksjonærer, VIIa Ufaglærte arbeidere, II Nedre se…",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "omkoding.html#oppsummering",
    "href": "omkoding.html#oppsummering",
    "title": "27  Omkoding av variable",
    "section": "27.8 Oppsummering",
    "text": "27.8 Oppsummering\n\n\n\n\n\n\n\n\nOppgave\nFunksjon\nEksempel\n\n\n\n\nTo kategorier\nifelse()\nifelse(x &gt; 10, \"Høy\", \"Lav\")\n\n\nFlere kategorier\ncase_when()\ncase_when(x &lt; 10 ~ \"Lav\", ...)\n\n\nKutte kontinuerlig\ncut()\ncut(x, breaks = c(0,10,20))\n\n\nSlå sammen nivåer\nfct_collapse()\nfct_collapse(x, A = c(\"a\",\"b\"))\n\n\nEndre navn\nfct_recode()\nfct_recode(x, \"Ny\" = \"Gml\")\n\n\nEndre rekkefølge\nfct_relevel()\nfct_relevel(x, \"Sist\")\n\n\nSortere etter verdi\nfct_reorder()\nfct_reorder(x, y, mean)\n\n\nFjerne tomme nivåer\nfct_drop()\nfct_drop(x)",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Omkoding av variable</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html",
    "href": "missing_verdier.html",
    "title": "28  Haandtering av missing-verdier",
    "section": "",
    "text": "28.1 Hva er NA?\nI nesten alle datasett fra sporreskjemaundersokelser vil det vaere observasjoner der vi mangler informasjon paa noen variable. Noen har ikke svart paa alle sporsmaal, noen har hoppet over deler av skjemaet, og noen ganger er det feil i registreringen. Slike manglende verdier – eller missing values – er noe du maa forholde deg til i praksis. R representerer manglende verdier med den spesielle verdien NA (Not Available), og det er viktig aa forstaa hvordan dette fungerer for aa unngaa feil i analysene.\nNA er Rs maate aa si “vi vet ikke”. Det er ikke det samme som null eller en tom tekststreng. Det betyr rett og slett at verdien mangler. Du kan tenke paa det som et tomt felt i et regneark – det er ikke fylt ut, og vi vet ikke hva svaret ville vaert.\nx &lt;- c(3, 7, NA, 12, NA, 5)\nx\n\n[1]  3  7 NA 12 NA  5\nLegg merke til at NA ikke har anforsselstegn rundt seg. Det er fordi NA er en spesiell verdi i R, ikke en tekststreng.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#sjekke-for-missing-verdier",
    "href": "missing_verdier.html#sjekke-for-missing-verdier",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.2 Sjekke for missing-verdier",
    "text": "28.2 Sjekke for missing-verdier\nFor aa finne ut hvilke verdier som er NA bruker vi funksjonen is.na(). Den returnerer TRUE for hver verdi som er NA og FALSE for resten.\n\nis.na(x)\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n\nMerk at du ikke kan bruke vanlig likhetstegn for aa sjekke om noe er NA. Uttrykket x == NA gir nemlig NA tilbake – ikke TRUE eller FALSE som du kanskje forventer. Det er fordi R tenker at “vi vet ikke om en ukjent verdi er lik en annen ukjent verdi”. Bruk alltid is.na().\nFor et helt datasett kan vi bruke complete.cases() for aa finne radene som ikke har noen manglende verdier overhodet:\n\nsum(complete.cases(abu89))\n\n[1] 3680\n\n\nDette forteller oss hvor mange rader i datasettet som har gyldige verdier paa alle variable.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#oppsummere-missing-i-datasettet",
    "href": "missing_verdier.html#oppsummere-missing-i-datasettet",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.3 Oppsummere missing i datasettet",
    "text": "28.3 Oppsummere missing i datasettet\nDet er lurt aa skaffe seg en oversikt over hvor mye missing det er i datasettet for man begynner aa analysere. En rask maate er aa kombinere colSums() og is.na():\n\ncolSums(is.na(abu89))\n\n   io_nr   time89       ed      age   female klasse89   promot     fexp \n       0      368        0        0        0       85        0        0 \n private \n       0 \n\n\nDette gir antall NA per variabel. Hvis det er mange variable kan det vaere nyttig aa sortere resultatet:\n\nsort(colSums(is.na(abu89)), decreasing = TRUE)\n\n  time89 klasse89    io_nr       ed      age   female   promot     fexp \n     368       85        0        0        0        0        0        0 \n private \n       0 \n\n\nFor en visuell oversikt kan du bruke pakken naniar:\n\nlibrary(naniar)\nvis_miss(abu89)\n\nDenne lager et plott der du ser monstre i missing-verdiene. Det kan for eksempel avslore om det er bestemte variable som har mye missing, eller om det er grupper av observasjoner som mangler paa mange variable samtidig.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#funksjoner-og-na-argumentet-na.rm",
    "href": "missing_verdier.html#funksjoner-og-na-argumentet-na.rm",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.4 Funksjoner og NA: argumentet na.rm",
    "text": "28.4 Funksjoner og NA: argumentet na.rm\nMange funksjoner i R gir NA som resultat hvis det er missing-verdier i dataene. Det er egentlig fornuftig: R sier at “resultatet er ukjent fordi noen av verdiene er ukjente”. Men i praksis vil man som oftest beregne resultatet basert paa de verdiene man faktisk har.\n\nx &lt;- c(3, 7, NA, 12, 5)\nmean(x)\n\n[1] NA\n\n\nFor aa faa gjennomsnittet av de verdiene som finnes, bruker vi argumentet na.rm = TRUE (som staar for “NA remove”):\n\nmean(x, na.rm = TRUE)\n\n[1] 6.75\n\n\nDette gjelder for en rekke funksjoner som sum(), sd(), median(), min(), max() og andre. Det er et veldig vanlig argument som du kommer til aa bruke ofte.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#filtrere-ut-missing",
    "href": "missing_verdier.html#filtrere-ut-missing",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.5 Filtrere ut missing",
    "text": "28.5 Filtrere ut missing\nNaar du jobber med datasett i tidyverse kan du filtrere bort rader med missing paa bestemte variable. Det gjor du med filter() og is.na():\n\nabu89 %&gt;%\n  filter(!is.na(time89)) %&gt;%\n  nrow()\n\n[1] 3759\n\n\nHer beholder vi bare radene der time89 ikke er NA. Utropstegnet ! betyr “ikke”.\nHvis du vil fjerne alle rader som har NA paa en eller flere bestemte variable kan du bruke drop_na() fra tidyr:\n\nabu89 %&gt;%\n  drop_na(time89, ed) %&gt;%\n  nrow()\n\n[1] 3759\n\n\nUten argumenter fjerner drop_na() alle rader med missing paa noen som helst variabel. Det kan vaere ganske drastisk, saa det er som regel lurt aa spesifisere hvilke variable du vil fjerne missing paa.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#omkode-verdier-til-na",
    "href": "missing_verdier.html#omkode-verdier-til-na",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.6 Omkode verdier til NA",
    "text": "28.6 Omkode verdier til NA\nI en del datasett er missing-verdier kodet som bestemte tall i stedet for ekte NA. For eksempel kan -9, 99 eller 999 bety “ikke svart” eller “vet ikke”. Slike verdier maa du kode om til NA selv.\nMed mutate() og na_if() er dette enkelt:\n\ndatasett &lt;- datasett %&gt;%\n  mutate(variabel = na_if(variabel, -9))\n\nDette gjor at alle verdier som er lik -9 paa variabelen blir til NA. Du kan ogsaa bruke case_when() for mer avansert omkoding der flere verdier skal bli NA:\n\ndatasett &lt;- datasett %&gt;%\n  mutate(variabel = case_when(\n    variabel %in% c(-9, -8, 999) ~ NA_real_,\n    TRUE ~ variabel\n  ))",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#erstatte-na-med-verdier",
    "href": "missing_verdier.html#erstatte-na-med-verdier",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.7 Erstatte NA med verdier",
    "text": "28.7 Erstatte NA med verdier\nNoen ganger vil du erstatte NA med en bestemt verdi. For eksempel kan det vaere fornuftig aa anta at manglende verdier paa en variabel for antall barn betyr at personen ikke har barn, altsa null.\n\ny &lt;- c(2, NA, 1, NA, 3)\nreplace_na(y, 0)\n\n[1] 2 0 1 0 3\n\n\nI en pipe med mutate():\n\ndatasett &lt;- datasett %&gt;%\n  mutate(ant_barn = replace_na(ant_barn, 0))\n\nFunksjonen coalesce() er nyttig hvis du har flere variable og vil bruke den forste som ikke er NA:\n\na &lt;- c(NA, 2, NA, 4)\nb &lt;- c(10, NA, 30, NA)\ncoalesce(a, b)\n\n[1] 10  2 30  4\n\n\nDenne funksjonen velger den forste ikke-manglende verdien fra venstre til hoyre. Det kan vaere nyttig naar du har informasjon fra flere kilder og vil fylle inn der det mangler.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#missing-i-regresjonsanalyser",
    "href": "missing_verdier.html#missing-i-regresjonsanalyser",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.8 Missing i regresjonsanalyser",
    "text": "28.8 Missing i regresjonsanalyser\nNaar du kjorer en regresjonsmodell med lm() i R, saa haandterer funksjonen missing automatisk ved aa fjerne alle observasjoner som har NA paa noen av variablene i modellen. Dette kalles listwise deletion (eller complete case analysis).\n\nmod &lt;- lm(time89 ~ ed + age, data = abu89)\nnobs(mod)\n\n[1] 3759\n\nnrow(abu89)\n\n[1] 4127\n\n\nLegg merke til at antall observasjoner i modellen (nobs()) kan vaere lavere enn antall rader i datasettet. Det er fordi rader med NA paa noen av variablene i modellen er fjernet. Det er viktig aa vaere oppmerksom paa dette, spesielt naar du sammenligner modeller med ulike variable. Hvis en variabel har mye missing, kan det endre utvalget betraktelig fra en modell til en annen.\nEt godt tips er aa lage et analysedatasett der du fjerner missing paa de relevante variablene forst, slik at alle modeller estimeres paa det samme utvalget:\n\nabu89_analyse &lt;- abu89 %&gt;%\n  drop_na(time89, ed, age)\n\nmod1 &lt;- lm(time89 ~ ed, data = abu89_analyse)\nmod2 &lt;- lm(time89 ~ ed + age, data = abu89_analyse)\n\nnobs(mod1)\n\n[1] 3759\n\nnobs(mod2)\n\n[1] 3759\n\n\nNaa bruker begge modellene noyaktig samme utvalg, og eventuelle forskjeller skyldes modellspesifikasjonen og ikke at ulike observasjoner er med.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#multippel-imputering",
    "href": "missing_verdier.html#multippel-imputering",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.9 Multippel imputering",
    "text": "28.9 Multippel imputering\nListwise deletion er den enkleste tilnaermingen, men den har en ulempe: du mister data. Hvis mange observasjoner har missing paa minst en variabel, kan utvalget bli vesentlig mindre. I tillegg kan resultatene bli skjeve hvis dataene ikke mangler helt tilfeldig.\nEn mer avansert tilnaerming er multippel imputering, der man estimerer hva de manglende verdiene sannsynligvis ville vaert basert paa den informasjonen man faktisk har. Pakken mice i R er det mest brukte verktoeyet for dette. Vi gaar ikke naermere inn paa dette her, men det er greit aa vite at det finnes. Hvis du har mye missing i dataene dine og det er viktig for resultatene, bor du sette deg inn i dette temaet.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "missing_verdier.html#vanlige-fallgruver-og-tips",
    "href": "missing_verdier.html#vanlige-fallgruver-og-tips",
    "title": "28  Haandtering av missing-verdier",
    "section": "28.10 Vanlige fallgruver og tips",
    "text": "28.10 Vanlige fallgruver og tips\nHer er noen praktiske rad for aa haandtere missing:\n\nSjekk alltid for missing for du begynner aa analysere. Bruk summary() eller colSums(is.na()) for aa faa en oversikt. Missing-verdier som du ikke er klar over kan gi misvisende resultater.\nBruk na.rm = TRUE bevisst. Det er lett aa bare legge til na.rm = TRUE overalt, men tenk igjennom hvorfor det er missing. Hvis mange verdier mangler, bor du undersoke dette naermere for du fjerner dem.\nIkke bruk x == NA. Bruk alltid is.na(x). Dette er en av de vanligste nybegynnerfeilene i R.\nPass paa at missing betyr det du tror. I noen datasett er missing-verdier kodet som -9, 999 eller lignende. Sjekk dokumentasjonen for datasettet og kod om til NA der det trengs.\nVaer forsiktig med drop_na() uten argumenter. Uten argumenter fjerner den alle rader med missing paa hvilken som helst variabel, noe som kan gi et veldig lite datasett.\nLag et analysedatasett. Naar du kjorer regresjoner, lag et eget datasett der du har fjernet missing paa de relevante variablene, slik at alle modeller bruker samme utvalg.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Haandtering av missing-verdier</span>"
    ]
  },
  {
    "objectID": "koble_omforme.html",
    "href": "koble_omforme.html",
    "title": "29  Koble sammen og omforme data",
    "section": "",
    "text": "29.1 Koble datasett med join-funksjoner\nI samfunnsvitenskapelig forskning vil man ofte ha behov for data fra ulike kilder. Kanskje har du et datasett med survey-data om individer og et annet med registerdata om kommunene de bor i. Eller du har data fra to ulike tidspunkter som skal kobles sammen. Da trenger du verktøy for å koble datasett sammen.\nI tillegg vil du noen ganger oppleve at dataene er organisert på en måte som ikke passer til det du skal gjøre. Data kan være i “bredt” format der hvert tidspunkt har sin egen kolonne, mens du trenger det i “langt” format der hvert tidspunkt er en egen rad – eller omvendt. Da trenger du verktøy for å omforme data.\nDette kapittelet handler om begge deler: å koble datasett og å omforme data mellom bredt og langt format.\nFor å illustrere hvordan join-funksjoner fungerer lager vi to små eksempeldatasett. Tenk deg at du har et datasett med karakterer fra et kurs og et annet med bakgrunnsinformasjon om studentene.\nkarakterer &lt;- tibble(\n  id = c(1, 2, 3, 4),\n  navn = c(\"Anna\", \"Bjørn\", \"Cecilie\", \"David\"),\n  karakter = c(\"A\", \"B\", \"C\", \"B\")\n)\n\nbakgrunn &lt;- tibble(\n  id = c(1, 2, 3, 5),\n  studieprogram = c(\"Sosiologi\", \"Statsvitenskap\", \"Økonomi\", \"Sosiologi\"),\n  kjonn = c(\"K\", \"M\", \"K\", \"M\")\n)\nLegg merke til at de to datasettene ikke har helt de samme id-verdiene. Student 4 (David) finnes bare i karakterdatasettet, mens student 5 finnes bare i bakgrunnsdatasettet. Dette er helt vanlig i praksis og det er nettopp derfor det er viktig å forstå de ulike typene joins.\nLa oss se på de to datasettene:\nkarakterer\n\n# A tibble: 4 × 3\n     id navn    karakter\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1     1 Anna    A       \n2     2 Bjørn   B       \n3     3 Cecilie C       \n4     4 David   B       \n\nbakgrunn\n\n# A tibble: 4 × 3\n     id studieprogram  kjonn\n  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n1     1 Sosiologi      K    \n2     2 Statsvitenskap M    \n3     3 Økonomi        K    \n4     5 Sosiologi      M",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Koble sammen og omforme data</span>"
    ]
  },
  {
    "objectID": "koble_omforme.html#koble-datasett-med-join-funksjoner",
    "href": "koble_omforme.html#koble-datasett-med-join-funksjoner",
    "title": "29  Koble sammen og omforme data",
    "section": "",
    "text": "29.1.1 left_join: Behold alt fra venstre datasett\nDen klart vanligste join-funksjonen er left_join(). Den beholder alle radene fra det første (venstre) datasettet og legger til informasjon fra det andre datasettet der det finnes en match.\n\nleft_join(karakterer, bakgrunn, by = \"id\")\n\n# A tibble: 4 × 5\n     id navn    karakter studieprogram  kjonn\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;\n1     1 Anna    A        Sosiologi      K    \n2     2 Bjørn   B        Statsvitenskap M    \n3     3 Cecilie C        Økonomi        K    \n4     4 David   B        &lt;NA&gt;           &lt;NA&gt; \n\n\nHer ser vi at alle fire studentene fra karakterer er med. Anna, Bjørn og Cecilie har fått påkoblet informasjon om studieprogram og kjønn. Men David (id = 4) finnes ikke i bakgrunn, så han får NA på de nye variablene. Student 5 fra bakgrunn er ikke med fordi vedkommende ikke fantes i karakterer.\nDette er den vanligste situasjonen: du har et hoveddatasett og vil legge til tilleggsinformasjon fra en annen kilde.\n\n\n29.1.2 right_join: Behold alt fra høyre datasett\nright_join() gjør det motsatte: beholder alt fra det andre (høyre) datasettet.\n\nright_join(karakterer, bakgrunn, by = \"id\")\n\n# A tibble: 4 × 5\n     id navn    karakter studieprogram  kjonn\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;\n1     1 Anna    A        Sosiologi      K    \n2     2 Bjørn   B        Statsvitenskap M    \n3     3 Cecilie C        Økonomi        K    \n4     5 &lt;NA&gt;    &lt;NA&gt;     Sosiologi      M    \n\n\nNå er student 5 med (fra bakgrunn), men David (id = 4) er borte. I praksis brukes right_join() sjelden fordi man like gjerne kan bytte rekkefølgen på datasettene og bruke left_join().\n\n\n29.1.3 inner_join: Bare rader som finnes i begge\ninner_join() beholder bare radene som har en match i begge datasettene.\n\ninner_join(karakterer, bakgrunn, by = \"id\")\n\n# A tibble: 3 × 5\n     id navn    karakter studieprogram  kjonn\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;\n1     1 Anna    A        Sosiologi      K    \n2     2 Bjørn   B        Statsvitenskap M    \n3     3 Cecilie C        Økonomi        K    \n\n\nHer er bare id 1, 2 og 3 med – altså de som finnes i begge datasett. Både David (id = 4) og student 5 er borte. Dette kan være nyttig når du bare vil ha komplette observasjoner, men vær oppmerksom på at du kan miste data uten å være klar over det.\n\n\n29.1.4 full_join: Behold alt fra begge datasett\nfull_join() beholder alle rader fra begge datasettene.\n\nfull_join(karakterer, bakgrunn, by = \"id\")\n\n# A tibble: 5 × 5\n     id navn    karakter studieprogram  kjonn\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;\n1     1 Anna    A        Sosiologi      K    \n2     2 Bjørn   B        Statsvitenskap M    \n3     3 Cecilie C        Økonomi        K    \n4     4 David   B        &lt;NA&gt;           &lt;NA&gt; \n5     5 &lt;NA&gt;    &lt;NA&gt;     Sosiologi      M    \n\n\nNå er alle med. David får NA på studieprogram og kjønn, og student 5 får NA på navn og karakter. Dette gir deg all tilgjengelig informasjon, men du må håndtere de manglende verdiene etterpå.\n\n\n29.1.5 Spesifisere koblingsnøkkel med by-argumentet\nI eksemplene ovenfor hadde begge datasettene en variabel som het id, og vi koblet på den. Men hva om variablene heter forskjellige ting i de to datasettene? Da må du spesifisere dette eksplisitt.\n\nkarakterer2 &lt;- tibble(\n  student_id = c(1, 2, 3, 4),\n  navn = c(\"Anna\", \"Bjørn\", \"Cecilie\", \"David\"),\n  karakter = c(\"A\", \"B\", \"C\", \"B\")\n)\n\nbakgrunn2 &lt;- tibble(\n  id_nr = c(1, 2, 3, 5),\n  studieprogram = c(\"Sosiologi\", \"Statsvitenskap\", \"Økonomi\", \"Sosiologi\")\n)\n\nleft_join(karakterer2, bakgrunn2, by = c(\"student_id\" = \"id_nr\"))\n\n# A tibble: 4 × 4\n  student_id navn    karakter studieprogram \n       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;         \n1          1 Anna    A        Sosiologi     \n2          2 Bjørn   B        Statsvitenskap\n3          3 Cecilie C        Økonomi       \n4          4 David   B        &lt;NA&gt;          \n\n\nHer forteller vi R at student_id i det første datasettet tilsvarer id_nr i det andre.\nDu kan også koble på flere variable samtidig. For eksempel hvis du har paneldata med både person-id og år:\n\nsurvey &lt;- tibble(\n  id = c(1, 1, 2, 2),\n  aar = c(2020, 2023, 2020, 2023),\n  tilfredshet = c(7, 8, 5, 6)\n)\n\nregister &lt;- tibble(\n  id = c(1, 1, 2, 2),\n  aar = c(2020, 2023, 2020, 2023),\n  inntekt = c(450000, 510000, 380000, 420000)\n)\n\nleft_join(survey, register, by = c(\"id\", \"aar\"))\n\n# A tibble: 4 × 4\n     id   aar tilfredshet inntekt\n  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1     1  2020           7  450000\n2     1  2023           8  510000\n3     2  2020           5  380000\n4     2  2023           6  420000\n\n\n\n\n29.1.6 Hva kan gå galt?\nDet vanligste problemet er at koblingen gir flere rader enn forventet. Det skjer når det er duplikater i koblingsnøklene. Hvis en id forekommer flere ganger i det ene datasettet, får du en rad for hver kombinasjon. Sjekk derfor alltid antall rader før og etter en join for å forsikre deg om at resultatet er som forventet:\n\nresultat &lt;- left_join(karakterer, bakgrunn, by = \"id\")\nnrow(karakterer)\n\n[1] 4\n\nnrow(resultat)\n\n[1] 4\n\n\nHvis nrow(resultat) er større enn nrow(karakterer) etter en left_join(), så har du sannsynligvis duplikater i koblingsnøklene og bør undersøke dette nærmere.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Koble sammen og omforme data</span>"
    ]
  },
  {
    "objectID": "koble_omforme.html#omforme-data-bredt-og-langt-format",
    "href": "koble_omforme.html#omforme-data-bredt-og-langt-format",
    "title": "29  Koble sammen og omforme data",
    "section": "29.2 Omforme data: bredt og langt format",
    "text": "29.2 Omforme data: bredt og langt format\nI samfunnsvitenskap jobber vi ofte med paneldata – altså data der vi har målinger på samme enhet over tid. Slike data kan organiseres på to måter.\nI bredt format har hver enhet en rad, og hvert tidspunkt har sin egen kolonne:\n\nbred &lt;- tibble(\n  kommune = c(\"Oslo\", \"Bergen\", \"Trondheim\"),\n  arbeidsledighet_2020 = c(4.2, 3.8, 3.5),\n  arbeidsledighet_2021 = c(5.1, 4.5, 4.0),\n  arbeidsledighet_2022 = c(3.9, 3.6, 3.2)\n)\nbred\n\n# A tibble: 3 × 4\n  kommune   arbeidsledighet_2020 arbeidsledighet_2021 arbeidsledighet_2022\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;                &lt;dbl&gt;\n1 Oslo                       4.2                  5.1                  3.9\n2 Bergen                     3.8                  4.5                  3.6\n3 Trondheim                  3.5                  4                    3.2\n\n\nI langt format har hver måling sin egen rad:\n\nlang &lt;- tibble(\n  kommune = rep(c(\"Oslo\", \"Bergen\", \"Trondheim\"), each = 3),\n  aar = rep(c(2020, 2021, 2022), 3),\n  arbeidsledighet = c(4.2, 5.1, 3.9, 3.8, 4.5, 3.6, 3.5, 4.0, 3.2)\n)\nlang\n\n# A tibble: 9 × 3\n  kommune     aar arbeidsledighet\n  &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n1 Oslo       2020             4.2\n2 Oslo       2021             5.1\n3 Oslo       2022             3.9\n4 Bergen     2020             3.8\n5 Bergen     2021             4.5\n6 Bergen     2022             3.6\n7 Trondheim  2020             3.5\n8 Trondheim  2021             4  \n9 Trondheim  2022             3.2\n\n\nBegge formatene inneholder nøyaktig samme informasjon. Men til analyser og plotting i R vil du som oftest trenge data i langt format. Data fra SSB og andre kilder kommer imidlertid ofte i bredt format. Heldigvis er det enkelt å omforme mellom de to formatene.\n\n29.2.1 Fra bredt til langt med pivot_longer()\npivot_longer() gjør data lengre ved å samle flere kolonner til en.\n\nbred %&gt;%\n  pivot_longer(\n    cols = starts_with(\"arbeidsledighet\"),\n    names_to = \"aar\",\n    values_to = \"arbeidsledighet\",\n    names_prefix = \"arbeidsledighet_\"\n  )\n\n# A tibble: 9 × 3\n  kommune   aar   arbeidsledighet\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;\n1 Oslo      2020              4.2\n2 Oslo      2021              5.1\n3 Oslo      2022              3.9\n4 Bergen    2020              3.8\n5 Bergen    2021              4.5\n6 Bergen    2022              3.6\n7 Trondheim 2020              3.5\n8 Trondheim 2021              4  \n9 Trondheim 2022              3.2\n\n\nHer angir vi:\n\ncols: hvilke kolonner som skal omformes (her: alle som starter med “arbeidsledighet”)\nnames_to: hva den nye variabelen med kolonnenavnene skal hete\nvalues_to: hva den nye variabelen med verdiene skal hete\nnames_prefix: en tekst som skal fjernes fra kolonnenavnene (slik at vi får “2020” i stedet for “arbeidsledighet_2020”)\n\nMerk at aar her blir en tekstvariabel. Hvis du trenger den som numerisk kan du legge til names_transform = list(aar = as.numeric) eller gjøre det i et eget steg etterpå.\n\n\n29.2.2 Fra langt til bredt med pivot_wider()\npivot_wider() gjør det motsatte: sprer rader utover i kolonner.\n\nlang %&gt;%\n  pivot_wider(\n    names_from = aar,\n    values_from = arbeidsledighet,\n    names_prefix = \"arbeidsledighet_\"\n  )\n\n# A tibble: 3 × 4\n  kommune   arbeidsledighet_2020 arbeidsledighet_2021 arbeidsledighet_2022\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;                &lt;dbl&gt;\n1 Oslo                       4.2                  5.1                  3.9\n2 Bergen                     3.8                  4.5                  3.6\n3 Trondheim                  3.5                  4                    3.2\n\n\nHer angir vi:\n\nnames_from: hvilken variabel som skal gi de nye kolonnenavnene\nvalues_from: hvilken variabel verdiene skal hentes fra\nnames_prefix: en tekst som legges foran de nye kolonnenavnene\n\n\n\n29.2.3 Når trenger du hva?\nNoen tommelfingerregler:\n\nLangt format trengs for de fleste analyser i R, inkludert ggplot, regresjonsmodeller og gruppert deskriptiv statistikk. Hvis du skal lage et plott med ggplot() der du vil vise utvikling over tid, må dataene være i langt format.\nBredt format er nyttig for å presentere data i tabeller, og noen spesifikke analyser krever bredt format. Data fra SSB og en del andre kilder leveres typisk i bredt format.\n\nI praksis er det vanligst at du må gjøre om fra bredt til langt format, altså bruke pivot_longer(). Men det er greit å vite om begge deler.\nDisse funksjonene kan virke litt forvirrende i starten, men blir raskt naturlige når man har brukt dem noen ganger. Det beste tipset er rett og slett å prøve selv på egne data.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Koble sammen og omforme data</span>"
    ]
  },
  {
    "objectID": "store_data.html",
    "href": "store_data.html",
    "title": "30  Håndtering av store datasett",
    "section": "",
    "text": "30.1 Når blir data “store”?\nI de foregående kapitlene har vi jobbet med datasett som er relativt små og håndterlige. Men hva skjer når datasettet blir stort? I dette kapittelet ser vi på noen praktiske strategier for når ting begynner å gå tregt – eller når datasettet rett og slett ikke får plass i minnet på datamaskinen din.\nFor de fleste samfunnsvitenskapelige datasett vil du aldri oppleve problemer med størrelsen. Et spørreundersøkelse med noen tusen respondenter og noen hundre variable er egentlig ganske lite i dataverdenen. Men det finnes situasjoner der ting kan bli tyngre:\nR holder alle data i minnet (RAM) på datamaskinen. En typisk laptop har 8-16 GB RAM, og operativsystemet bruker en del av dette. Når datasettet nærmer seg størrelsen på tilgjengelig RAM, begynner ting å gå veldig tregt – og til slutt krasjer R.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#når-blir-data-store",
    "href": "store_data.html#når-blir-data-store",
    "title": "30  Håndtering av store datasett",
    "section": "",
    "text": "Registerdata med millioner av observasjoner over mange år\nTekstdata, f.eks. fra sosiale medier, med millioner av poster\nGeodata med svært detaljert oppløsning\nKoblede datasett der mange registre er koblet sammen",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#sjekke-størrelsen-på-datasett",
    "href": "store_data.html#sjekke-størrelsen-på-datasett",
    "title": "30  Håndtering av store datasett",
    "section": "30.2 Sjekke størrelsen på datasett",
    "text": "30.2 Sjekke størrelsen på datasett\nDet er nyttig å vite hvor mye plass et datasett tar. Funksjonen object.size() gir deg en enkel oversikt:\n\n# Lager et eksempel-datasett\neksempel &lt;- data.frame(\n  id = 1:100000,\n  verdi = rnorm(100000),\n  kategori = sample(letters[1:5], 100000, replace = TRUE)\n)\n\nobject.size(eksempel)\n\n2001272 bytes\n\nprint(object.size(eksempel), units = \"Mb\")\n\n1.9 Mb\n\n\nFor en mer nøyaktig måling kan du bruke lobstr::obj_size() som tar hensyn til delte objekter i minnet:\n\nlibrary(lobstr)\nobj_size(eksempel)\n\nSom en tommelfingerregel: et datasett på noen hundre megabyte er uproblematisk. Når det nærmer seg noen gigabyte bør du begynne å tenke på alternativer.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#effektive-filformater-parquet",
    "href": "store_data.html#effektive-filformater-parquet",
    "title": "30  Håndtering av store datasett",
    "section": "30.3 Effektive filformater: Parquet",
    "text": "30.3 Effektive filformater: Parquet\nCsv-filer er enkle og universelle, men de er trege å lese inn og tar mye plass. For større datasett finnes det langt bedre alternativer. De to viktigste er feather og parquet, som begge håndteres av pakken arrow.\nParquet-formatet er spesielt nyttig fordi det:\n\nTar vesentlig mindre plass enn csv (ofte 5-10 ganger mindre)\nEr mye raskere å lese inn\nBevarer datatyper (du slipper problemer med at tall blir lest inn som tekst)\nKan leses av både R, Python og mange andre verktøy\n\nHer er et eksempel på hvordan du skriver og leser parquet-filer:\n\nlibrary(arrow)\n\n# Skrive til parquet\nwrite_parquet(eksempel, \"data/eksempel.parquet\")\n\n# Lese fra parquet\neksempel_parquet &lt;- read_parquet(\"data/eksempel.parquet\")\n\nForskjellen i hastighet merkes godt på store filer. En csv-fil som tar 30 sekunder å lese inn kan ta under ett sekund som parquet. Hvis du jobber med store datasett og leser inn de samme dataene flere ganger, er det absolutt verdt å konvertere til parquet.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#data.table-et-raskt-alternativ",
    "href": "store_data.html#data.table-et-raskt-alternativ",
    "title": "30  Håndtering av store datasett",
    "section": "30.4 data.table: Et raskt alternativ",
    "text": "30.4 data.table: Et raskt alternativ\nGjennom hele denne boken har vi brukt tidyverse og dplyr for datahåndtering. Det fungerer utmerket for de aller fleste formål. Men hvis du jobber med svært store datasett og synes ting går tregt, finnes det et alternativ: pakken data.table.\ndata.table er designet for hastighet og minneeffektivitet. Syntaksen er ganske annerledes enn tidyverse, men for noen operasjoner kan den være mange ganger raskere. Her er en liten smakebit:\n\nlibrary(data.table)\n\n# Konvertere til data.table\ndt &lt;- as.data.table(eksempel)\n\n# Filtrere og aggregere (tilsvarer filter + group_by + summarise)\ndt[kategori == \"a\", .(gjennomsnitt = mean(verdi)), by = kategori]\n\nMerk at data.table bruker en kompakt syntax med klammeparenteser: dt[i, j, by] der i er radfiltrering, j er hva du vil gjøre med kolonnene, og by er gruppering. Det er effektivt, men kan være vanskeligere å lese for nybegynnere.\nFor de fleste studenter er tidyverse absolutt å anbefale. Men det er greit å vite at data.table finnes dersom du en gang jobber med data der hastighet er kritisk. Det går også an å kombinere de to tilnærmingene med pakken dtplyr, som lar deg skrive dplyr-kode som kjøres med data.table i bakgrunnen.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#lazy-evaluation-med-arrow",
    "href": "store_data.html#lazy-evaluation-med-arrow",
    "title": "30  Håndtering av store datasett",
    "section": "30.5 Lazy evaluation med Arrow",
    "text": "30.5 Lazy evaluation med Arrow\nHva gjør du når datasettet er større enn minnet på datamaskinen? Da kan du bruke arrow til å jobbe med data uten å laste alt inn i minnet. Dette kalles lazy evaluation: du bygger opp en serie operasjoner, og arrow utfører dem først når du eksplisitt ber om resultatet.\n\nlibrary(arrow)\n\n# Åpne datasett uten å laste det i minnet\nstort_datasett &lt;- open_dataset(\"data/stor_mappe/\")\n\n# Bygg opp operasjoner (ingenting kjøres ennå)\nresultat &lt;- stort_datasett |&gt;\n  filter(aar &gt;= 2015) |&gt;\n  select(id, aar, inntekt, kommune) |&gt;\n  group_by(kommune) |&gt;\n  summarise(snitt_inntekt = mean(inntekt))\n\n# Hent resultatet inn i minnet\nresultat_df &lt;- collect(resultat)\n\nHer er poenget at filter(), select() og summarise() ikke utføres med en gang. Det er først når du kaller collect() at arrow faktisk leser og prosesserer dataene – og da leser den bare de delene den trenger. Syntaksen er altså helt vanlig dplyr-kode, men den kjøres på en smartere måte i bakgrunnen.\nDette fungerer spesielt godt med parquet-filer som er delt opp i flere filer i en mappe (såkalt partisjonert data).",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#databasetilkoblinger",
    "href": "store_data.html#databasetilkoblinger",
    "title": "30  Håndtering av store datasett",
    "section": "30.6 Databasetilkoblinger",
    "text": "30.6 Databasetilkoblinger\nFor virkelig store data, eller data som oppdateres kontinuerlig, er det vanlig å bruke databaser. R kan koble seg til de fleste typer databaser via pakkene DBI og dbplyr. Med dbplyr kan du skrive vanlig dplyr-kode, men i bakgrunnen oversettes det til SQL-spørringer mot databasen.\n\nlibrary(DBI)\nlibrary(dbplyr)\n\n# Koble til en database (eksempel med SQLite)\ncon &lt;- dbConnect(RSQLite::SQLite(), \"min_database.sqlite\")\n\n# Referere til en tabell i databasen\ntabell &lt;- tbl(con, \"min_tabell\")\n\n# Bruke vanlig dplyr-syntax\nresultat &lt;- tabell |&gt;\n  filter(aar == 2020) |&gt;\n  group_by(kommune) |&gt;\n  summarise(antall = n()) |&gt;\n  collect()\n\n# Lukke tilkoblingen\ndbDisconnect(con)\n\nDe fleste studenter vil ikke trenge dette, men det er godt å vite at muligheten finnes. Noen forskningsprosjekter benytter databaser som PostgreSQL, MySQL eller Oracle for lagring av store datamengder, og da er dette veien å gå.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#praktiske-tips-for-store-datasett",
    "href": "store_data.html#praktiske-tips-for-store-datasett",
    "title": "30  Håndtering av store datasett",
    "section": "30.7 Praktiske tips for store datasett",
    "text": "30.7 Praktiske tips for store datasett\nUansett hvilke verktøy du bruker, er det noen enkle grep som hjelper:\n\nVelg kun de kolonnene du trenger. Ikke les inn 500 variable hvis du bare skal bruke 10. Bruk select() så tidlig som mulig.\nFiltrer tidlig. Hvis du bare trenger data fra et bestemt år eller en bestemt kommune, filtrer før du gjør tunge beregninger.\nBruk effektive datatyper. Tekstvariable tar mer plass enn numeriske. Konverter kategoriske variable til factor med as.factor() for å spare plass.\nLagre mellomresultater. Hvis du har gjort en tung bearbeiding, lagre resultatet som en rds- eller parquet-fil slik at du slipper å gjøre det på nytt.\nUnngå unødvendige kopier. Hver gang du lager et nytt objekt i R, brukes mer minne. Fjern objekter du ikke trenger lenger med rm() og frigjør minne med gc().\n\n\n# Fjerne et objekt og frigjøre minne\nrm(stort_objekt)\ngc()",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "store_data.html#når-r-ikke-er-nok",
    "href": "store_data.html#når-r-ikke-er-nok",
    "title": "30  Håndtering av store datasett",
    "section": "30.8 Når R ikke er nok",
    "text": "30.8 Når R ikke er nok\nI noen sjeldne tilfeller kan det hende at R rett og slett ikke strekker til. Dette gjelder typisk for svært store data (mange titalls gigabyte eller mer) eller oppgaver som krever distribuert beregning. Da kan det være aktuelt å se på:\n\nPython med pandas eller polars for datahåndtering, eventuelt via pakken reticulate som lar deg kjøre Python-kode direkte fra R\nApache Spark for distribuert databehandling, tilgjengelig fra R via pakken sparklyr\n\nMen for de aller, aller fleste samfunnsvitenskapelige analyser er R mer enn kraftig nok. Og med verktøyene vi har sett på i dette kapittelet – parquet-filer, arrow og eventuelt data.table – kommer du veldig langt.",
    "crumbs": [
      "Del VI: Datahåndtering",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Håndtering av store datasett</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referanser",
    "section": "",
    "text": "Moore, David S., Notz William I, and Michael Fligner. 2021. The\nBasic Practice of Statistics. W.H.Freeman & Co Ltd.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data\nScience. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley.",
    "crumbs": [
      "Referanser"
    ]
  },
  {
    "objectID": "appendix_addins.html",
    "href": "appendix_addins.html",
    "title": "Appendix A — Rstudio addins",
    "section": "",
    "text": "A.1 Styler - skriv pent\nRstudio er det mulig å installere såkalte “addins”. Dette gir ikke økt funksjonalitet til R, men til Rstudio. De fleste addins er imidlertid laget med tanke på helt andre brukere enn studenter og kan fremstå nokså kryptiske. Nedenfor er det omtalt tre pakker som kan være nyttige for nybegynnere i R-programmering ved å tilby en “pek-og-klikk” funksjonalitet til å skrive kode. Dette kan være nyttig for å finne ut av problemer og vanskelig syntaks - men er ikke noe du skal bruke på daglig basis. Det er hjelp til å finne ut av ting, så bruk det til å lære!\nAddins installeres på samme måte som R-pakker med install.packages, men du trenger ikke laste det med library for å brukes. I stedet er funksjonene tilgjengelig i Rstudio-menyen “Addins”. For en liste over addins, se hjelpesiden til pakken addinslist.\nDet er veldig viktig at du bruker slike addins på en måte som gjør at du lærer deg R på ordentlig. Du kan ikke belage deg på å bruke addins for å skrive kode i det lange løp. De som nevnes nedenfor genererer kode for deg og du bør så lime den koden inn i scriptet ditt!\nI R spiller det ingen rolle hvordan du skriver kode: linjeskift, innrykk og mellomrom etter parentes osv gir det samme resultatet. (Komma og parenteser er derimot viktig!). Men det er ikke likegyldig for lesbarheten. {styler} kan brukes til å bedre lesbarheten av egen kode. Denne addin’en er laget av de samme som lager tidyverse, og er derfor utmerket verktøy for å skrive bedre kode. “Bedre” er da her i betydningen ryddig og ordentlig, noe som gjør den lettere å lese, de-bugge og at andre forstår koden din.\nDu kan se nærmere på vignetten til Styler",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Rstudio addins</span>"
    ]
  },
  {
    "objectID": "appendix_addins.html#esquisse---grafikk",
    "href": "appendix_addins.html#esquisse---grafikk",
    "title": "Appendix A — Rstudio addins",
    "section": "A.2 Esquisse - grafikk",
    "text": "A.2 Esquisse - grafikk\nEsquisse kan brukes til å lage grafikk med “drag-and-drop”. Noen synes det er lettere i begynnelsen. Men det viktigste med å bruke slike verktøy er at du etterpå kan vise koden slik den lages med ggplot.\nDu kan se nærmere på vignetten til Esquisse.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Rstudio addins</span>"
    ]
  },
  {
    "objectID": "appendix_addins.html#questionr---omkode-factor",
    "href": "appendix_addins.html#questionr---omkode-factor",
    "title": "Appendix A — Rstudio addins",
    "section": "A.3 Questionr - omkode factor",
    "text": "A.3 Questionr - omkode factor\nÅ omkode factor-variable kan være litt styr. Det er en egen addin for dette formålet.\nOBS! Questionr generer kode i base-R. Det er altså ikke helt den samme dialekten som ellers er dekket her. Men det er likheter, så det kan være til hjelp likevel. Dessuten funker det, jo.\nDu kan se nærmere på vignetten til questionr.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Rstudio addins</span>"
    ]
  },
  {
    "objectID": "appendix_import_metadata.html",
    "href": "appendix_import_metadata.html",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "",
    "text": "B.0.1 Hvorfor så vanskelig?\nFor de som vil ha en litt mer utfordring kan man lese inn filen i Stata-format. Dette er slik det blir levert fra Sikt1\nStata-formatet dta har to utfordringer når vi importerer til R. Det er tilsvarende problemstilling hvis man importerer fra SPSS eller SAS. For det første er det noen ganger gitt en egen kode for manglende verdi, såkalt “missing”. For det andre lagres informasjonen på en annen måte enn i R. I Stata er ofte kategoriske variable lagret som en numerisk variabel med en tilhørende “label”. Når man leser inn dta-fil til R vil disse variablene være av typen “labelled”. I R er det langt bedre å gjøre de om til factor-variable, men det er litt styr å kode om hvis det er veldig mange variable i datasettet - slik det ofte er i surveydata.\nVi presenterer en samlet løsning først, så tar vi hver del for seg etterpå for å forklare. Nedenforstående kode gjør omtrent følgende:\nNedenfor vil det vises en god del komplisert kode bare for å få datasettet over i et håndterbart R-format. Mye styr her. Dette gjør at du lett kan få inntrykk av at R er lite egnet til å håndtere slike data når det trengs så mye jobb. Men: Hvis dataene var lagret på en annen måte ville det vært vesentlig enklere. La oss derfor vise hvordan koden ville vært hvis NorLAG var lagret i Stata-format med følgende forutsetninger:\nHvis dataene er konsekvent kodet på denne måten kunne en innlesning se omtrent slik ut:\nnorlag &lt;- read_stata(\"data/norlag.dta\") %&gt;% \n  unlabelled()\nFørste linje importerer dataene. Andre linje gjør om alle variable av typen “labelled” til factor-variable der lablene blir omgjort til “factor-levels”. Dette er da alt som trengs.\nMen i den virkelige verden er det sjelden så enkelt. Alle datasett har en del mikk-makk ved seg av både gode og dårlige grunner. Hvordan dataene har blitt til og hvem som har lagt til rette for videre bruk for andre er de to store avgjørende faktorene her.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Import av data fra Sikt - håndtering av formater med metadata</span>"
    ]
  },
  {
    "objectID": "appendix_import_metadata.html#håndtering-av-user-nas",
    "href": "appendix_import_metadata.html#håndtering-av-user-nas",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.1 Håndtering av user-NAs",
    "text": "B.1 Håndtering av user-NAs\nFor datasettet NorLAG vil det være ulike sett av missing-verdier for de ulike variablene. Dette kan helt fint håndteres manuelt variabel for variabel. Men for å ha ordentlig kontroll på at det blir riktig bør det automatiseres. Logikken i denne delen går et stykke utover hva vi forventer at den jevne sosiologistudent skal lære.\nEn første sted er å lese inn dokumentasjonsrapporten fra en html-fil slik den leveres fra Sikt og gjør det om til et håndterbart oppslags-datasett. Dette er beskrevet i eget appendix. Det følgende tar utgangspunkt i at en slik oppslagsfil finnes.\nDet er noen verdier som i dokumentasjonen er spesifisert som spesielle typer missing. Disse skal vi kode om til NA. Disse verdiene har labler som starter med “filter:” eller “vil ikke svare” etc. Disse danner basis for omkoding til NA. Dette er ikke en komplett liste over koder som innebærer at det egentlig mangler informasjon. (Dvs. fordi koden indikerer grunner til at det mangler informasjon). Etter denne oppryddingen kan det altså fremdeles hende at det dukker opp noe slikt, så vær påpasselig med å sjekke variabelens fordeling før du analyserer med regresjonsmodeller.\nFunksjonen nedenfor skal brukes innenfor et steg der man går gjennom alle variablene en om gangen. For hver variabel slås det opp de aktuelle missing-verdiene som gjelder for denne og bruker replace til å omkode til NA for disse verdiene. Når denne funksjonen kalles for hver variabel senere, så brukes det altså ulike definisjoner av missing-verdier for hver variabel.2",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Import av data fra Sikt - håndtering av formater med metadata</span>"
    ]
  },
  {
    "objectID": "appendix_import_metadata.html#innlesning-av-data",
    "href": "appendix_import_metadata.html#innlesning-av-data",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.2 innlesning av data",
    "text": "B.2 innlesning av data\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(labelled)\n\n# data\n\nfaste &lt;- read_stata( \"data/NorLAG-lengde-faste.dta\", encoding = \"utf-8\")\n\nlang &lt;- read_stata( \"data/NorLAG-lengde-intervju.dta\", encoding = \"utf-8\")\n\nregister &lt;- read_stata(paste0(infilbane, \"NorLAG-lengde-register.dta\"), encoding = \"utf-8\")\n\nNår dataene er er fordelt på flere filer, som i NorLAG, må de slås sammen. Dette gjøres ved å bruke merge()-funksjonen i R. I NorLAG er det en del variable som er i faste og en del som er i intervju. Så er det et eget datasett med variable hentet fra registre. Vi vil ha alle variable i samme datasett.\n\nnorlag_lbl1 &lt;- merge(faste, lang, by = c(\"ref_nr\"), all.x = TRUE) %&gt;% \n  filter(iodeltakelse == 1 |  \n           iodeltakelse == 2 & round %in% c(1, 3) | \n           iodeltakelse == 3 & round %in% c(2, 3) |\n           iodeltakelse == 4 & round %in% c(1) |\n           iodeltakelse == 5 & round %in% c(1, 2) |\n           iodeltakelse == 6 & round %in% c(2)\n  ) %&gt;% \n  mutate(year = iointervjuaar)\n\nnorlag_lbl &lt;- merge(norlag_lbl1, register, all.x = TRUE, by = c(\"ref_nr\", \"year\"))\n\nI neste steg benyttes katalogen som ble laget tidligere til å omkode alle variable som har spesifikke missing-verdier til NA. Dette gjøres for alle variable i hele datasettet.\n\n# vektorer av variable som skal omkodes\ncols_vec_all &lt;- unique(dat_dict$col_nm)\nvars &lt;- unique(names(norlag_lbl))\ncols_vec &lt;- cols_vec_all[cols_vec_all %in% vars]\ncols_vec_na &lt;- cols_vec[(cols_vec %in% unique(dat_dict_na$col_nm))]\n\nnorlag &lt;- norlag_lbl %&gt;% \n  mutate(across(all_of(cols_vec_na), \n              \\(x,dic) recode_col_na(x, .env$dat_dict_na))) %&gt;% \n  mutate(across(where(is.labelled), ~as_factor(.))) %&gt;% \n  mutate(across(where(is.factor), ~fct_drop(.)))\n\nI tilegg skal vi lage en variabel for det vi kan kalle hovedaktivitet som sysselsettingsstatus. Det er om man er yrkesaktiv, arbeidsledig, student eller annet. I hver runde av NorLAG ble svarkategoriene utformet litt forskjellig, så derfor er svarene fordelt over tre variable. Nedenfor samles disse sammen og kodes om basert på tekststrenger. Dette gjøres noe mer manuelt da det bare gjelder akkurat disse variablene.\n\n## Omkoder hovedaktivitet \nfs &lt;- lvls_union( list(norlag$wr001, norlag$wr002, norlag$wr003c)) %&gt;% tolower() %&gt;% unique()\n\nnorlag &lt;- norlag %&gt;% \n  mutate(across(wr001:wr003c, ~factor(tolower(.), levels=fs))) %&gt;% \n  mutate(hovedaktivitet = case_when(round == 1 ~ wr001, \n                                    round == 2 ~ wr002, \n                                    round == 3 ~ wr003c) ) %&gt;% \n  mutate(hovedaktivitet2 = case_when( str_sub(hovedaktivitet, 1, 5) == \"yrkes\" ~ \"Yrkesaktiv\", \n                                      str_detect(hovedaktivitet, \"arbeidsledig\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"student\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"trygd\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"annet\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_sub(hovedaktivitet,1,6)   == \"hjemme\" ~ \"hjemmeværende/husmor\", \n                                      str_detect(hovedaktivitet, \"pensjonist\") ~ \"pensjonist\", \n                                      is.na(hovedaktivitet) ~ \"Trygdet/arbeidsledig/stud/annet\") %&gt;% as_factor())\n\nI NorLAG er det en del variable som omhandler inntekt og er beløp i kroner. I NorLAG har de valgt å legge på en label på noen av disse verdiene. Bildet nedenfor viser hvordan variabelen inwies ser ut.\n\nDet er altså to verdier som er spesifisert som “Value &lt;0 &gt;-5000” og “Value &gt;0 &lt;5000”. Dette er altså en måte å spesifisere at verdien er en verdi som ligger innenfor et intervall. Dette skaper problemer fordi det gjør at R tolker disse som factor-variable i stedet for numeriske variable slik de er ment å være.\nDet kan virke praktisk å legge slike labler inn i datasettet slik at man lett ser f.eks. at verdien “-5000” faktisk viser til et intervall og ikke den nøyaktige verdien. Men i dette tilfellet står jo dette allerede i dokumentasjonen og i en konkret analyse vil man jo måtte tolke verdien numerisk uansett. Det kan også bemerkes at de numeriske verdiene er avrundet til intervaller på 10.000 slik at det er ganske logisk at det også gjelder for “-5000” og “5000”. Vi velger derfor å omkode disse til numeriske verdier og slette lablene.\nMen det er en hel rekke variable som har labler på tilsvarende måte. Alle like hensiktsløst. Vi kan derfor bruke across() for å kode om på samme måte for alle variable samtidig.\nHeldigvis ligger disse inntektsvariablene i rekkefølge i datasettet slik at vi kan spesifisere variablene med “fra:til”. Den første variabelen er inarbled og den siste er inwyrkinnt og det kan da skrives som inarbled:inwyrkinnt.\nHer er koden som gjør dette:\n\nnorlag &lt;- norlag %&gt;% \n    mutate(across(inarbled:inwyrkinnt, \n                ~ case_when(. == \"Value &lt;0 &gt;-5000\" ~ -5000, \n                            . == \"Value &gt;0 &lt;5000\" ~ 5000,\n                            TRUE ~ as.numeric(as.character(.))\n                            )\n                )\n           )\n\nOg dermed har vi et datasett i et svært så ryddig R-format. Eller i hvert fall det aller meste. Det vil alltid være behov for å gjøre ytterligere omkodinger for en spesifikk analyse, og det kan være andre generelle ting som ikke har blitt tatt hånd om her.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Import av data fra Sikt - håndtering av formater med metadata</span>"
    ]
  },
  {
    "objectID": "appendix_import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "href": "appendix_import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling",
    "text": "B.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling\nKoden ovenfor er ganske avansert. Det er en del ting som er litt mer avansert enn det vi har gått gjennom tidligere. Vi skal her gå gjennom de viktigste elementene i koden.\n\nB.3.1 across()\nacross() er en funksjon som brukes for å gjøre noe på tvers av kolonner. Det er en del av dplyr-pakken. Den brukes for å gjøre noe på tvers av kolonner. I koden ovenfor brukes den for å gjøre om alle variable som er inntektsvariable til numeriske variable.\n\n\nB.3.2 case_when()\ncase_when() er en funksjon som brukes for å gjøre en rekke sammenligninger og returnere en verdi basert på disse sammenligningene. Den brukes i koden ovenfor for å gjøre om lablene på inntektsvariablene til numeriske verdier.\n\n\nB.3.3 fra factor til numerisk\nI koden ovenfor gjøres det om fra factor til numerisk ved å bruke as.numeric(as.character(.)). Dette er fordi en factor ikke kan gjøres om til numerisk direkte.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Import av data fra Sikt - håndtering av formater med metadata</span>"
    ]
  },
  {
    "objectID": "appendix_import_metadata.html#footnotes",
    "href": "appendix_import_metadata.html#footnotes",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "",
    "text": "Det kan sies mye om å levere ut data på denne måten, men det vil ikke ta seg ut å gjøre det i undervisningsmaterialet.↩︎\nBasert på kode fra https://tim-tiefenbach.de/post/2023-recode-columns/↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Import av data fra Sikt - håndtering av formater med metadata</span>"
    ]
  },
  {
    "objectID": "appendix_dictionary.html",
    "href": "appendix_dictionary.html",
    "title": "Appendix C — Lage dictionary-fil",
    "section": "",
    "text": "C.1 Lese inn html-dokumentasjonen\nDokumentasjonen som følger med NorLAG og andre datasett fra Sikt er en html-fil (dvs. web-side) med en oversikt over alle variable og hvordan de er kodet. Dette er fint for manuelt oppslag, men er ikke ideelt til bruk for maskinell behandling.\nDet vi ideelt skulle hatt er et samlet datasett der kodeskjemaet er knyttet til variabelnavnene. Dette kalles noen ganger en “dictionary” fil. All informasjonen vi trenger for å lage en slik ligger i html-filen man får sammen med datasettet fra Sikt, bare på en knotete form. Det skal vi fikse.\nNedenfor skal vi vise hvordan vi gjør følgende:\nDette er egentlig en svært enkel introduksjon til webscraping for et spesfikt formål. Vi skal bruke pakken rvest som er laget nettopp for webscraping.\nFørste sted er å lese inn html-filen. Funksjonen read_html() gjør dette. For å skjønne litt mer av hvordan dette ser ut kan du åpne den opprinnelige html-filen i ren tekst, f.eks. med bruk av Notepad. Det er dette som leses inn. Jeg legger det i et nytt objekt som jeg har kalt cb (forkortelse for codebook).\n# read html file\n\ncb &lt;- read_html(\"data/Kodebok.html\")\nFor NorLAG er dokumentasjonsdokumentet inndelt i flere deler, og det er bare den siste delen som inneholder kodeskjemaene. Det er denne siste delen vi trenger, så første utfordring er å plukke ut denne delen.\nEn html-fil er strukturert innenfor “noder” som har en start og en slutt. Et avsnitt starter med en kode &lt;a&gt; og avsluttes med &lt;/a&gt;. Tilsvarende koder finnes for tabeller og andre elementer. Disse delene har er oftest gitt et navn som man kan identififiseres og brukes til lage lenker til spesifikke deler av siden (jf. innholdsfortegnelsen). Vi bruker denne til å filtrere filen.\nI akkurat denne filen trenger vi informasjonen som ligger etter overskriften “Variables Description”. For å finne navnet på dette avsnittet kan man undersøke lenken i innholdsfortegnelsen der det fremkommer som #variables. Eller man kan åpne html-filen i et tekstdokument og søke opp tittelen, så finner man koden name='variables innenfor det avsnittet.\nVi bruker html_nodes til å trekke ut bare dette avsnittet som følger.\n# Find the specific heading\nvariables &lt;- cb %&gt;% \n  html_nodes(\"a[name='variables']\")\nI denne dokumentasjonen er hver variabel lagret i en egen tabell. I html-kode angis begynnelsen av en tabell med &lt;table&gt; og denne brukes til å trekke ut bare tabellene.\ntables &lt;- variables %&gt;% \n    #html_node(xpath = \"//a[@name='variables']\") %&gt;% \n    html_nodes(xpath = \"./following::table\")\nSå kan vi bruke funksjonen html_table til å trekke ut hver enkelt tabell i en struktur som er lettere å jobbe med, nemlig en “data.frame”, altså en rektangulær struktur med rader og kolonner slik datasett vanligvis ser ut. Hver tabell blir et eget data.frame-objekt, og når man legger dette i et nytt objekt blir det av typen “list”. En “list” er en samling objekter som har hver sin plass i det samme objektet. (Du kan tenke på det som en eske med flere mindre ekster oppi). Vi kommer tilbake til hvordan de slås sammen.\ntable_data &lt;- html_table(tables)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Lage dictionary-fil</span>"
    ]
  },
  {
    "objectID": "appendix_dictionary.html#lese-inn-html-dokumentasjonen",
    "href": "appendix_dictionary.html#lese-inn-html-dokumentasjonen",
    "title": "Appendix C — Lage dictionary-fil",
    "section": "",
    "text": "C.1.1 Legge det hele i en funksjon\n\n# Check if the heading exists\nif (length(variables) &gt; 0) {\n  # Find the tables after the heading\n  tables &lt;- variables %&gt;% \n    html_node(xpath = \"//a[@name='variables']\") %&gt;% \n    html_nodes(xpath = \"./following::table\")\n  \n  # Extract the table data\n  table_data &lt;- html_table(tables)\n  } else {\n  cat(\"The specified heading was not found.\")\n}\n\n\ntbslist &lt;- list()\nfor(i in 1:length(table_data)){ \n  if(\"X2\" %in% names(table_data[[i]]) & \n     \"X3\" %in% names(table_data[[i]]) & \n     !(\"X4\" %in% names(table_data[[i]])) ){\n    \n    tbslist[[i]] &lt;- table_data[[i]] %&gt;% \n      mutate(col_nm = strsplit(as.character(.[1,1]), split = \":\")[[1]][1],\n             spm = strsplit(as.character(.[1,1]), split = \":\")[[1]][2]) %&gt;% \n      rename( value = X2, \n              label = X3) %&gt;%\n      filter( str_detect(X1, \"Values and categories\")) %&gt;% \n      filter( !is.na(value)) %&gt;% \n      select(-X1)\n  }\n  else{\n    if(i==1){\n      teller &lt;- 0\n      }\n    teller &lt;- teller + 1 \n  }\n  if(i == length(table_data)){\n    print(paste(\"Antall variable som ikke har omkodinger: \", teller)) \n  }\n}\n\n[1] \"Antall variable som ikke har omkodinger:  1\"\n\ndat_dict &lt;- bind_rows(tbslist) %&gt;% \n  select(col_nm, value, label, spm)\n\n\nsaveRDS(dat_dict, \"data/dat_dict.rds\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Lage dictionary-fil</span>"
    ]
  },
  {
    "objectID": "appendix_empirisk_eksempel.html",
    "href": "appendix_empirisk_eksempel.html",
    "title": "Appendix D — Empirisk eksempel",
    "section": "",
    "text": "D.1 Utvalg av variable\nArtikkelen “Human Values and Retirement Experiences: a Longitudinal Analysis of Norwegian Data” bruker data fra NorLAG, runde 2 og 3. I det som følger vil hovedresultatene fra denne studien replikeres. Stor takk til Morten Blekesaune som var meget velvillig til å dele script slik at reprodusering er praktisk mulig.\nAlle variable er dokumentert på NorLAG sine sider, og i egen fil som følger med utdelt datasett “kodebok.html”.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.2.0     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.2     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(haven)\n\n\ninfilbane &lt;- \"C:/Users/torbskar/OneDrive - Universitetet i Oslo/Dokumenter/Undervisning/SOS4020_forkurs/data2023/rOBH3y10/\"\n\n# Leser inn dta-fil, velger aktuelle variable og koder om missing-verdier til NA. \n# drop_na() sletter observasjoner med NA-verdier. Merk at dette gjøres for de variablene som er valgt ut i steget før. \nregister &lt;- read_stata( paste0(infilbane, \"NorLAG-lengde-register.dta\"), encoding = \"utf-8\") %&gt;% \n  select(ref_nr, year, \n         inpgivinnt, inwoverfor, inftryg, inwyrkinnt, inwoverfor,    # pensj_ft overf_ft penal_ft penuf_ft penin_ft \n         inkode217, inkode218 ) %&gt;% \n  mutate(inpgivinnt = ifelse(inpgivinnt == 999999999, NA, inpgivinnt),\n         inwoverfor = ifelse(inwoverfor == 999999999, NA, inwoverfor),\n         inftryg = ifelse(inftryg == 999999999, NA, inftryg)) %&gt;% \n  drop_na()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Empirisk eksempel</span>"
    ]
  },
  {
    "objectID": "appendix_empirisk_eksempel.html#etablering-av-utvalg-for-analyse",
    "href": "appendix_empirisk_eksempel.html#etablering-av-utvalg-for-analyse",
    "title": "Appendix D — Empirisk eksempel",
    "section": "G.1 Etablering av utvalg for analyse",
    "text": "G.1 Etablering av utvalg for analyse",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Empirisk eksempel</span>"
    ]
  },
  {
    "objectID": "appendix_empirisk_eksempel.html#deskriptiv-statistikk",
    "href": "appendix_empirisk_eksempel.html#deskriptiv-statistikk",
    "title": "Appendix D — Empirisk eksempel",
    "section": "G.2 Deskriptiv statistikk",
    "text": "G.2 Deskriptiv statistikk",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Empirisk eksempel</span>"
    ]
  },
  {
    "objectID": "appendix_empirisk_eksempel.html#en-kommentar-om-reproduserbarhet",
    "href": "appendix_empirisk_eksempel.html#en-kommentar-om-reproduserbarhet",
    "title": "Appendix D — Empirisk eksempel",
    "section": "G.3 En kommentar om reproduserbarhet",
    "text": "G.3 En kommentar om reproduserbarhet\nDet er svært viktig at forskning lar seg reprodusere. I denne sammenhengen gjelder det å kunne reprodusere nøyaktig samme resultat på samme data, som er viktig for uavhengig ettergåelse og kvalitetskontroll. At reproduserbart script kan gjøres tilgjengelig er helt avgjørende, men også at data er tilgjengelig. I dette tilfellet har Morten Blekesaune vært meget velvillig delt script etter forespørsel. Han svarte på epost samme dag, noe som er et tydelig tegn på at han også hadde orden i sakene og visst godt hvor scriptet var. Sånn skal det være!\nData var vanskeligere. NorLAG er ikke åpne data og er ikke opp til forskeren å dele. Vi er derfor avhengig av at også Sikt har orden i sakene. NorLAG er publisert i flere versjoner der det har vært noen endringer underveis. Det ble derfor praktisk vanskelig å få etablert nøyaktig samme utvalg uten å også få nøyaktig samme datauttrekk utlevert. Hvis ikke dataleverandør kan gi nøyaktig samme data, så blir heller ikke scriptet nøyaktig reproduserbart.\nEn viktig side ved å dele scriptet er at det gjøres en del små valg i den faktiske analysen som typisk ikke fremgår med tilstrekkelig detaljgrad i forskningsartikkelen.\n\nG.3.1 Replikering på uavhengige data\nMer generelt er det også viktig å kunne replikere tilsvarende resultater på andre data, men det har et litt annet formål. For slik replisering er det imidlertid også viktig å ha nøyaktig informasjon om hva som ble gjort i den opprinnelige studien og data er godt dokumentert.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Empirisk eksempel</span>"
    ]
  }
]