# Logistisk regresjon

```{r}
#| echo: false
invisible(Sys.setlocale(locale='no_NB.utf8'))
```

```{r}
#| warning: false
#| message: false
library(tidyverse)
library(haven)
library(modelsummary)
```

```{r}
#| echo: false
#| warning: false
#| message: false
abu89 <- read_stata("data/abu89.dta") %>%
  mutate(across(where(is.labelled), ~as_factor(.)),
         across(where(is.factor), ~fct_drop(.)))
```

I forrige kapittel om den lineære sannsynlighetsmodellen så vi at man kan bruke vanlig lineær regresjon selv om utfallsvariabelen er binær (0/1). Det fungerer greit i mange sammenhenger, men har noen begrensninger. Den viktigste er at modellen kan gi predikerte sannsynligheter som er under 0 eller over 1, noe som jo ikke gir mening. Logistisk regresjon løser dette problemet.

Logistisk regresjon er den vanligste metoden når utfallsvariabelen er binær, altså har to verdier. I samfunnsvitenskapen brukes det veldig mye: er personen i jobb eller ikke? Stemte personen ved valget eller ikke? Har personen høy eller lav inntekt? Osv.


## Lage en binær utfallsvariabel

Vi skal bruke et eksempel der vi prøver å predikere hvem som har høy timelønn. Vi lager en ny variabel `hoylonn` som er 1 hvis timelønna er over medianen og 0 ellers.

```{r}
#| warning: false
#| message: false
abu89 <- abu89 %>%
  mutate(hoylonn = ifelse(time89 > median(time89, na.rm = TRUE), 1, 0))
```

La oss sjekke fordelingen:
```{r}
#| warning: false
#| message: false
table(abu89$hoylonn)
```

Omtrent halvparten har høy lønn, noe som gir mening siden vi delte ved medianen.


## Hvorfor ikke bare bruke lineær regresjon?

Som vi så i kapittelet om [lineær sannsynlighetsmodell](lineaer_sannsynlighetsmodell.qmd), kan vi bruke vanlig `lm()` også med binær utfallsvariabel. Koeffisientene tolkes da som endring i sannsynlighet (andel). Problemet oppstår spesielt når vi predikerer: vi kan få verdier under 0 eller over 1. Logistisk regresjon sørger for at predikerte sannsynligheter alltid ligger mellom 0 og 1.


## Logit-transformasjonen og odds

Ideen bak logistisk regresjon er å modellere *log-oddsen* i stedet for sannsynligheten direkte. Men hva er egentlig odds?

Tenk deg at 80 av 100 personer i en gruppe er i jobb. Da er sannsynligheten 0.80 (80%). Oddsen er forholdet mellom sannsynligheten for å være i jobb og sannsynligheten for å *ikke* være i jobb: $0.80 / 0.20 = 4$. Altså: det er fire ganger så sannsynlig å være i jobb som å ikke være det.

Logistisk regresjon modellerer logaritmen av oddsen (log-odds). Fordelen er at log-odds kan variere fritt fra minus uendelig til pluss uendelig, mens sannsynligheter er begrenset mellom 0 og 1. Matematisk sett gjør dette at modellen alltid gir gyldige sannsynligheter.

Du trenger ikke bekymre deg så mye om den matematiske detaljen her. Det viktigste å huske er:

- Koeffisientene fra logistisk regresjon er på log-odds-skalaen
- Man kan konvertere til odds-ratio ved å eksponentiere: `exp(koeffisient)`
- Man kan regne om til sannsynligheter med `predict(..., type = "response")`


## Estimere logistisk regresjon i R

I R bruker vi `glm()` med argumentet `family = binomial` for å estimere logistisk regresjon. Syntaksen er ellers helt lik `lm()`.

La oss starte enkelt med kjønn som forklaringsvariabel:

```{r}
#| warning: false
#| message: false
logit1 <- glm(hoylonn ~ female, data = abu89, family = binomial)
summary(logit1)
```

Koeffisienten for `female` er negativ, som betyr at kvinner har lavere log-odds for å ha høy lønn sammenlignet med menn. Men log-odds er ikke veldig intuitivt, så vi konverterer til odds-ratio.


## Tolke koeffisientene: odds-ratio

For å gjøre koeffisientene mer tolkbare konverterer vi fra log-odds til odds-ratio med `exp()`:

```{r}
#| warning: false
#| message: false
exp(coef(logit1))
```

En odds-ratio på 1 betyr ingen forskjell. Over 1 betyr høyere odds, under 1 betyr lavere odds. Koeffisienten for `female` gir en odds-ratio under 1, som altså betyr at kvinner har lavere odds for høy lønn enn menn.

Man kan også få ut konfidensintervaller for odds-ratioene:

```{r}
#| warning: false
#| message: false
exp(confint(logit1))
```


## Flere forklaringsvariable

La oss utvide modellen med klasse og alder i tillegg til kjønn:

```{r}
#| warning: false
#| message: false
logit2 <- glm(hoylonn ~ female + klasse89 + age, data = abu89, family = binomial)
summary(logit2)
```

Tolkningen av koeffisientene er litt annerledes enn i lineær regresjon. Hver koeffisient viser endring i log-odds for utfallet (høy lønn) per enhets endring i forklaringsvariabelen, kontrollert for de andre variablene. La oss se på odds-ratioene:

```{r}
#| warning: false
#| message: false
exp(coef(logit2))
```

Odds-ratioene tolkes slik: en odds-ratio for `age` på f.eks. 1.02 ville bety at for hvert års økning i alder øker oddsen for høy lønn med 2%, kontrollert for kjønn og klasse.


## Predikere sannsynligheter

En veldig nyttig ting med logistisk regresjon er at vi kan predikere sannsynligheter. Vi bruker `predict()` med `type = "response"` for å få sannsynligheter i stedet for log-odds:

```{r}
#| warning: false
#| message: false
nyedata <- expand.grid(
  female = c(0, 1),
  klasse89 = levels(abu89$klasse89)[1:2],
  age = c(30, 40, 50)
)

nyedata$pred_sannsynlighet <- predict(logit2, newdata = nyedata, type = "response")
nyedata
```

Nå har vi estimerte sannsynligheter for høy lønn for ulike kombinasjoner av kjønn, klasse og alder. Merk at alle verdier ligger mellom 0 og 1, slik det skal være.


## Presentere resultater med `modelsummary()`

Vi kan bruke `modelsummary()` for å lage pene tabeller, akkurat som for lineær regresjon. Her viser vi først koeffisienter på log-odds-skalaen:

```{r}
#| warning: false
#| message: false
modelsummary(list("Log-odds" = logit1, "Log-odds" = logit2),
             fmt = 3,
             estimate = "{estimate} ({std.error})",
             statistic = NULL,
             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|F|RMSE')
```

Vi kan også vise odds-ratioer ved å bruke `exponentiate = TRUE`:

```{r}
#| warning: false
#| message: false
modelsummary(list("OR" = logit1, "OR" = logit2),
             exponentiate = TRUE,
             fmt = 2,
             estimate = "{estimate} ({std.error})",
             statistic = 'conf.int',
             gof_omit = 'DF|Deviance|AIC|BIC|Log.Lik.|F|RMSE')
```

Merk `exponentiate = TRUE` som gjør at koeffisientene vises som odds-ratioer. Det er som regel lurt å rapportere odds-ratioer fordi de er lettere å tolke.

For å eksportere til Word gjøres det på nøyaktig samme måte som for lineær regresjon, ved å sette `output = "filnavn.docx"`.


## Modelltilpasning

I lineær regresjon har vi $R^2$ som mål på hvor godt modellen passer til dataene. I logistisk regresjon finnes det ingen perfekt ekvivalent, men det finnes flere varianter av pseudo-$R^2$. Disse kan tolkes omtrent på samme måte: et tall mellom 0 og 1 der høyere verdier betyr bedre tilpasning.

En annen tilnærming er å se på hvor godt modellen klassifiserer observasjonene. Vi kan sammenligne predikerte verdier med faktiske verdier:

```{r}
#| warning: false
#| message: false
abu89_pred <- abu89 %>%
  filter(!is.na(hoylonn), !is.na(klasse89), !is.na(age)) %>%
  mutate(pred_prob = predict(logit2, type = "response"),
         pred_klasse = ifelse(pred_prob > 0.5, 1, 0))

table(Faktisk = abu89_pred$hoylonn, Predikert = abu89_pred$pred_klasse)
```

Denne tabellen kalles en *forvirringsmatrise* (confusion matrix). Diagonalen viser korrekte prediksjoner, mens de andre cellene viser feilklassifiseringer. Andelen korrekte prediksjoner kan regnes ut slik:

```{r}
#| warning: false
#| message: false
mean(abu89_pred$hoylonn == abu89_pred$pred_klasse, na.rm = TRUE)
```

Dette gir oss en enkel indikasjon på hvor godt modellen predikerer. Husk imidlertid at hovedpoenget med logistisk regresjon i samfunnsvitenskap som regel er å forstå sammenhenger mellom variable, ikke nødvendigvis å predikere best mulig.


## Oppsummering

Logistisk regresjon brukes når utfallsvariabelen er binær (0/1). De viktigste punktene er:

- Bruk `glm(y ~ x, family = binomial)` for å estimere modellen
- Koeffisientene er på log-odds-skalaen, konverter til odds-ratio med `exp()`
- Odds-ratio over 1 betyr høyere odds, under 1 betyr lavere odds
- Bruk `predict(modell, type = "response")` for å få predikerte sannsynligheter
- Bruk `modelsummary()` med `exponentiate = TRUE` for å vise odds-ratioer i tabeller
- Tolkningen av kontrollvariable er den samme som i lineær regresjon
